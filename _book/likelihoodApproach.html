<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3.4 Likelihood Approach | Forecasting and Analytics with ADAM</title>
  <meta name="description" content="This textbook explains how to do time series analysis and forecasting using Augmented Dynamic Adaptive Model, implemented in smooth package for R." />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="3.4 Likelihood Approach | Forecasting and Analytics with ADAM" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This textbook explains how to do time series analysis and forecasting using Augmented Dynamic Adaptive Model, implemented in smooth package for R." />
  <meta name="github-repo" content="config-i1/adam" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3.4 Likelihood Approach | Forecasting and Analytics with ADAM" />
  
  <meta name="twitter:description" content="This textbook explains how to do time series analysis and forecasting using Augmented Dynamic Adaptive Model, implemented in smooth package for R." />
  

<meta name="author" content="Ivan Svetunkov" />


<meta name="date" content="2021-07-01" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="regression-uncertainty.html"/>
<link rel="next" href="statisticsNumberOfParameters.html"/>
<script src="libs/header-attrs-2.9/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/bsTable-3.3.7/bootstrapTable.min.css" rel="stylesheet" />
<script src="libs/bsTable-3.3.7/bootstrapTable.js"></script>
<script async defer src="https://hypothes.is/embed.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-XH37Z8VYP8"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-XH37Z8VYP8');
</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Forecasting and Analytics with ADAM</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i>License</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#what-is-adam"><i class="fa fa-check"></i>What is ADAM?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgments"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="modelsMethods.html"><a href="modelsMethods.html"><i class="fa fa-check"></i><b>1.1</b> Models, methods et al. </a></li>
<li class="chapter" data-level="1.2" data-path="scales.html"><a href="scales.html"><i class="fa fa-check"></i><b>1.2</b> Scales of information</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="scales.html"><a href="scales.html#nominal-scale"><i class="fa fa-check"></i><b>1.2.1</b> Nominal scale</a></li>
<li class="chapter" data-level="1.2.2" data-path="scales.html"><a href="scales.html#ordinal-scale"><i class="fa fa-check"></i><b>1.2.2</b> Ordinal scale</a></li>
<li class="chapter" data-level="1.2.3" data-path="scales.html"><a href="scales.html#interval-scale"><i class="fa fa-check"></i><b>1.2.3</b> Interval scale</a></li>
<li class="chapter" data-level="1.2.4" data-path="scales.html"><a href="scales.html#ratio-scale"><i class="fa fa-check"></i><b>1.2.4</b> Ratio scale</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="statistics.html"><a href="statistics.html"><i class="fa fa-check"></i><b>2</b> Introduction to statistics</a>
<ul>
<li class="chapter" data-level="2.1" data-path="dataAnalysis.html"><a href="dataAnalysis.html"><i class="fa fa-check"></i><b>2.1</b> Preliminary data analysis</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="dataAnalysis.html"><a href="dataAnalysis.html#numerical-analysis"><i class="fa fa-check"></i><b>2.1.1</b> Numerical analysis</a></li>
<li class="chapter" data-level="2.1.2" data-path="dataAnalysis.html"><a href="dataAnalysis.html#dataAnalysisGraphical"><i class="fa fa-check"></i><b>2.1.2</b> Graphical analysis</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="LLNandCLT.html"><a href="LLNandCLT.html"><i class="fa fa-check"></i><b>2.2</b> Law of Large Numbers and Central Limit Theorem</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="LLNandCLT.html"><a href="LLNandCLT.html#LLN"><i class="fa fa-check"></i><b>2.2.1</b> Law of Large Numbers</a></li>
<li class="chapter" data-level="2.2.2" data-path="LLNandCLT.html"><a href="LLNandCLT.html#CLT"><i class="fa fa-check"></i><b>2.2.2</b> Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="estimatesProperties.html"><a href="estimatesProperties.html"><i class="fa fa-check"></i><b>2.3</b> Properties of estimators</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="estimatesProperties.html"><a href="estimatesProperties.html#estimatesPropertiesBias"><i class="fa fa-check"></i><b>2.3.1</b> Bias</a></li>
<li class="chapter" data-level="2.3.2" data-path="estimatesProperties.html"><a href="estimatesProperties.html#estimatesPropertiesEfficiency"><i class="fa fa-check"></i><b>2.3.2</b> Efficiency</a></li>
<li class="chapter" data-level="2.3.3" data-path="estimatesProperties.html"><a href="estimatesProperties.html#estimatesPropertiesConsistency"><i class="fa fa-check"></i><b>2.3.3</b> Consistency</a></li>
<li class="chapter" data-level="2.3.4" data-path="estimatesProperties.html"><a href="estimatesProperties.html#asymptoticNormality"><i class="fa fa-check"></i><b>2.3.4</b> Asymptotic normality</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="confidenceIntervals.html"><a href="confidenceIntervals.html"><i class="fa fa-check"></i><b>2.4</b> Confidence and prediction intervals</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="confidenceIntervals.html"><a href="confidenceIntervals.html#confidence-interval"><i class="fa fa-check"></i><b>2.4.1</b> Confidence interval</a></li>
<li class="chapter" data-level="2.4.2" data-path="confidenceIntervals.html"><a href="confidenceIntervals.html#prediction-interval"><i class="fa fa-check"></i><b>2.4.2</b> Prediction interval</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="hypothesisTesting.html"><a href="hypothesisTesting.html"><i class="fa fa-check"></i><b>2.5</b> Hypothesis testing</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="hypothesisTesting.html"><a href="hypothesisTesting.html#hypothesisTestingMistakes"><i class="fa fa-check"></i><b>2.5.1</b> Common mistakes related to hypothesis testing</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="correlations.html"><a href="correlations.html"><i class="fa fa-check"></i><b>2.6</b> Correlation and measures of association</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="correlations.html"><a href="correlations.html#nominal-scale-1"><i class="fa fa-check"></i><b>2.6.1</b> Nominal scale</a></li>
<li class="chapter" data-level="2.6.2" data-path="correlations.html"><a href="correlations.html#ordinal-scale-1"><i class="fa fa-check"></i><b>2.6.2</b> Ordinal scale</a></li>
<li class="chapter" data-level="2.6.3" data-path="correlations.html"><a href="correlations.html#correlationCoefficient"><i class="fa fa-check"></i><b>2.6.3</b> Numerical scale</a></li>
<li class="chapter" data-level="2.6.4" data-path="correlations.html"><a href="correlations.html#correlationsMixed"><i class="fa fa-check"></i><b>2.6.4</b> Mixed scales</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="distributions.html"><a href="distributions.html"><i class="fa fa-check"></i><b>2.7</b> Theory of distributions</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="distributions.html"><a href="distributions.html#distributionsNormal"><i class="fa fa-check"></i><b>2.7.1</b> Normal distribution</a></li>
<li class="chapter" data-level="2.7.2" data-path="distributions.html"><a href="distributions.html#distributionsLaplace"><i class="fa fa-check"></i><b>2.7.2</b> Laplace distribution</a></li>
<li class="chapter" data-level="2.7.3" data-path="distributions.html"><a href="distributions.html#s-distribution"><i class="fa fa-check"></i><b>2.7.3</b> S distribution</a></li>
<li class="chapter" data-level="2.7.4" data-path="distributions.html"><a href="distributions.html#distributionsGeneralisedNormal"><i class="fa fa-check"></i><b>2.7.4</b> Generalised Normal distribution</a></li>
<li class="chapter" data-level="2.7.5" data-path="distributions.html"><a href="distributions.html#distributionsALaplace"><i class="fa fa-check"></i><b>2.7.5</b> Asymmetric Laplace distribution</a></li>
<li class="chapter" data-level="2.7.6" data-path="distributions.html"><a href="distributions.html#log-normal-log-laplace-log-s-and-log-gn-distributions"><i class="fa fa-check"></i><b>2.7.6</b> Log Normal, Log Laplace, Log S and Log GN distributions</a></li>
<li class="chapter" data-level="2.7.7" data-path="distributions.html"><a href="distributions.html#IGDistribution"><i class="fa fa-check"></i><b>2.7.7</b> Inverse Gaussian distribution</a></li>
<li class="chapter" data-level="2.7.8" data-path="distributions.html"><a href="distributions.html#GammaDistribution"><i class="fa fa-check"></i><b>2.7.8</b> Gamma distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>3</b> Regression analysis</a>
<ul>
<li class="chapter" data-level="3.1" data-path="simpleLinearRegression.html"><a href="simpleLinearRegression.html"><i class="fa fa-check"></i><b>3.1</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="simpleLinearRegression.html"><a href="simpleLinearRegression.html#OLS"><i class="fa fa-check"></i><b>3.1.1</b> Ordinary Least Squares (OLS)</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="linearRegression.html"><a href="linearRegression.html"><i class="fa fa-check"></i><b>3.2</b> Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="linearRegression.html"><a href="linearRegression.html#ols-estimation"><i class="fa fa-check"></i><b>3.2.1</b> OLS estimation</a></li>
<li class="chapter" data-level="3.2.2" data-path="linearRegression.html"><a href="linearRegression.html#linearRegressionQualityOfFit"><i class="fa fa-check"></i><b>3.2.2</b> Quality of a fit</a></li>
<li class="chapter" data-level="3.2.3" data-path="linearRegression.html"><a href="linearRegression.html#interpretation-of-parameters"><i class="fa fa-check"></i><b>3.2.3</b> Interpretation of parameters</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="regression-uncertainty.html"><a href="regression-uncertainty.html"><i class="fa fa-check"></i><b>3.3</b> Regression uncertainty</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="regression-uncertainty.html"><a href="regression-uncertainty.html#confidence-intervals"><i class="fa fa-check"></i><b>3.3.1</b> Confidence intervals</a></li>
<li class="chapter" data-level="3.3.2" data-path="regression-uncertainty.html"><a href="regression-uncertainty.html#hypothesis-testing"><i class="fa fa-check"></i><b>3.3.2</b> Hypothesis testing</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="likelihoodApproach.html"><a href="likelihoodApproach.html"><i class="fa fa-check"></i><b>3.4</b> Likelihood Approach</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="likelihoodApproach.html"><a href="likelihoodApproach.html#an-example-in-r"><i class="fa fa-check"></i><b>3.4.1</b> An example in R</a></li>
<li class="chapter" data-level="3.4.2" data-path="likelihoodApproach.html"><a href="likelihoodApproach.html#likelihoodApproachMaths"><i class="fa fa-check"></i><b>3.4.2</b> Mathematical explanation</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="statisticsNumberOfParameters.html"><a href="statisticsNumberOfParameters.html"><i class="fa fa-check"></i><b>3.5</b> Calculating number of parameters in models</a></li>
<li class="chapter" data-level="3.6" data-path="assumptions.html"><a href="assumptions.html"><i class="fa fa-check"></i><b>3.6</b> Typical assumptions of statistical models</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="assumptions.html"><a href="assumptions.html#assumptionsCorrectModel"><i class="fa fa-check"></i><b>3.6.1</b> Model is correctly specified</a></li>
<li class="chapter" data-level="3.6.2" data-path="assumptions.html"><a href="assumptions.html#assumptionsResidualsAreIID"><i class="fa fa-check"></i><b>3.6.2</b> Residuals are i.i.d.</a></li>
<li class="chapter" data-level="3.6.3" data-path="assumptions.html"><a href="assumptions.html#assumptionsXreg"><i class="fa fa-check"></i><b>3.6.3</b> The explanatory variables are not correlated with anything but the response variable</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="regressionModelBuilding.html"><a href="regressionModelBuilding.html"><i class="fa fa-check"></i><b>4</b> Regression model building</a>
<ul>
<li class="chapter" data-level="4.1" data-path="modelSelection.html"><a href="modelSelection.html"><i class="fa fa-check"></i><b>4.1</b> Model selection mechanism</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="modelSelection.html"><a href="modelSelection.html#informationCriteria"><i class="fa fa-check"></i><b>4.1.1</b> Information criteria idea</a></li>
<li class="chapter" data-level="4.1.2" data-path="modelSelection.html"><a href="modelSelection.html#informationCriteriaMistakes"><i class="fa fa-check"></i><b>4.1.2</b> Common confusions related to information criteria</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="forecastingProcess.html"><a href="forecastingProcess.html"><i class="fa fa-check"></i><b>5</b> Forecasts evaluation</a>
<ul>
<li class="chapter" data-level="5.1" data-path="errorMeasures.html"><a href="errorMeasures.html"><i class="fa fa-check"></i><b>5.1</b> Measuring accuracy of point forecasts</a></li>
<li class="chapter" data-level="5.2" data-path="uncertainty.html"><a href="uncertainty.html"><i class="fa fa-check"></i><b>5.2</b> Measuring uncertainty</a></li>
<li class="chapter" data-level="5.3" data-path="rollingOrigin.html"><a href="rollingOrigin.html"><i class="fa fa-check"></i><b>5.3</b> Rolling origin</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="rollingOrigin.html"><a href="rollingOrigin.html#principles-of-rolling-origin"><i class="fa fa-check"></i><b>5.3.1</b> Principles of Rolling origin</a></li>
<li class="chapter" data-level="5.3.2" data-path="rollingOrigin.html"><a href="rollingOrigin.html#rolling-origin-in-r"><i class="fa fa-check"></i><b>5.3.2</b> Rolling origin in R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="tsDecomposition.html"><a href="tsDecomposition.html"><i class="fa fa-check"></i><b>6</b> From time series components to ETS</a>
<ul>
<li class="chapter" data-level="6.1" data-path="tsComponents.html"><a href="tsComponents.html"><i class="fa fa-check"></i><b>6.1</b> Time series components</a></li>
<li class="chapter" data-level="6.2" data-path="ClassicalDecomposition.html"><a href="ClassicalDecomposition.html"><i class="fa fa-check"></i><b>6.2</b> Classical Seasonal Decomposition</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="ClassicalDecomposition.html"><a href="ClassicalDecomposition.html#how-to-do"><i class="fa fa-check"></i><b>6.2.1</b> How to do?</a></li>
<li class="chapter" data-level="6.2.2" data-path="ClassicalDecomposition.html"><a href="ClassicalDecomposition.html#a-couple-of-examples"><i class="fa fa-check"></i><b>6.2.2</b> A couple of examples</a></li>
<li class="chapter" data-level="6.2.3" data-path="ClassicalDecomposition.html"><a href="ClassicalDecomposition.html#other-techniques"><i class="fa fa-check"></i><b>6.2.3</b> Other techniques</a></li>
<li class="chapter" data-level="6.2.4" data-path="ClassicalDecomposition.html"><a href="ClassicalDecomposition.html#why-bother"><i class="fa fa-check"></i><b>6.2.4</b> “Why bother?”</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="ETSTaxonomy.html"><a href="ETSTaxonomy.html"><i class="fa fa-check"></i><b>6.3</b> ETS taxonomy</a></li>
<li class="chapter" data-level="6.4" data-path="ETSTaxonomyMaths.html"><a href="ETSTaxonomyMaths.html"><i class="fa fa-check"></i><b>6.4</b> Mathematical models in the ETS taxonomy</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="conventional-exponential-smoothing.html"><a href="conventional-exponential-smoothing.html"><i class="fa fa-check"></i><b>7</b> Conventional Exponential Smoothing</a>
<ul>
<li class="chapter" data-level="7.1" data-path="SES.html"><a href="SES.html"><i class="fa fa-check"></i><b>7.1</b> Simple Exponential Smoothing</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="SES.html"><a href="SES.html#examples-of-application"><i class="fa fa-check"></i><b>7.1.1</b> Examples of application</a></li>
<li class="chapter" data-level="7.1.2" data-path="SES.html"><a href="SES.html#whyExponential"><i class="fa fa-check"></i><b>7.1.2</b> Why “exponential?”</a></li>
<li class="chapter" data-level="7.1.3" data-path="SES.html"><a href="SES.html#error-correction-form-of-ses"><i class="fa fa-check"></i><b>7.1.3</b> Error correction form of SES</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="SESandETS.html"><a href="SESandETS.html"><i class="fa fa-check"></i><b>7.2</b> SES and ETS</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="SESandETS.html"><a href="SESandETS.html#etsann"><i class="fa fa-check"></i><b>7.2.1</b> ETS(A,N,N)</a></li>
<li class="chapter" data-level="7.2.2" data-path="SESandETS.html"><a href="SESandETS.html#etsmnn"><i class="fa fa-check"></i><b>7.2.2</b> ETS(M,N,N)</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="ETSExamples.html"><a href="ETSExamples.html"><i class="fa fa-check"></i><b>7.3</b> Several examples of exponential smoothing methods and ETS</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="ETSExamples.html"><a href="ETSExamples.html#ETSAAN"><i class="fa fa-check"></i><b>7.3.1</b> ETS(A,A,N)</a></li>
<li class="chapter" data-level="7.3.2" data-path="ETSExamples.html"><a href="ETSExamples.html#ETSAAdN"><i class="fa fa-check"></i><b>7.3.2</b> ETS(A,Ad,N)</a></li>
<li class="chapter" data-level="7.3.3" data-path="ETSExamples.html"><a href="ETSExamples.html#etsaam"><i class="fa fa-check"></i><b>7.3.3</b> ETS(A,A,M)</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="ets-assumptions-estimation-and-selection.html"><a href="ets-assumptions-estimation-and-selection.html"><i class="fa fa-check"></i><b>7.4</b> ETS assumptions, estimation and selection</a></li>
<li class="chapter" data-level="7.5" data-path="state-space-form-of-ets.html"><a href="state-space-form-of-ets.html"><i class="fa fa-check"></i><b>7.5</b> State space form of ETS</a></li>
<li class="chapter" data-level="7.6" data-path="ETSParametersBounds.html"><a href="ETSParametersBounds.html"><i class="fa fa-check"></i><b>7.6</b> Parameters bounds</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ADAMETSIntroduction.html"><a href="ADAMETSIntroduction.html"><i class="fa fa-check"></i><b>8</b> Pure additive ADAM ETS</a>
<ul>
<li class="chapter" data-level="8.1" data-path="ADAMETSPureAdditive.html"><a href="ADAMETSPureAdditive.html"><i class="fa fa-check"></i><b>8.1</b> Model formulation</a></li>
<li class="chapter" data-level="8.2" data-path="adamETSPureAdditiveRecursive.html"><a href="adamETSPureAdditiveRecursive.html"><i class="fa fa-check"></i><b>8.2</b> Recursive relation</a></li>
<li class="chapter" data-level="8.3" data-path="pureAdditiveExpectationAndVariance.html"><a href="pureAdditiveExpectationAndVariance.html"><i class="fa fa-check"></i><b>8.3</b> Conditional expectation and variance</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="pureAdditiveExpectationAndVariance.html"><a href="pureAdditiveExpectationAndVariance.html#example-with-etsann"><i class="fa fa-check"></i><b>8.3.1</b> Example with ETS(A,N,N)</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="stabilityConditionAdditiveError.html"><a href="stabilityConditionAdditiveError.html"><i class="fa fa-check"></i><b>8.4</b> Stability and forecastability conditions</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="stabilityConditionAdditiveError.html"><a href="stabilityConditionAdditiveError.html#example-with-etsann-1"><i class="fa fa-check"></i><b>8.4.1</b> Example with ETS(A,N,N)</a></li>
<li class="chapter" data-level="8.4.2" data-path="stabilityConditionAdditiveError.html"><a href="stabilityConditionAdditiveError.html#comming-back-to-the-general-case"><i class="fa fa-check"></i><b>8.4.2</b> Comming back to the general case</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="ADAMETSAdditiveDistributions.html"><a href="ADAMETSAdditiveDistributions.html"><i class="fa fa-check"></i><b>8.5</b> Distributional assumptions in pure additive ETS</a></li>
<li class="chapter" data-level="8.6" data-path="ADAMETSPureAdditiveExamples.html"><a href="ADAMETSPureAdditiveExamples.html"><i class="fa fa-check"></i><b>8.6</b> Examples of application</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="ADAMETSPureAdditiveExamples.html"><a href="ADAMETSPureAdditiveExamples.html#non-seasonal-data"><i class="fa fa-check"></i><b>8.6.1</b> Non-seasonal data</a></li>
<li class="chapter" data-level="8.6.2" data-path="ADAMETSPureAdditiveExamples.html"><a href="ADAMETSPureAdditiveExamples.html#ADAMETSPureAdditiveExamplesETSAAA"><i class="fa fa-check"></i><b>8.6.2</b> Seasonal data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ADAMETSPureMultiplicative.html"><a href="ADAMETSPureMultiplicative.html"><i class="fa fa-check"></i><b>9</b> Pure multiplicative ADAM ETS</a>
<ul>
<li class="chapter" data-level="9.1" data-path="adamETSPuremultiplicativeRecursive.html"><a href="adamETSPuremultiplicativeRecursive.html"><i class="fa fa-check"></i><b>9.1</b> Recursive relation</a></li>
<li class="chapter" data-level="9.2" data-path="pureMultiplicativeExpectationAndVariance.html"><a href="pureMultiplicativeExpectationAndVariance.html"><i class="fa fa-check"></i><b>9.2</b> The problem with moments in pure multiplicative ETS</a></li>
<li class="chapter" data-level="9.3" data-path="stabilityConditionMultiplicativeError.html"><a href="stabilityConditionMultiplicativeError.html"><i class="fa fa-check"></i><b>9.3</b> Smoothing parameters bounds</a></li>
<li class="chapter" data-level="9.4" data-path="ADAMETSMultiplicativeDistributions.html"><a href="ADAMETSMultiplicativeDistributions.html"><i class="fa fa-check"></i><b>9.4</b> Distributional assumptions in pure multiplicative ETS</a></li>
<li class="chapter" data-level="9.5" data-path="ADAMETSMultiplicativeExamples.html"><a href="ADAMETSMultiplicativeExamples.html"><i class="fa fa-check"></i><b>9.5</b> Examples of application</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="ADAMETSMultiplicativeExamples.html"><a href="ADAMETSMultiplicativeExamples.html#non-seasonal-data-1"><i class="fa fa-check"></i><b>9.5.1</b> Non-seasonal data</a></li>
<li class="chapter" data-level="9.5.2" data-path="ADAMETSMultiplicativeExamples.html"><a href="ADAMETSMultiplicativeExamples.html#seasonal-data"><i class="fa fa-check"></i><b>9.5.2</b> Seasonal data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="ADAMETSMixedModels.html"><a href="ADAMETSMixedModels.html"><i class="fa fa-check"></i><b>10</b> Further ADAM ETS topics</a>
<ul>
<li class="chapter" data-level="10.1" data-path="ADAMETSMixedModelsGroup3.html"><a href="ADAMETSMixedModelsGroup3.html"><i class="fa fa-check"></i><b>10.1</b> Mixed models with non-multiplicative trend</a></li>
<li class="chapter" data-level="10.2" data-path="ADAMETSMixedModelsGroup4.html"><a href="ADAMETSMixedModelsGroup4.html"><i class="fa fa-check"></i><b>10.2</b> Mixed models with multiplicative trend</a></li>
<li class="chapter" data-level="10.3" data-path="ADAMETSSeasonalNormalisation.html"><a href="ADAMETSSeasonalNormalisation.html"><i class="fa fa-check"></i><b>10.3</b> Normalisation of seasonal indices in ETS models</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ARIMA.html"><a href="ARIMA.html"><i class="fa fa-check"></i><b>11</b> Conventional ARIMA</a>
<ul>
<li class="chapter" data-level="11.1" data-path="ARIMAIntro.html"><a href="ARIMAIntro.html"><i class="fa fa-check"></i><b>11.1</b> Introduction to ARIMA</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="ARIMAIntro.html"><a href="ARIMAIntro.html#AR"><i class="fa fa-check"></i><b>11.1.1</b> AR(p)</a></li>
<li class="chapter" data-level="11.1.2" data-path="ARIMAIntro.html"><a href="ARIMAIntro.html#MA"><i class="fa fa-check"></i><b>11.1.2</b> MA(q)</a></li>
<li class="chapter" data-level="11.1.3" data-path="ARIMAIntro.html"><a href="ARIMAIntro.html#ARMA"><i class="fa fa-check"></i><b>11.1.3</b> ARMA(p,q)</a></li>
<li class="chapter" data-level="11.1.4" data-path="ARIMAIntro.html"><a href="ARIMAIntro.html#ARMAConstant"><i class="fa fa-check"></i><b>11.1.4</b> ARMA with constant</a></li>
<li class="chapter" data-level="11.1.5" data-path="ARIMAIntro.html"><a href="ARIMAIntro.html#Differences"><i class="fa fa-check"></i><b>11.1.5</b> I(d)</a></li>
<li class="chapter" data-level="11.1.6" data-path="ARIMAIntro.html"><a href="ARIMAIntro.html#arimapdq"><i class="fa fa-check"></i><b>11.1.6</b> ARIMA(p,d,q)</a></li>
<li class="chapter" data-level="11.1.7" data-path="ARIMAIntro.html"><a href="ARIMAIntro.html#ARIMABounds"><i class="fa fa-check"></i><b>11.1.7</b> Parameters bounds</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="seasonal-arima.html"><a href="seasonal-arima.html"><i class="fa fa-check"></i><b>11.2</b> Seasonal ARIMA</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="seasonal-arima.html"><a href="seasonal-arima.html#single-seasonal-arima"><i class="fa fa-check"></i><b>11.2.1</b> Single seasonal ARIMA</a></li>
<li class="chapter" data-level="11.2.2" data-path="seasonal-arima.html"><a href="seasonal-arima.html#sarima-with-constant"><i class="fa fa-check"></i><b>11.2.2</b> SARIMA with constant</a></li>
<li class="chapter" data-level="11.2.3" data-path="seasonal-arima.html"><a href="seasonal-arima.html#MSARIMA"><i class="fa fa-check"></i><b>11.2.3</b> Multiple seasonal ARIMA</a></li>
<li class="chapter" data-level="11.2.4" data-path="seasonal-arima.html"><a href="seasonal-arima.html#MSARIMABounds"><i class="fa fa-check"></i><b>11.2.4</b> Parameters bounds for MSARIMA</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="BJApproach.html"><a href="BJApproach.html"><i class="fa fa-check"></i><b>11.3</b> Box-Jenkins approach</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="BJApproach.html"><a href="BJApproach.html#identifying-stationarity"><i class="fa fa-check"></i><b>11.3.1</b> Identifying stationarity</a></li>
<li class="chapter" data-level="11.3.2" data-path="BJApproach.html"><a href="BJApproach.html#ACF"><i class="fa fa-check"></i><b>11.3.2</b> Autocorrelation function (ACF)</a></li>
<li class="chapter" data-level="11.3.3" data-path="BJApproach.html"><a href="BJApproach.html#PACF"><i class="fa fa-check"></i><b>11.3.3</b> Partial autocorrelation function (PACF)</a></li>
<li class="chapter" data-level="11.3.4" data-path="BJApproach.html"><a href="BJApproach.html#BJApproachSummary"><i class="fa fa-check"></i><b>11.3.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="ARIMAandETS.html"><a href="ARIMAandETS.html"><i class="fa fa-check"></i><b>11.4</b> ARIMA and ETS</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="ARIMAandETS.html"><a href="ARIMAandETS.html#ARIMAETS011"><i class="fa fa-check"></i><b>11.4.1</b> ARIMA(0,1,1) and ETS(A,N,N)</a></li>
<li class="chapter" data-level="11.4.2" data-path="ARIMAandETS.html"><a href="ARIMAandETS.html#ARIMAETS022"><i class="fa fa-check"></i><b>11.4.2</b> ARIMA(0,2,2) and ETS(A,A,N)</a></li>
<li class="chapter" data-level="11.4.3" data-path="ARIMAandETS.html"><a href="ARIMAandETS.html#ARIMAETS112"><i class="fa fa-check"></i><b>11.4.3</b> ARIMA(1,1,2) and ETS(A,Ad,N)</a></li>
<li class="chapter" data-level="11.4.4" data-path="ARIMAandETS.html"><a href="ARIMAandETS.html#arima-and-other-ets-models"><i class="fa fa-check"></i><b>11.4.4</b> ARIMA and other ETS models</a></li>
<li class="chapter" data-level="11.4.5" data-path="ARIMAandETS.html"><a href="ARIMAandETS.html#ets-arima"><i class="fa fa-check"></i><b>11.4.5</b> ETS + ARIMA</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="ARIMAExampleInR.html"><a href="ARIMAExampleInR.html"><i class="fa fa-check"></i><b>11.5</b> Examples of application</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="ARIMAExampleInR.html"><a href="ARIMAExampleInR.html#non-seasonal-data-2"><i class="fa fa-check"></i><b>11.5.1</b> Non-seasonal data</a></li>
<li class="chapter" data-level="11.5.2" data-path="ARIMAExampleInR.html"><a href="ARIMAExampleInR.html#ARIMAExampleInRSeasonal"><i class="fa fa-check"></i><b>11.5.2</b> Seasonal data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="ADAMARIMA.html"><a href="ADAMARIMA.html"><i class="fa fa-check"></i><b>12</b> ADAM ARIMA</a>
<ul>
<li class="chapter" data-level="12.1" data-path="StateSpaceARIMA.html"><a href="StateSpaceARIMA.html"><i class="fa fa-check"></i><b>12.1</b> State space ARIMA</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="StateSpaceARIMA.html"><a href="StateSpaceARIMA.html#StateSpaceARIMAAdditive"><i class="fa fa-check"></i><b>12.1.1</b> Additive ARIMA</a></li>
<li class="chapter" data-level="12.1.2" data-path="StateSpaceARIMA.html"><a href="StateSpaceARIMA.html#an-example"><i class="fa fa-check"></i><b>12.1.2</b> An example</a></li>
<li class="chapter" data-level="12.1.3" data-path="StateSpaceARIMA.html"><a href="StateSpaceARIMA.html#state-space-arima-with-constant"><i class="fa fa-check"></i><b>12.1.3</b> State space ARIMA with constant</a></li>
<li class="chapter" data-level="12.1.4" data-path="StateSpaceARIMA.html"><a href="StateSpaceARIMA.html#ADAMARIMAPureMultiplicative"><i class="fa fa-check"></i><b>12.1.4</b> Multiplicative ARIMA</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="ADAMARIMARecursive.html"><a href="ADAMARIMARecursive.html"><i class="fa fa-check"></i><b>12.2</b> Recursive relation</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="ADAMARIMARecursive.html"><a href="ADAMARIMARecursive.html#moments-of-adam-arima"><i class="fa fa-check"></i><b>12.2.1</b> Moments of ADAM ARIMA</a></li>
<li class="chapter" data-level="12.2.2" data-path="ADAMARIMARecursive.html"><a href="ADAMARIMARecursive.html#parameters-bounds"><i class="fa fa-check"></i><b>12.2.2</b> Parameters bounds</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="ADAMARIMADistributions.html"><a href="ADAMARIMADistributions.html"><i class="fa fa-check"></i><b>12.3</b> Distributional assumptions of ADAM ARIMA</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="ADAMARIMADistributions.html"><a href="ADAMARIMADistributions.html#conditional-distributions"><i class="fa fa-check"></i><b>12.3.1</b> Conditional distributions</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="ets-arima-1.html"><a href="ets-arima-1.html"><i class="fa fa-check"></i><b>12.4</b> ETS + ARIMA</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="ets-arima-1.html"><a href="ets-arima-1.html#pure-additive-models"><i class="fa fa-check"></i><b>12.4.1</b> Pure additive models</a></li>
<li class="chapter" data-level="12.4.2" data-path="ets-arima-1.html"><a href="ets-arima-1.html#pure-multiplicative-models"><i class="fa fa-check"></i><b>12.4.2</b> Pure multiplicative models</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="ADAMARIMAExamples.html"><a href="ADAMARIMAExamples.html"><i class="fa fa-check"></i><b>12.5</b> Examples of application</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="ADAMX.html"><a href="ADAMX.html"><i class="fa fa-check"></i><b>13</b> Explanatory variables in ADAM</a>
<ul>
<li class="chapter" data-level="13.1" data-path="adamx-model-formulation.html"><a href="adamx-model-formulation.html"><i class="fa fa-check"></i><b>13.1</b> ADAMX: Model formulation</a></li>
<li class="chapter" data-level="13.2" data-path="ADAMXConventionalConditionalMoments.html"><a href="ADAMXConventionalConditionalMoments.html"><i class="fa fa-check"></i><b>13.2</b> Conditional expectation and variance of ADAMX</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="ADAMXConventionalConditionalMoments.html"><a href="ADAMXConventionalConditionalMoments.html#the-adamx-with-known-explanatory-variables"><i class="fa fa-check"></i><b>13.2.1</b> The ADAMX with known explanatory variables</a></li>
<li class="chapter" data-level="13.2.2" data-path="ADAMXConventionalConditionalMoments.html"><a href="ADAMXConventionalConditionalMoments.html#adamx-with-random-explanatory-variables"><i class="fa fa-check"></i><b>13.2.2</b> ADAMX with random explanatory variables</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="ADAMXDynamic.html"><a href="ADAMXDynamic.html"><i class="fa fa-check"></i><b>13.3</b> Dynamic X in ADAMX</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="ADAMXDynamic.html"><a href="ADAMXDynamic.html#conditional-moments-of-dynamic-adamx"><i class="fa fa-check"></i><b>13.3.1</b> Conditional moments of dynamic ADAMX</a></li>
<li class="chapter" data-level="13.3.2" data-path="ADAMXDynamic.html"><a href="ADAMXDynamic.html#known-explanatory-variables"><i class="fa fa-check"></i><b>13.3.2</b> Known explanatory variables</a></li>
<li class="chapter" data-level="13.3.3" data-path="ADAMXDynamic.html"><a href="ADAMXDynamic.html#random-explanatory-variables"><i class="fa fa-check"></i><b>13.3.3</b> Random explanatory variables</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="stability-and-forecastability-conditions-of-adamx.html"><a href="stability-and-forecastability-conditions-of-adamx.html"><i class="fa fa-check"></i><b>13.4</b> Stability and forecastability conditions of ADAMX</a></li>
<li class="chapter" data-level="13.5" data-path="ETSXDynamicCategories.html"><a href="ETSXDynamicCategories.html"><i class="fa fa-check"></i><b>13.5</b> Dealing with categorical variables in ADAMX</a></li>
<li class="chapter" data-level="13.6" data-path="ETSXRExample.html"><a href="ETSXRExample.html"><i class="fa fa-check"></i><b>13.6</b> Examples of application</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="ADAMETSEstimation.html"><a href="ADAMETSEstimation.html"><i class="fa fa-check"></i><b>14</b> Estimation of ADAM models</a>
<ul>
<li class="chapter" data-level="14.1" data-path="ADAMETSEstimationLikelihood.html"><a href="ADAMETSEstimationLikelihood.html"><i class="fa fa-check"></i><b>14.1</b> Maximum Likelihood Estimation</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="ADAMETSEstimationLikelihood.html"><a href="ADAMETSEstimationLikelihood.html#an-example-in-r-1"><i class="fa fa-check"></i><b>14.1.1</b> An example in R</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="non-mle-based-loss-functions.html"><a href="non-mle-based-loss-functions.html"><i class="fa fa-check"></i><b>14.2</b> Non MLE-based loss functions</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="non-mle-based-loss-functions.html"><a href="non-mle-based-loss-functions.html#MSEandMAEEstimators"><i class="fa fa-check"></i><b>14.2.1</b> MSE and MAE</a></li>
<li class="chapter" data-level="14.2.2" data-path="non-mle-based-loss-functions.html"><a href="non-mle-based-loss-functions.html#ham"><i class="fa fa-check"></i><b>14.2.2</b> HAM</a></li>
<li class="chapter" data-level="14.2.3" data-path="non-mle-based-loss-functions.html"><a href="non-mle-based-loss-functions.html#lasso-and-ridge"><i class="fa fa-check"></i><b>14.2.3</b> LASSO and RIDGE</a></li>
<li class="chapter" data-level="14.2.4" data-path="non-mle-based-loss-functions.html"><a href="non-mle-based-loss-functions.html#custom-losses"><i class="fa fa-check"></i><b>14.2.4</b> Custom losses</a></li>
<li class="chapter" data-level="14.2.5" data-path="non-mle-based-loss-functions.html"><a href="non-mle-based-loss-functions.html#examples-in-r"><i class="fa fa-check"></i><b>14.2.5</b> Examples in R</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="multistepLosses.html"><a href="multistepLosses.html"><i class="fa fa-check"></i><b>14.3</b> Multistep losses</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="multistepLosses.html"><a href="multistepLosses.html#mathrmmse_h---mse-for-h-steps-ahead"><i class="fa fa-check"></i><b>14.3.1</b> <span class="math inline">\(\mathrm{MSE}_h\)</span> - MSE for h steps ahead</a></li>
<li class="chapter" data-level="14.3.2" data-path="multistepLosses.html"><a href="multistepLosses.html#multistepLossesTMSE"><i class="fa fa-check"></i><b>14.3.2</b> TMSE - Trace MSE</a></li>
<li class="chapter" data-level="14.3.3" data-path="multistepLosses.html"><a href="multistepLosses.html#multistepLossesGTMSE"><i class="fa fa-check"></i><b>14.3.3</b> GTMSE - Geometric Trace MSE</a></li>
<li class="chapter" data-level="14.3.4" data-path="multistepLosses.html"><a href="multistepLosses.html#msce---mean-squared-cumulative-error"><i class="fa fa-check"></i><b>14.3.4</b> MSCE - Mean Squared Cumulative Error</a></li>
<li class="chapter" data-level="14.3.5" data-path="multistepLosses.html"><a href="multistepLosses.html#gpl---general-predictive-likelihood"><i class="fa fa-check"></i><b>14.3.5</b> GPL - General Predictive Likelihood</a></li>
<li class="chapter" data-level="14.3.6" data-path="multistepLosses.html"><a href="multistepLosses.html#other-multistep-estimators"><i class="fa fa-check"></i><b>14.3.6</b> Other multistep estimators</a></li>
<li class="chapter" data-level="14.3.7" data-path="multistepLosses.html"><a href="multistepLosses.html#an-example-in-r-2"><i class="fa fa-check"></i><b>14.3.7</b> An example in R</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="ADAMInitialisation.html"><a href="ADAMInitialisation.html"><i class="fa fa-check"></i><b>14.4</b> Initialisation of ADAM</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="ADAMInitialisation.html"><a href="ADAMInitialisation.html#ADAMInitialisationOptAndBack"><i class="fa fa-check"></i><b>14.4.1</b> Optimisation vs backcasting</a></li>
<li class="chapter" data-level="14.4.2" data-path="ADAMInitialisation.html"><a href="ADAMInitialisation.html#pre-initialisation-of-adam-parameters"><i class="fa fa-check"></i><b>14.4.2</b> Pre-initialisation of ADAM parameters</a></li>
<li class="chapter" data-level="14.4.3" data-path="ADAMInitialisation.html"><a href="ADAMInitialisation.html#pre-initialisation-of-adam-states-ets"><i class="fa fa-check"></i><b>14.4.3</b> Pre-initialisation of ADAM states, ETS</a></li>
<li class="chapter" data-level="14.4.4" data-path="ADAMInitialisation.html"><a href="ADAMInitialisation.html#pre-initialisation-of-adam-states-arima"><i class="fa fa-check"></i><b>14.4.4</b> Pre-initialisation of ADAM states, ARIMA</a></li>
<li class="chapter" data-level="14.4.5" data-path="ADAMInitialisation.html"><a href="ADAMInitialisation.html#pre-initialisation-of-adam-states-regressors-and-constant"><i class="fa fa-check"></i><b>14.4.5</b> Pre-initialisation of ADAM states, Regressors and constant</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="multiple-frequencies-in-adam-ets.html"><a href="multiple-frequencies-in-adam-ets.html"><i class="fa fa-check"></i><b>15</b> Multiple frequencies in ADAM ETS</a>
<ul>
<li class="chapter" data-level="15.1" data-path="estimation-of-multiple-seasonal-model.html"><a href="estimation-of-multiple-seasonal-model.html"><i class="fa fa-check"></i><b>15.1</b> Estimation of multiple seasonal model</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="estimation-of-multiple-seasonal-model.html"><a href="estimation-of-multiple-seasonal-model.html#adam-ets-issues"><i class="fa fa-check"></i><b>15.1.1</b> ADAM ETS issues</a></li>
<li class="chapter" data-level="15.1.2" data-path="estimation-of-multiple-seasonal-model.html"><a href="estimation-of-multiple-seasonal-model.html#adam-arima-issues"><i class="fa fa-check"></i><b>15.1.2</b> ADAM ARIMA issues</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="ETSXMultipleSeasonality.html"><a href="ETSXMultipleSeasonality.html"><i class="fa fa-check"></i><b>15.2</b> Using explanatory variables for multiple seasonalities</a></li>
<li class="chapter" data-level="15.3" data-path="MultipleFrequenciesDSTandLeap.html"><a href="MultipleFrequenciesDSTandLeap.html"><i class="fa fa-check"></i><b>15.3</b> Dealing with daylight saving and leap years</a></li>
<li class="chapter" data-level="15.4" data-path="ADAMMultipleFrequenciesExamples.html"><a href="ADAMMultipleFrequenciesExamples.html"><i class="fa fa-check"></i><b>15.4</b> Examples of application</a>
<ul>
<li class="chapter" data-level="15.4.1" data-path="ADAMMultipleFrequenciesExamples.html"><a href="ADAMMultipleFrequenciesExamples.html#adam-ets"><i class="fa fa-check"></i><b>15.4.1</b> ADAM ETS</a></li>
<li class="chapter" data-level="15.4.2" data-path="ADAMMultipleFrequenciesExamples.html"><a href="ADAMMultipleFrequenciesExamples.html#adam-etsx"><i class="fa fa-check"></i><b>15.4.2</b> ADAM ETSX</a></li>
<li class="chapter" data-level="15.4.3" data-path="ADAMMultipleFrequenciesExamples.html"><a href="ADAMMultipleFrequenciesExamples.html#adam-arima"><i class="fa fa-check"></i><b>15.4.3</b> ADAM ARIMA</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="ADAMIntermittent.html"><a href="ADAMIntermittent.html"><i class="fa fa-check"></i><b>16</b> ADAM for Intermittent Demand</a>
<ul>
<li class="chapter" data-level="16.1" data-path="ADAMOccurrence.html"><a href="ADAMOccurrence.html"><i class="fa fa-check"></i><b>16.1</b> Occurrence part of the model</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="ADAMOccurrence.html"><a href="ADAMOccurrence.html#fixed-probability-model-oets_f"><i class="fa fa-check"></i><b>16.1.1</b> Fixed probability model, oETS<span class="math inline">\(_F\)</span></a></li>
<li class="chapter" data-level="16.1.2" data-path="ADAMOccurrence.html"><a href="ADAMOccurrence.html#oETSO"><i class="fa fa-check"></i><b>16.1.2</b> Odds ratio model, oETS<span class="math inline">\(_O\)</span></a></li>
<li class="chapter" data-level="16.1.3" data-path="ADAMOccurrence.html"><a href="ADAMOccurrence.html#inverse-odds-ratio-model-oets_i"><i class="fa fa-check"></i><b>16.1.3</b> Inverse odds ratio model, oETS<span class="math inline">\(_I\)</span></a></li>
<li class="chapter" data-level="16.1.4" data-path="ADAMOccurrence.html"><a href="ADAMOccurrence.html#oETSG"><i class="fa fa-check"></i><b>16.1.4</b> General oETS model, oETS<span class="math inline">\(_G\)</span></a></li>
<li class="chapter" data-level="16.1.5" data-path="ADAMOccurrence.html"><a href="ADAMOccurrence.html#direct-probability-model-oets_d"><i class="fa fa-check"></i><b>16.1.5</b> Direct probability model, oETS<span class="math inline">\(_D\)</span></a></li>
<li class="chapter" data-level="16.1.6" data-path="ADAMOccurrence.html"><a href="ADAMOccurrence.html#oETSModelSelection"><i class="fa fa-check"></i><b>16.1.6</b> Model selection in oETS</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="ADAMDemandSizes.html"><a href="ADAMDemandSizes.html"><i class="fa fa-check"></i><b>16.2</b> Demand sizes part of the model</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="ADAMDemandSizes.html"><a href="ADAMDemandSizes.html#additive-vs-multiplicative-ets-for-demand-sizes"><i class="fa fa-check"></i><b>16.2.1</b> Additive vs multiplicative ETS for demand sizes</a></li>
<li class="chapter" data-level="16.2.2" data-path="ADAMDemandSizes.html"><a href="ADAMDemandSizes.html#using-arima-for-demand-sizes"><i class="fa fa-check"></i><b>16.2.2</b> Using ARIMA for demand sizes</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="ADAMIntermittentFull.html"><a href="ADAMIntermittentFull.html"><i class="fa fa-check"></i><b>16.3</b> The full ADAM model</a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="ADAMIntermittentFull.html"><a href="ADAMIntermittentFull.html#iETSMLE"><i class="fa fa-check"></i><b>16.3.1</b> Maximum Likelihood Estimation</a></li>
<li class="chapter" data-level="16.3.2" data-path="ADAMIntermittentFull.html"><a href="ADAMIntermittentFull.html#conditional-expectation-and-variance"><i class="fa fa-check"></i><b>16.3.2</b> Conditional expectation and variance</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="examples-of-application-1.html"><a href="examples-of-application-1.html"><i class="fa fa-check"></i><b>16.4</b> Examples of application</a></li>
<li class="chapter" data-level="16.5" data-path="intermittent-demand-challenges.html"><a href="intermittent-demand-challenges.html"><i class="fa fa-check"></i><b>16.5</b> Intermittent demand challenges</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="diagnostics.html"><a href="diagnostics.html"><i class="fa fa-check"></i><b>17</b> Model diagnostics</a>
<ul>
<li class="chapter" data-level="17.1" data-path="diagnosticsOmitted.html"><a href="diagnosticsOmitted.html"><i class="fa fa-check"></i><b>17.1</b> Model specification: Omitted variables</a></li>
<li class="chapter" data-level="17.2" data-path="model-specification-redundant-variables.html"><a href="model-specification-redundant-variables.html"><i class="fa fa-check"></i><b>17.2</b> Model specification: Redundant variables</a></li>
<li class="chapter" data-level="17.3" data-path="diagnosticsTransformations.html"><a href="diagnosticsTransformations.html"><i class="fa fa-check"></i><b>17.3</b> Model specification: Transformations</a></li>
<li class="chapter" data-level="17.4" data-path="diagnosticsOutliers.html"><a href="diagnosticsOutliers.html"><i class="fa fa-check"></i><b>17.4</b> Model specification: Outliers</a>
<ul>
<li class="chapter" data-level="17.4.1" data-path="diagnosticsOutliers.html"><a href="diagnosticsOutliers.html#outliers-detection"><i class="fa fa-check"></i><b>17.4.1</b> Outliers detection</a></li>
<li class="chapter" data-level="17.4.2" data-path="diagnosticsOutliers.html"><a href="diagnosticsOutliers.html#dealing-with-outliers"><i class="fa fa-check"></i><b>17.4.2</b> Dealing with outliers</a></li>
<li class="chapter" data-level="17.4.3" data-path="diagnosticsOutliers.html"><a href="diagnosticsOutliers.html#an-automatic-mechanism"><i class="fa fa-check"></i><b>17.4.3</b> An automatic mechanism</a></li>
<li class="chapter" data-level="17.4.4" data-path="diagnosticsOutliers.html"><a href="diagnosticsOutliers.html#final-remarks"><i class="fa fa-check"></i><b>17.4.4</b> Final remarks</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="diagnosticsResidualsIIDAuto.html"><a href="diagnosticsResidualsIIDAuto.html"><i class="fa fa-check"></i><b>17.5</b> Residuals are i.i.d.: autocorrelation</a></li>
<li class="chapter" data-level="17.6" data-path="diagnosticsResidualsIIDHetero.html"><a href="diagnosticsResidualsIIDHetero.html"><i class="fa fa-check"></i><b>17.6</b> Residuals are i.i.d.: heteroscedasticity</a>
<ul>
<li class="chapter" data-level="17.6.1" data-path="diagnosticsResidualsIIDHetero.html"><a href="diagnosticsResidualsIIDHetero.html#detecting-heteroscedasticity"><i class="fa fa-check"></i><b>17.6.1</b> Detecting heteroscedasticity</a></li>
</ul></li>
<li class="chapter" data-level="17.7" data-path="residuals-are-i-i-d-zero-expectation.html"><a href="residuals-are-i-i-d-zero-expectation.html"><i class="fa fa-check"></i><b>17.7</b> Residuals are i.i.d.: zero expectation</a></li>
<li class="chapter" data-level="17.8" data-path="residuals-are-i-i-d-distributional-assumptions.html"><a href="residuals-are-i-i-d-distributional-assumptions.html"><i class="fa fa-check"></i><b>17.8</b> Residuals are i.i.d.: distributional assumptions</a></li>
<li class="chapter" data-level="17.9" data-path="multicollinearity.html"><a href="multicollinearity.html"><i class="fa fa-check"></i><b>17.9</b> Multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="ADAMSelection.html"><a href="ADAMSelection.html"><i class="fa fa-check"></i><b>18</b> Model selection and combinations in ADAM</a>
<ul>
<li class="chapter" data-level="18.1" data-path="ETSSelection.html"><a href="ETSSelection.html"><i class="fa fa-check"></i><b>18.1</b> ADAM ETS components selection</a></li>
<li class="chapter" data-level="18.2" data-path="ARIMASelection.html"><a href="ARIMASelection.html"><i class="fa fa-check"></i><b>18.2</b> ADAM ARIMA order selection</a></li>
<li class="chapter" data-level="18.3" data-path="ETSXSelection.html"><a href="ETSXSelection.html"><i class="fa fa-check"></i><b>18.3</b> Explanatory variables selection</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Forecasting and Analytics with ADAM</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div class = rmdreview>
This book is in <b><a href="open.html#open">Open Review</a></b>. I want your feedback to make the book better for you and other readers. To add your annotation, <span style="background-color: #3297FD; color: white">select some text</span> and then click the <i class="h-icon-annotate"></i> on the pop-up menu. To see the annotations of others, click the button in the upper right hand corner of the page <i class="fa fa-arrow-circle-right  fa-rotate-315" aria-hidden="true"></i>
</div>
<div id="likelihoodApproach" class="section level2" number="3.4">
<h2><span class="header-section-number">3.4</span> Likelihood Approach</h2>
<p>We will use different estimation techniques throughout this book, one of the main of which is <strong>Maximum Likelihood Estimate</strong> (MLE). The very rough idea of the approach is to maximise the chance that each observation in the sample follows a pre-selected distribution with specific set of parameters. In a nutshell, what we try to do when using likelihood for estimation, is fit the distribution function to the data. In order to demonstrate this idea, we start in a non-conventional way, with an example in R. We will then move to the mathematical side of the problem.</p>
<div id="an-example-in-r" class="section level3" number="3.4.1">
<h3><span class="header-section-number">3.4.1</span> An example in R</h3>
<p>We consider a simple example, when we want to estimate the model <span class="math inline">\(y_t = \mu_y + \epsilon_t\)</span> (global average), assuming that the error term follows normal distribution: <span class="math inline">\(\epsilon_t \sim \mathcal{N}(0, \sigma^2)\)</span>, which means that <span class="math inline">\(y_t \sim \mathcal{N}(\mu_{y}, \sigma^2)\)</span>. In this case we want to estimate two parameters using likelihood: <span class="math inline">\(\hat{\mu}_y\)</span> and <span class="math inline">\(\hat{\sigma}^2\)</span>. First, we generate the random variable in R and plot its distribution:</p>
<div class="sourceCode" id="cb121"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb121-1"><a href="likelihoodApproach.html#cb121-1" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1000</span>, <span class="dv">100</span>, <span class="dv">10</span>)</span>
<span id="cb121-2"><a href="likelihoodApproach.html#cb121-2" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(y, <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">50</span>,<span class="dv">150</span>), <span class="at">main=</span><span class="st">&quot;&quot;</span>, <span class="at">probability=</span><span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="adam_files/figure-html/unnamed-chunk-52-1.png" width="672" /></p>
<p>As expected, the distribution of this variable (1000 observations) has the bell shape of Normal distribution. In order to estimate the parameters, for the distribution, we will try them one by one and see how the likelihood and the shape of the fitted curve to this histogram change. We start with <span class="math inline">\(\hat{\mu}_y=80\)</span> and <span class="math inline">\(\hat{\sigma}=10\)</span> just to see how the probability density function of normal distribution fits the data:</p>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb122-1"><a href="likelihoodApproach.html#cb122-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(y, <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">50</span>,<span class="dv">150</span>), <span class="at">main=</span><span class="st">&quot;&quot;</span>, <span class="at">probability=</span><span class="cn">TRUE</span>)</span>
<span id="cb122-2"><a href="likelihoodApproach.html#cb122-2" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">c</span>(<span class="dv">50</span><span class="sc">:</span><span class="dv">150</span>),<span class="fu">dnorm</span>(<span class="fu">c</span>(<span class="dv">50</span><span class="sc">:</span><span class="dv">150</span>),<span class="dv">80</span>,<span class="dv">10</span>),<span class="at">col=</span><span class="st">&quot;red&quot;</span>,<span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb122-3"><a href="likelihoodApproach.html#cb122-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="dv">80</span>,<span class="at">col=</span><span class="st">&quot;red&quot;</span>,<span class="at">lwd=</span><span class="dv">2</span>)</span></code></pre></div>
<div class="figure"><span id="fig:MLENormalExample01"></span>
<img src="adam_files/figure-html/MLENormalExample01-1.png" alt="ML example with Normal curve and $\hat{\mu}_y=80$ and $\hat{\sigma}=10$" width="672" />
<p class="caption">
Figure 3.10: ML example with Normal curve and <span class="math inline">\(\hat{\mu}_y=80\)</span> and <span class="math inline">\(\hat{\sigma}=10\)</span>
</p>
</div>
<p>and we get the following log-likelihood value (we will discuss how this formula can be obtained later):</p>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb123-1"><a href="likelihoodApproach.html#cb123-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">dnorm</span>(y,<span class="dv">80</span>,<span class="dv">10</span>,<span class="at">log=</span>T))</span></code></pre></div>
<pre><code>## [1] -5706.477</code></pre>
<p>In order for the normal distribution on <a href="likelihoodApproach.html#fig:MLENormalExample01">3.10</a> to fit the data well, we need to shift the estimate of <span class="math inline">\(\mu_y\)</span> to the right, thus increasing the value to, let’s say, <span class="math inline">\(\hat{\mu}_y=90\)</span>:</p>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb125-1"><a href="likelihoodApproach.html#cb125-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(y, <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">50</span>,<span class="dv">150</span>), <span class="at">main=</span><span class="st">&quot;&quot;</span>, <span class="at">probability=</span><span class="cn">TRUE</span>)</span>
<span id="cb125-2"><a href="likelihoodApproach.html#cb125-2" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">c</span>(<span class="dv">50</span><span class="sc">:</span><span class="dv">150</span>),<span class="fu">dnorm</span>(<span class="fu">c</span>(<span class="dv">50</span><span class="sc">:</span><span class="dv">150</span>),<span class="dv">90</span>,<span class="dv">10</span>),<span class="at">col=</span><span class="st">&quot;orange&quot;</span>,<span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb125-3"><a href="likelihoodApproach.html#cb125-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="dv">90</span>,<span class="at">col=</span><span class="st">&quot;orange&quot;</span>,<span class="at">lwd=</span><span class="dv">2</span>)</span></code></pre></div>
<div class="figure"><span id="fig:MLENormalExample02"></span>
<img src="adam_files/figure-html/MLENormalExample02-1.png" alt="ML example with Normal curve and $\hat{\mu}_y=90$ and $\hat{\sigma}=10$" width="672" />
<p class="caption">
Figure 3.11: ML example with Normal curve and <span class="math inline">\(\hat{\mu}_y=90\)</span> and <span class="math inline">\(\hat{\sigma}=10\)</span>
</p>
</div>
<p>Now, in Figure <a href="likelihoodApproach.html#fig:MLENormalExample02">3.11</a>, the normal curve is much closer to the data, but it is still a bit off. The log-likelihood value in this case is -4216.671, which is higher than the previous one, indicating that we are moving towards the maximum of the likelihood function. Moving it further, setting <span class="math inline">\(\hat{\mu}_y=100\)</span>, we get:</p>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb126-1"><a href="likelihoodApproach.html#cb126-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(y, <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">50</span>,<span class="dv">150</span>), <span class="at">main=</span><span class="st">&quot;&quot;</span>, <span class="at">probability=</span><span class="cn">TRUE</span>)</span>
<span id="cb126-2"><a href="likelihoodApproach.html#cb126-2" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">c</span>(<span class="dv">50</span><span class="sc">:</span><span class="dv">150</span>),<span class="fu">dnorm</span>(<span class="fu">c</span>(<span class="dv">50</span><span class="sc">:</span><span class="dv">150</span>),<span class="dv">100</span>,<span class="dv">10</span>),<span class="at">col=</span><span class="st">&quot;green3&quot;</span>,<span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb126-3"><a href="likelihoodApproach.html#cb126-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="dv">100</span>,<span class="at">col=</span><span class="st">&quot;green3&quot;</span>,<span class="at">lwd=</span><span class="dv">2</span>)</span></code></pre></div>
<div class="figure"><span id="fig:MLENormalExample03"></span>
<img src="adam_files/figure-html/MLENormalExample03-1.png" alt="ML example with Normal curve and $\hat{\mu}_y=100$ and $\hat{\sigma}=10$" width="672" />
<p class="caption">
Figure 3.12: ML example with Normal curve and <span class="math inline">\(\hat{\mu}_y=100\)</span> and <span class="math inline">\(\hat{\sigma}=10\)</span>
</p>
</div>
<p>Figure <a href="likelihoodApproach.html#fig:MLENormalExample02">3.11</a> demonstrates a much better fit than in the previous cases with the log-likelihood of -3726.864, which is even higher than in the previous case. We are almost there. In fact, in order to maximise this likelihood, we just need to calculate the sample mean of the variable (this is the MLE of the location parameter in normal distribution) and insert it in the function to obtain:</p>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb127-1"><a href="likelihoodApproach.html#cb127-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(y, <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">50</span>,<span class="dv">150</span>), <span class="at">main=</span><span class="st">&quot;&quot;</span>, <span class="at">probability=</span><span class="cn">TRUE</span>)</span>
<span id="cb127-2"><a href="likelihoodApproach.html#cb127-2" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">c</span>(<span class="dv">50</span><span class="sc">:</span><span class="dv">150</span>),<span class="fu">dnorm</span>(<span class="fu">c</span>(<span class="dv">50</span><span class="sc">:</span><span class="dv">150</span>),<span class="fu">mean</span>(y),<span class="dv">10</span>),<span class="at">col=</span><span class="st">&quot;darkgreen&quot;</span>,<span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb127-3"><a href="likelihoodApproach.html#cb127-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="fu">mean</span>(y),<span class="at">col=</span><span class="st">&quot;darkgreen&quot;</span>,<span class="at">lwd=</span><span class="dv">2</span>)</span></code></pre></div>
<div class="figure"><span id="fig:MLENormalExample04"></span>
<img src="adam_files/figure-html/MLENormalExample04-1.png" alt="ML example with Normal curve and $\hat{\mu}_y=\bar{y}$ and $\hat{\sigma}=10$" width="672" />
<p class="caption">
Figure 3.13: ML example with Normal curve and <span class="math inline">\(\hat{\mu}_y=\bar{y}\)</span> and <span class="math inline">\(\hat{\sigma}=10\)</span>
</p>
</div>
<p>So the value of <span class="math inline">\(\hat{\mu}_y=\bar{y}=\)</span> 99.898 (where <span class="math inline">\(\bar{y}\)</span> is the sample mean) maximises the likelihood function, resulting in log-likelihood of -3726.812.</p>
<p>In a similar fashion we can get the MLE of the scale parameter <span class="math inline">\(\sigma^2\)</span> of the model. In this case, we will be changing the height of the distribution. Here is an example with <span class="math inline">\(\hat{\mu}_y=\)</span> 99.898 and <span class="math inline">\(\hat{\sigma}=15\)</span>:</p>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb128-1"><a href="likelihoodApproach.html#cb128-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(y, <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">50</span>,<span class="dv">150</span>), <span class="at">main=</span><span class="st">&quot;&quot;</span>, <span class="at">probability=</span><span class="cn">TRUE</span>)</span>
<span id="cb128-2"><a href="likelihoodApproach.html#cb128-2" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">c</span>(<span class="dv">50</span><span class="sc">:</span><span class="dv">150</span>),<span class="fu">dnorm</span>(<span class="fu">c</span>(<span class="dv">50</span><span class="sc">:</span><span class="dv">150</span>),<span class="fu">mean</span>(y),<span class="dv">15</span>),<span class="at">col=</span><span class="st">&quot;royalblue&quot;</span>,<span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb128-3"><a href="likelihoodApproach.html#cb128-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="fu">mean</span>(y),<span class="at">col=</span><span class="st">&quot;royalblue&quot;</span>,<span class="at">lwd=</span><span class="dv">2</span>)</span></code></pre></div>
<div class="figure"><span id="fig:MLENormalExample05"></span>
<img src="adam_files/figure-html/MLENormalExample05-1.png" alt="ML example with Normal curve and $\hat{\mu}_y=\bar{y}$ and $\hat{\sigma}=15$" width="672" />
<p class="caption">
Figure 3.14: ML example with Normal curve and <span class="math inline">\(\hat{\mu}_y=\bar{y}\)</span> and <span class="math inline">\(\hat{\sigma}=15\)</span>
</p>
</div>
<p>Figure <a href="likelihoodApproach.html#fig:MLENormalExample05">3.14</a> demonstrates that the curve is located lower than needed, which implies that the scale parameter <span class="math inline">\(\hat{\sigma}\)</span> is too high. The log-likelihood value in this case is -3851.562. In order to get a better fit of the curve to the data, we need to reduce the <span class="math inline">\(\hat{\sigma}\)</span>. Here how the situation would look for the case of <span class="math inline">\(\hat{\sigma}=10\)</span>:</p>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="likelihoodApproach.html#cb129-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(y, <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">50</span>,<span class="dv">150</span>), <span class="at">main=</span><span class="st">&quot;&quot;</span>, <span class="at">probability=</span><span class="cn">TRUE</span>)</span>
<span id="cb129-2"><a href="likelihoodApproach.html#cb129-2" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">c</span>(<span class="dv">50</span><span class="sc">:</span><span class="dv">150</span>),<span class="fu">dnorm</span>(<span class="fu">c</span>(<span class="dv">50</span><span class="sc">:</span><span class="dv">150</span>),<span class="fu">mean</span>(y),<span class="dv">10</span>),<span class="at">col=</span><span class="st">&quot;darkblue&quot;</span>,<span class="at">lwd=</span><span class="dv">2</span>)</span>
<span id="cb129-3"><a href="likelihoodApproach.html#cb129-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v=</span><span class="fu">mean</span>(y),<span class="at">col=</span><span class="st">&quot;darkblue&quot;</span>,<span class="at">lwd=</span><span class="dv">2</span>)</span></code></pre></div>
<div class="figure"><span id="fig:MLENormalExample06"></span>
<img src="adam_files/figure-html/MLENormalExample06-1.png" alt="ML example with Normal curve and $\hat{\mu}_y=\bar{y}$ and $\hat{\sigma}=10$" width="672" />
<p class="caption">
Figure 3.15: ML example with Normal curve and <span class="math inline">\(\hat{\mu}_y=\bar{y}\)</span> and <span class="math inline">\(\hat{\sigma}=10\)</span>
</p>
</div>
<p>The fit on Figure <a href="likelihoodApproach.html#fig:MLENormalExample06">3.15</a> is better than on Figure <a href="likelihoodApproach.html#fig:MLENormalExample05">3.14</a>, which is also reflected in the log-likelihood value being equal to -3726.812 instead of -3851.562. The best fit and the maximum of the likelihood is obtained, when the scale parameter is estimated using the formula <span class="math inline">\(\hat{\sigma}^2 = \frac{1}{T}\sum_{t=1}^T\left(y_t - \bar{y}\right)^2\)</span>, resulting in log-likelihood of -3726.785. Note that if we use the unbiased estimate of the variance <span class="math inline">\(\hat{s}^2 = \frac{1}{T-1}\sum_{t=1}^T\left(y_t - \bar{y}\right)^2\)</span>, the log-likelihood will not reach the maximum and will be equal to -3726.785. In our special case the difference between the two is infinitesimal, because of the large sample (1000 observations), but it will be more substantial on small samples. Still, the two likelihood values are diffrent, which can be checked in R via the following commands:</p>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb130-1"><a href="likelihoodApproach.html#cb130-1" aria-hidden="true" tabindex="-1"></a><span class="co"># The maximum log-likelihood with the biased variance</span></span>
<span id="cb130-2"><a href="likelihoodApproach.html#cb130-2" aria-hidden="true" tabindex="-1"></a>logLik01 <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">dnorm</span>(y,<span class="fu">mean</span>(y),<span class="fu">sqrt</span>(<span class="fu">mean</span>((y<span class="sc">-</span><span class="fu">mean</span>(y))<span class="sc">^</span><span class="dv">2</span>)),<span class="at">log=</span><span class="cn">TRUE</span>))</span>
<span id="cb130-3"><a href="likelihoodApproach.html#cb130-3" aria-hidden="true" tabindex="-1"></a><span class="co"># The log-likelihood value with the unbiased variance</span></span>
<span id="cb130-4"><a href="likelihoodApproach.html#cb130-4" aria-hidden="true" tabindex="-1"></a>logLik02 <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">dnorm</span>(y,<span class="fu">mean</span>(y),<span class="fu">sd</span>(y),<span class="at">log=</span><span class="cn">TRUE</span>))</span>
<span id="cb130-5"><a href="likelihoodApproach.html#cb130-5" aria-hidden="true" tabindex="-1"></a><span class="co"># The difference between the two</span></span>
<span id="cb130-6"><a href="likelihoodApproach.html#cb130-6" aria-hidden="true" tabindex="-1"></a>logLik01 <span class="sc">-</span> logLik02</span></code></pre></div>
<p>All of this is great, but so far we have discussed a very special case, when the data follows normal distribution and we fit the respective model. But what if the model is wrong (no kidding!)? In that case the idea stays the same: we need to find the parameters of the normal distribution, that would guarantee the best possible fit to the non-normal data. Here is an example with MLE of parameters of Normal distribution for the data following Log Normal one:</p>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb131-1"><a href="likelihoodApproach.html#cb131-1" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rlnorm</span>(<span class="dv">1000</span>, <span class="fu">log</span>(<span class="dv">80</span>), <span class="fl">0.4</span>)</span>
<span id="cb131-2"><a href="likelihoodApproach.html#cb131-2" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(y, <span class="at">main=</span><span class="st">&quot;&quot;</span>, <span class="at">probability=</span>T, <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">300</span>))</span>
<span id="cb131-3"><a href="likelihoodApproach.html#cb131-3" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">c</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">300</span>),<span class="fu">dnorm</span>(<span class="fu">c</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">300</span>),<span class="fu">mean</span>(y),<span class="fu">sd</span>(y)),<span class="at">col=</span><span class="st">&quot;blue&quot;</span>,<span class="at">lwd=</span><span class="dv">2</span>)</span></code></pre></div>
<div class="figure"><span id="fig:MLENormalExample07"></span>
<img src="adam_files/figure-html/MLENormalExample07-1.png" alt="ML example with Normal curve on Log Normal data" width="672" />
<p class="caption">
Figure 3.16: ML example with Normal curve on Log Normal data
</p>
</div>
<p>Figure <a href="likelihoodApproach.html#fig:MLENormalExample07">3.16</a> shows that the Normal model does not fit the Log Normal data properly, but this is the best we can get, given our assumptions. The log-likelihood in this case is -5034.319. The much better model would be the Log Normal one:</p>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb132-1"><a href="likelihoodApproach.html#cb132-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(y, <span class="at">main=</span><span class="st">&quot;&quot;</span>, <span class="at">probability=</span>T, <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">300</span>))</span>
<span id="cb132-2"><a href="likelihoodApproach.html#cb132-2" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">c</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">300</span>),<span class="fu">dlnorm</span>(<span class="fu">c</span>(<span class="dv">0</span><span class="sc">:</span><span class="dv">300</span>),<span class="fu">mean</span>(<span class="fu">log</span>(y)),<span class="fu">sd</span>(<span class="fu">log</span>(y))),<span class="at">col=</span><span class="st">&quot;red&quot;</span>,<span class="at">lwd=</span><span class="dv">2</span>)</span></code></pre></div>
<div class="figure"><span id="fig:MLENormalExample08"></span>
<img src="adam_files/figure-html/MLENormalExample08-1.png" alt="ML example with Log Normal curve on Log Normal data" width="672" />
<p class="caption">
Figure 3.17: ML example with Log Normal curve on Log Normal data
</p>
</div>
<p>The model in Figure <a href="likelihoodApproach.html#fig:MLENormalExample08">3.17</a> has the log likelihood of -4915.125. This indicates that the Log Normal model is more appropriate for the data and gives us an idea that it is possible to compare different distributions via the likelihood, finding the better fit to the data. This idea is explored further in the <a href="modelSelection.html#modelSelection">next section</a>.</p>
<p>As a final word, when it comes to more complicated models with more parameters and dynamic structure, the specific curves and data become more complicated, but the logic of the likelihood approach stays the same.</p>
</div>
<div id="likelihoodApproachMaths" class="section level3" number="3.4.2">
<h3><span class="header-section-number">3.4.2</span> Mathematical explanation</h3>
<p>Now we can discuss the same idea from the mathematical point of view. We use an example of <a href="distributions.html#distributionsNormal">normal distribution</a> and a simple model as before:
<span class="math display" id="eq:MLESimpleRegression">\[\begin{equation}
    y_t = \mu_{y} + \epsilon_t,
    \tag{3.27}
\end{equation}\]</span>
where <span class="math inline">\(\mu_{y}\)</span> is the population location parameter (the true parameter, the global mean). The typical assumption in regression context is that <span class="math inline">\(\epsilon_t \sim \mathcal{N}(0, \sigma^2)\)</span>, which means that <span class="math inline">\(y_t \sim \mathcal{N}(\mu_{y}, \sigma^2)\)</span>. We can use this assumption in order to calculate the point likelihood value for each observation based on the <a href="distributions.html#distributionsNormal">PDF of Normal distribution</a>:
<span class="math display" id="eq:MLEPointLik">\[\begin{equation}
    \mathcal{L} (\mu_{y}, \sigma^2 | y_t) = f(y_t | \mu_{y}, \sigma^2) = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp \left( -\frac{\left(y_t - \mu_{y,t} \right)^2}{2 \sigma^2} \right).
    \tag{3.28}
\end{equation}\]</span>
Very roughly, what the value <a href="likelihoodApproach.html#eq:MLEPointLik">(3.28)</a> shows is the chance that the specific observation comes from the assumed model with specified parameters (we know that in real world the data does not come from any model, but this interprertation is easier to work with). Note that the likelihood is not the same as probability, because for any continuous random variables the probability for it to be equal to any specific number is equal to zero. However, the idea of likelihood has some similarities with the probability, so we prefer to refer to it as a “chance.” The point likelihood <a href="likelihoodApproach.html#eq:MLEPointLik">(3.28)</a> is not very helpful on its own, but we can get <span class="math inline">\(T\)</span> values like that, based on our sample of data. We can then summarise it in one number, that would characterise the whole sample, given the assumed distribution, applied model and selected values of parameters:
<span class="math display" id="eq:MLEFullLik">\[\begin{equation}
    \mathcal{L} (\boldsymbol{\theta} | \mathbf{y}) = \mathcal{L} (\mu_{y}, \sigma^2 | \mathbf{y}) = \prod_{t=1}^T f(y_t | \mu_{y}, \sigma^2),
    \tag{3.29}
\end{equation}\]</span>
where <span class="math inline">\(\boldsymbol{\theta}\)</span> is the vector of all parameters in the model (in our example, it is just the two of them). We take the product of likelihoods in <a href="likelihoodApproach.html#eq:MLEFullLik">(3.29)</a> because we need to get the joint likelihood for all observations and because we can typically assume that the point likelihoods are independent of each other (for example, the value on observation <span class="math inline">\(t\)</span> will not be influenced by the value on <span class="math inline">\(t-1\)</span>). The value <a href="likelihoodApproach.html#eq:MLEFullLik">(3.29)</a> shows the summary chance that the data comes from the assumed model with specified parameters. Having this value, we can change the values of parameters of the model, getting different value of <a href="likelihoodApproach.html#eq:MLEFullLik">(3.29)</a> (as we did in the example above). Using an iterative procedure, we can get such estimates of parameters that would maximise the likelihood <a href="likelihoodApproach.html#eq:MLEFullLik">(3.29)</a>, which are called Maximum Likelihood Estimates (MLE) of parameters. However, working with the products in that formula is difficult, so typically we linearise it using natural logarithm, obtaining log-likelihood:
<span class="math display" id="eq:MLEFullLogLik">\[\begin{equation}
    \ell (\boldsymbol{\theta} | \mathbf{y}) = \log \mathcal{L} (\boldsymbol{\theta} | \mathbf{y}) = -\frac{T}{2} \log(2 \pi \sigma^2) -\sum_{t=1}^T \frac{\left(y_t - \mu_{y,t} \right)^2}{2 \sigma^2} .
    \tag{3.30}
\end{equation}\]</span>
Based on that, we can find some of parameters of the model analytically. For example, we can take derivative of <a href="likelihoodApproach.html#eq:MLEFullLogLik">(3.30)</a> with respect to the scale <span class="math inline">\(\hat{\sigma}^2\)</span> (which is an estimate of the true parameter <span class="math inline">\(\sigma^2\)</span>) and equate it to zero in order to find the value that maximises the log-likelihood function in our sample:
<span class="math display" id="eq:MLEFullLogLikScale01">\[\begin{equation}
    \frac{d \ell (\boldsymbol{\theta} | \mathbf{y})}{d \hat{\sigma}^2} = -\frac{T}{2} \frac{1}{\hat{\sigma}^2} + \frac{1}{2 \hat{\sigma}^4}\sum_{t=1}^T \left(y_t - \mu_{y,t} \right)^2 =0 , 
    \tag{3.31}
\end{equation}\]</span>
which after multiplication of both sides by <span class="math inline">\(2 \hat{\sigma}^4\)</span> leads to:
<span class="math display" id="eq:MLEFullLogLikScale02">\[\begin{equation}
    T \hat{\sigma}^2 = \sum_{t=1}^T \left(y_t - \mu_{y,t} \right)^2 , 
    \tag{3.32}
\end{equation}\]</span>
or
<span class="math display" id="eq:MLEFullLogLikScale">\[\begin{equation}
    \hat{\sigma}^2 = \frac{1}{T}\sum_{t=1}^T \left(y_t - \mu_{y,t} \right)^2 .
    \tag{3.33}
\end{equation}\]</span>
The value <a href="likelihoodApproach.html#eq:MLEFullLogLikScale">(3.33)</a> is in fact a <a href="errorMeasures.html#errorMeasures">Mean Squared Error</a> (MSE) of the model. If we calculate the value of <span class="math inline">\(\hat{\sigma}^2\)</span> using the formula <a href="likelihoodApproach.html#eq:MLEFullLogLikScale">(3.33)</a>, we will maximise the likelihood with respect to the scale parameter. In fact, we can insert <a href="likelihoodApproach.html#eq:MLEFullLogLikScale">(3.33)</a> in <a href="likelihoodApproach.html#eq:MLEFullLogLik">(3.30)</a> in order to obtain the so called concentrated (or profile) log-likelihood for the normal distribution:
<span class="math display" id="eq:MLEFullLogLikConcentrated">\[\begin{equation}
    \ell^* (\boldsymbol{\theta}, \hat{\sigma}^2 | \mathbf{y}) = -\frac{T}{2}\left( \log(2 \pi e) + \log \hat{\sigma}^2 \right) .
    \tag{3.34}
\end{equation}\]</span>
This function is useful because it simplifies some calculations and also demonstrates the condition, for which the likelihood is maximised: the first part on the right hand side of the formula does not depend on the parameters of the model, it is only the <span class="math inline">\(\log \hat{\sigma}^2\)</span> that does. So, the maximum of the concentrated log-likelihood <a href="likelihoodApproach.html#eq:MLEFullLogLikConcentrated">(3.34)</a> is obtained, when <span class="math inline">\(\hat{\sigma}^2\)</span> is minimised, implying the minimisation of MSE, which is the mechanism behind the “Ordinary Least Squares” (OLS)
) estimation method. By doing this, we have just demonstrated that if we assume normality in the model, then the estimates of its parameters obtained via the maximisation of the likelihood coincide with the values obtained from OLS. So, why bother with MLE, when we have OLS?</p>
<p>First, the finding above holds for normal distribution only. If we assume a different <a href="distributions.html#distributions">distribution</a>, we would get different estimates of parameters. In some cases, it might not be possible or reasonable to use OLS, but MLE would be a plausible option (for example, logistic, Poisson and any other non-standard model).</p>
<p>Second, the MLE of parameters have good statistical properties: they are <a href="estimatesProperties.html#estimatesPropertiesConsistency">consistent</a> and <a href="estimatesProperties.html#estimatesPropertiesEfficiency">efficient</a>. These properties hold almost universally for many likelihoods under very mild conditions. Note that the MLE of parameters are not necessarily <a href="estimatesProperties.html#estimatesPropertiesBias">unbiased</a>, but after estimating the model, one can de-bias some of them (for example, calculate the standard deviation of the error via devision of the sum of squared errors by the number of degrees of freedom <span class="math inline">\(T-k\)</span> instead of <span class="math inline">\(T\)</span>).</p>
<p>Third, likelihood can be used for the model assessment, even when the standard statistics, such as <span class="math inline">\(R^2\)</span> or F-test are not available. We do not discuss these aspects in this textbook.</p>
<p>Finally, it permits the <a href="modelSelection.html#modelSelection">model selection</a> via information criteria. In general, this is not possible to do unless you assume a distribution and maximise the respective likelihood. In some statistical literature, you can notice that information criteria are calculated for the models estimated via OLS, but what the authors of such resources do not tell you is that there is still an assumption of normality behind this (see the link between OLS and MLE of Normal distribution above).</p>
<p>Note that the likelihood approach assumes that all parameters of the model are estimated, including location, scale, shape, shift etc of distribution. So typically it has more parameters to estimate than, for example, the OLS does. This is discussed in some detail later in the <a href="statisticsNumberOfParameters.html#statisticsNumberOfParameters">next section</a>.</p>
</div>
</div>

            </section>

          </div>
        </div>
      </div>
<a href="regression-uncertainty.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="statisticsNumberOfParameters.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/config-i1/adam/tree/master/Chapters//03-regression.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["adam.pdf", "adam.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
