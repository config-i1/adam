<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3.6 Statistical models assumptions | Forecasting and Analytics with ADAM</title>
  <meta name="description" content="This textbook explains how to do time series analysis and forecasting using Augmented Dynamic Adaptive Model, implemented in smooth package for R." />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="3.6 Statistical models assumptions | Forecasting and Analytics with ADAM" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This textbook explains how to do time series analysis and forecasting using Augmented Dynamic Adaptive Model, implemented in smooth package for R." />
  <meta name="github-repo" content="config-i1/adam" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3.6 Statistical models assumptions | Forecasting and Analytics with ADAM" />
  
  <meta name="twitter:description" content="This textbook explains how to do time series analysis and forecasting using Augmented Dynamic Adaptive Model, implemented in smooth package for R." />
  

<meta name="author" content="Ivan Svetunkov" />


<meta name="date" content="2021-07-07" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="variablesTransformations.html"/>
<link rel="next" href="likelihoodApproach.html"/>
<script src="libs/header-attrs-2.9/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/bsTable-3.3.7/bootstrapTable.min.css" rel="stylesheet" />
<script src="libs/bsTable-3.3.7/bootstrapTable.js"></script>
<script async defer src="https://hypothes.is/embed.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-XH37Z8VYP8"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-XH37Z8VYP8');
</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Forecasting and Analytics with ADAM</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i>License</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#what-is-adam"><i class="fa fa-check"></i>What is ADAM?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgments"><i class="fa fa-check"></i>Acknowledgments</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="modelsMethods.html"><a href="modelsMethods.html"><i class="fa fa-check"></i><b>1.1</b> Models, methods et al.Â </a></li>
<li class="chapter" data-level="1.2" data-path="scales.html"><a href="scales.html"><i class="fa fa-check"></i><b>1.2</b> Scales of information</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="scales.html"><a href="scales.html#nominal-scale"><i class="fa fa-check"></i><b>1.2.1</b> Nominal scale</a></li>
<li class="chapter" data-level="1.2.2" data-path="scales.html"><a href="scales.html#ordinal-scale"><i class="fa fa-check"></i><b>1.2.2</b> Ordinal scale</a></li>
<li class="chapter" data-level="1.2.3" data-path="scales.html"><a href="scales.html#interval-scale"><i class="fa fa-check"></i><b>1.2.3</b> Interval scale</a></li>
<li class="chapter" data-level="1.2.4" data-path="scales.html"><a href="scales.html#ratio-scale"><i class="fa fa-check"></i><b>1.2.4</b> Ratio scale</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="statistics.html"><a href="statistics.html"><i class="fa fa-check"></i><b>2</b> Introduction to statistics</a>
<ul>
<li class="chapter" data-level="2.1" data-path="dataAnalysis.html"><a href="dataAnalysis.html"><i class="fa fa-check"></i><b>2.1</b> Preliminary data analysis</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="dataAnalysis.html"><a href="dataAnalysis.html#numerical-analysis"><i class="fa fa-check"></i><b>2.1.1</b> Numerical analysis</a></li>
<li class="chapter" data-level="2.1.2" data-path="dataAnalysis.html"><a href="dataAnalysis.html#dataAnalysisGraphical"><i class="fa fa-check"></i><b>2.1.2</b> Graphical analysis</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="LLNandCLT.html"><a href="LLNandCLT.html"><i class="fa fa-check"></i><b>2.2</b> Law of Large Numbers and Central Limit Theorem</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="LLNandCLT.html"><a href="LLNandCLT.html#LLN"><i class="fa fa-check"></i><b>2.2.1</b> Law of Large Numbers</a></li>
<li class="chapter" data-level="2.2.2" data-path="LLNandCLT.html"><a href="LLNandCLT.html#CLT"><i class="fa fa-check"></i><b>2.2.2</b> Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="estimatesProperties.html"><a href="estimatesProperties.html"><i class="fa fa-check"></i><b>2.3</b> Properties of estimators</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="estimatesProperties.html"><a href="estimatesProperties.html#estimatesPropertiesBias"><i class="fa fa-check"></i><b>2.3.1</b> Bias</a></li>
<li class="chapter" data-level="2.3.2" data-path="estimatesProperties.html"><a href="estimatesProperties.html#estimatesPropertiesEfficiency"><i class="fa fa-check"></i><b>2.3.2</b> Efficiency</a></li>
<li class="chapter" data-level="2.3.3" data-path="estimatesProperties.html"><a href="estimatesProperties.html#estimatesPropertiesConsistency"><i class="fa fa-check"></i><b>2.3.3</b> Consistency</a></li>
<li class="chapter" data-level="2.3.4" data-path="estimatesProperties.html"><a href="estimatesProperties.html#asymptoticNormality"><i class="fa fa-check"></i><b>2.3.4</b> Asymptotic normality</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="confidenceIntervals.html"><a href="confidenceIntervals.html"><i class="fa fa-check"></i><b>2.4</b> Confidence and prediction intervals</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="confidenceIntervals.html"><a href="confidenceIntervals.html#confidence-interval"><i class="fa fa-check"></i><b>2.4.1</b> Confidence interval</a></li>
<li class="chapter" data-level="2.4.2" data-path="confidenceIntervals.html"><a href="confidenceIntervals.html#confidenceIntervalsPrediction"><i class="fa fa-check"></i><b>2.4.2</b> Prediction interval</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="hypothesisTesting.html"><a href="hypothesisTesting.html"><i class="fa fa-check"></i><b>2.5</b> Hypothesis testing</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="hypothesisTesting.html"><a href="hypothesisTesting.html#hypothesisTestingMistakes"><i class="fa fa-check"></i><b>2.5.1</b> Common mistakes related to hypothesis testing</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="correlations.html"><a href="correlations.html"><i class="fa fa-check"></i><b>2.6</b> Correlation and measures of association</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="correlations.html"><a href="correlations.html#nominal-scale-1"><i class="fa fa-check"></i><b>2.6.1</b> Nominal scale</a></li>
<li class="chapter" data-level="2.6.2" data-path="correlations.html"><a href="correlations.html#ordinal-scale-1"><i class="fa fa-check"></i><b>2.6.2</b> Ordinal scale</a></li>
<li class="chapter" data-level="2.6.3" data-path="correlations.html"><a href="correlations.html#correlationCoefficient"><i class="fa fa-check"></i><b>2.6.3</b> Numerical scale</a></li>
<li class="chapter" data-level="2.6.4" data-path="correlations.html"><a href="correlations.html#correlationsMixed"><i class="fa fa-check"></i><b>2.6.4</b> Mixed scales</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="distributions.html"><a href="distributions.html"><i class="fa fa-check"></i><b>2.7</b> Theory of distributions</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="distributions.html"><a href="distributions.html#distributionsNormal"><i class="fa fa-check"></i><b>2.7.1</b> Normal distribution</a></li>
<li class="chapter" data-level="2.7.2" data-path="distributions.html"><a href="distributions.html#distributionsLaplace"><i class="fa fa-check"></i><b>2.7.2</b> Laplace distribution</a></li>
<li class="chapter" data-level="2.7.3" data-path="distributions.html"><a href="distributions.html#s-distribution"><i class="fa fa-check"></i><b>2.7.3</b> S distribution</a></li>
<li class="chapter" data-level="2.7.4" data-path="distributions.html"><a href="distributions.html#distributionsGeneralisedNormal"><i class="fa fa-check"></i><b>2.7.4</b> Generalised Normal distribution</a></li>
<li class="chapter" data-level="2.7.5" data-path="distributions.html"><a href="distributions.html#distributionsALaplace"><i class="fa fa-check"></i><b>2.7.5</b> Asymmetric Laplace distribution</a></li>
<li class="chapter" data-level="2.7.6" data-path="distributions.html"><a href="distributions.html#log-normal-log-laplace-log-s-and-log-gn-distributions"><i class="fa fa-check"></i><b>2.7.6</b> Log Normal, Log Laplace, Log S and Log GN distributions</a></li>
<li class="chapter" data-level="2.7.7" data-path="distributions.html"><a href="distributions.html#IGDistribution"><i class="fa fa-check"></i><b>2.7.7</b> Inverse Gaussian distribution</a></li>
<li class="chapter" data-level="2.7.8" data-path="distributions.html"><a href="distributions.html#GammaDistribution"><i class="fa fa-check"></i><b>2.7.8</b> Gamma distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="regression.html"><a href="regression.html"><i class="fa fa-check"></i><b>3</b> Regression analysis</a>
<ul>
<li class="chapter" data-level="3.1" data-path="simpleLinearRegression.html"><a href="simpleLinearRegression.html"><i class="fa fa-check"></i><b>3.1</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="simpleLinearRegression.html"><a href="simpleLinearRegression.html#OLS"><i class="fa fa-check"></i><b>3.1.1</b> Ordinary Least Squares (OLS)</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="linearRegression.html"><a href="linearRegression.html"><i class="fa fa-check"></i><b>3.2</b> Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="linearRegression.html"><a href="linearRegression.html#ols-estimation"><i class="fa fa-check"></i><b>3.2.1</b> OLS estimation</a></li>
<li class="chapter" data-level="3.2.2" data-path="linearRegression.html"><a href="linearRegression.html#linearRegressionQualityOfFit"><i class="fa fa-check"></i><b>3.2.2</b> Quality of a fit</a></li>
<li class="chapter" data-level="3.2.3" data-path="linearRegression.html"><a href="linearRegression.html#interpretation-of-parameters"><i class="fa fa-check"></i><b>3.2.3</b> Interpretation of parameters</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="regression-uncertainty.html"><a href="regression-uncertainty.html"><i class="fa fa-check"></i><b>3.3</b> Regression uncertainty</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="regression-uncertainty.html"><a href="regression-uncertainty.html#confidence-intervals"><i class="fa fa-check"></i><b>3.3.1</b> Confidence intervals</a></li>
<li class="chapter" data-level="3.3.2" data-path="regression-uncertainty.html"><a href="regression-uncertainty.html#hypothesis-testing"><i class="fa fa-check"></i><b>3.3.2</b> Hypothesis testing</a></li>
<li class="chapter" data-level="3.3.3" data-path="regression-uncertainty.html"><a href="regression-uncertainty.html#regression-model-uncertainty"><i class="fa fa-check"></i><b>3.3.3</b> Regression model uncertainty</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="dummyVariables.html"><a href="dummyVariables.html"><i class="fa fa-check"></i><b>3.4</b> Regression with categorical variables</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="dummyVariables.html"><a href="dummyVariables.html#categorical-variables-for-the-slope"><i class="fa fa-check"></i><b>3.4.1</b> Categorical variables for the slope</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="variablesTransformations.html"><a href="variablesTransformations.html"><i class="fa fa-check"></i><b>3.5</b> Variables transformations</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="variablesTransformations.html"><a href="variablesTransformations.html#types-of-variables-transformations"><i class="fa fa-check"></i><b>3.5.1</b> Types of variables transformations</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="assumptions.html"><a href="assumptions.html"><i class="fa fa-check"></i><b>3.6</b> Statistical models assumptions</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="assumptions.html"><a href="assumptions.html#assumptionsCorrectModel"><i class="fa fa-check"></i><b>3.6.1</b> Model is correctly specified</a></li>
<li class="chapter" data-level="3.6.2" data-path="assumptions.html"><a href="assumptions.html#assumptionsResidualsAreIID"><i class="fa fa-check"></i><b>3.6.2</b> Residuals are i.i.d.</a></li>
<li class="chapter" data-level="3.6.3" data-path="assumptions.html"><a href="assumptions.html#assumptionsXreg"><i class="fa fa-check"></i><b>3.6.3</b> The explanatory variables are not correlated with anything but the response variable</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="likelihoodApproach.html"><a href="likelihoodApproach.html"><i class="fa fa-check"></i><b>3.7</b> Likelihood Approach</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="likelihoodApproach.html"><a href="likelihoodApproach.html#an-example-in-r"><i class="fa fa-check"></i><b>3.7.1</b> An example in R</a></li>
<li class="chapter" data-level="3.7.2" data-path="likelihoodApproach.html"><a href="likelihoodApproach.html#likelihoodApproachMaths"><i class="fa fa-check"></i><b>3.7.2</b> Mathematical explanation</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="statisticsNumberOfParameters.html"><a href="statisticsNumberOfParameters.html"><i class="fa fa-check"></i><b>3.8</b> Calculating number of parameters in models</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="regressionModelBuilding.html"><a href="regressionModelBuilding.html"><i class="fa fa-check"></i><b>4</b> Regression model building</a>
<ul>
<li class="chapter" data-level="4.1" data-path="modelSelection.html"><a href="modelSelection.html"><i class="fa fa-check"></i><b>4.1</b> Model selection mechanism</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="modelSelection.html"><a href="modelSelection.html#informationCriteria"><i class="fa fa-check"></i><b>4.1.1</b> Information criteria idea</a></li>
<li class="chapter" data-level="4.1.2" data-path="modelSelection.html"><a href="modelSelection.html#informationCriteriaMistakes"><i class="fa fa-check"></i><b>4.1.2</b> Common confusions related to information criteria</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="forecastingProcess.html"><a href="forecastingProcess.html"><i class="fa fa-check"></i><b>5</b> Forecasts evaluation</a>
<ul>
<li class="chapter" data-level="5.1" data-path="errorMeasures.html"><a href="errorMeasures.html"><i class="fa fa-check"></i><b>5.1</b> Measuring accuracy of point forecasts</a></li>
<li class="chapter" data-level="5.2" data-path="uncertainty.html"><a href="uncertainty.html"><i class="fa fa-check"></i><b>5.2</b> Measuring uncertainty</a></li>
<li class="chapter" data-level="5.3" data-path="rollingOrigin.html"><a href="rollingOrigin.html"><i class="fa fa-check"></i><b>5.3</b> Rolling origin</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="rollingOrigin.html"><a href="rollingOrigin.html#principles-of-rolling-origin"><i class="fa fa-check"></i><b>5.3.1</b> Principles of Rolling origin</a></li>
<li class="chapter" data-level="5.3.2" data-path="rollingOrigin.html"><a href="rollingOrigin.html#rolling-origin-in-r"><i class="fa fa-check"></i><b>5.3.2</b> Rolling origin in R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="tsDecomposition.html"><a href="tsDecomposition.html"><i class="fa fa-check"></i><b>6</b> From time series components to ETS</a>
<ul>
<li class="chapter" data-level="6.1" data-path="tsComponents.html"><a href="tsComponents.html"><i class="fa fa-check"></i><b>6.1</b> Time series components</a></li>
<li class="chapter" data-level="6.2" data-path="ClassicalDecomposition.html"><a href="ClassicalDecomposition.html"><i class="fa fa-check"></i><b>6.2</b> Classical Seasonal Decomposition</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="ClassicalDecomposition.html"><a href="ClassicalDecomposition.html#how-to-do"><i class="fa fa-check"></i><b>6.2.1</b> How to do?</a></li>
<li class="chapter" data-level="6.2.2" data-path="ClassicalDecomposition.html"><a href="ClassicalDecomposition.html#a-couple-of-examples"><i class="fa fa-check"></i><b>6.2.2</b> A couple of examples</a></li>
<li class="chapter" data-level="6.2.3" data-path="ClassicalDecomposition.html"><a href="ClassicalDecomposition.html#other-techniques"><i class="fa fa-check"></i><b>6.2.3</b> Other techniques</a></li>
<li class="chapter" data-level="6.2.4" data-path="ClassicalDecomposition.html"><a href="ClassicalDecomposition.html#why-bother"><i class="fa fa-check"></i><b>6.2.4</b> âWhy bother?â</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="ETSTaxonomy.html"><a href="ETSTaxonomy.html"><i class="fa fa-check"></i><b>6.3</b> ETS taxonomy</a></li>
<li class="chapter" data-level="6.4" data-path="ETSTaxonomyMaths.html"><a href="ETSTaxonomyMaths.html"><i class="fa fa-check"></i><b>6.4</b> Mathematical models in the ETS taxonomy</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="conventional-exponential-smoothing.html"><a href="conventional-exponential-smoothing.html"><i class="fa fa-check"></i><b>7</b> Conventional Exponential Smoothing</a>
<ul>
<li class="chapter" data-level="7.1" data-path="SES.html"><a href="SES.html"><i class="fa fa-check"></i><b>7.1</b> Simple Exponential Smoothing</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="SES.html"><a href="SES.html#examples-of-application"><i class="fa fa-check"></i><b>7.1.1</b> Examples of application</a></li>
<li class="chapter" data-level="7.1.2" data-path="SES.html"><a href="SES.html#whyExponential"><i class="fa fa-check"></i><b>7.1.2</b> Why âexponential?â</a></li>
<li class="chapter" data-level="7.1.3" data-path="SES.html"><a href="SES.html#error-correction-form-of-ses"><i class="fa fa-check"></i><b>7.1.3</b> Error correction form of SES</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="SESandETS.html"><a href="SESandETS.html"><i class="fa fa-check"></i><b>7.2</b> SES and ETS</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="SESandETS.html"><a href="SESandETS.html#etsann"><i class="fa fa-check"></i><b>7.2.1</b> ETS(A,N,N)</a></li>
<li class="chapter" data-level="7.2.2" data-path="SESandETS.html"><a href="SESandETS.html#etsmnn"><i class="fa fa-check"></i><b>7.2.2</b> ETS(M,N,N)</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="ETSExamples.html"><a href="ETSExamples.html"><i class="fa fa-check"></i><b>7.3</b> Several examples of exponential smoothing methods and ETS</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="ETSExamples.html"><a href="ETSExamples.html#ETSAAN"><i class="fa fa-check"></i><b>7.3.1</b> ETS(A,A,N)</a></li>
<li class="chapter" data-level="7.3.2" data-path="ETSExamples.html"><a href="ETSExamples.html#ETSAAdN"><i class="fa fa-check"></i><b>7.3.2</b> ETS(A,Ad,N)</a></li>
<li class="chapter" data-level="7.3.3" data-path="ETSExamples.html"><a href="ETSExamples.html#etsaam"><i class="fa fa-check"></i><b>7.3.3</b> ETS(A,A,M)</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="ets-assumptions-estimation-and-selection.html"><a href="ets-assumptions-estimation-and-selection.html"><i class="fa fa-check"></i><b>7.4</b> ETS assumptions, estimation and selection</a></li>
<li class="chapter" data-level="7.5" data-path="state-space-form-of-ets.html"><a href="state-space-form-of-ets.html"><i class="fa fa-check"></i><b>7.5</b> State space form of ETS</a></li>
<li class="chapter" data-level="7.6" data-path="ETSParametersBounds.html"><a href="ETSParametersBounds.html"><i class="fa fa-check"></i><b>7.6</b> Parameters bounds</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="ADAMETSIntroduction.html"><a href="ADAMETSIntroduction.html"><i class="fa fa-check"></i><b>8</b> Pure additive ADAM ETS</a>
<ul>
<li class="chapter" data-level="8.1" data-path="ADAMETSPureAdditive.html"><a href="ADAMETSPureAdditive.html"><i class="fa fa-check"></i><b>8.1</b> Model formulation</a></li>
<li class="chapter" data-level="8.2" data-path="adamETSPureAdditiveRecursive.html"><a href="adamETSPureAdditiveRecursive.html"><i class="fa fa-check"></i><b>8.2</b> Recursive relation</a></li>
<li class="chapter" data-level="8.3" data-path="pureAdditiveExpectationAndVariance.html"><a href="pureAdditiveExpectationAndVariance.html"><i class="fa fa-check"></i><b>8.3</b> Conditional expectation and variance</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="pureAdditiveExpectationAndVariance.html"><a href="pureAdditiveExpectationAndVariance.html#example-with-etsann"><i class="fa fa-check"></i><b>8.3.1</b> Example with ETS(A,N,N)</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="stabilityConditionAdditiveError.html"><a href="stabilityConditionAdditiveError.html"><i class="fa fa-check"></i><b>8.4</b> Stability and forecastability conditions</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="stabilityConditionAdditiveError.html"><a href="stabilityConditionAdditiveError.html#example-with-etsann-1"><i class="fa fa-check"></i><b>8.4.1</b> Example with ETS(A,N,N)</a></li>
<li class="chapter" data-level="8.4.2" data-path="stabilityConditionAdditiveError.html"><a href="stabilityConditionAdditiveError.html#comming-back-to-the-general-case"><i class="fa fa-check"></i><b>8.4.2</b> Comming back to the general case</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="ADAMETSAdditiveDistributions.html"><a href="ADAMETSAdditiveDistributions.html"><i class="fa fa-check"></i><b>8.5</b> Distributional assumptions in pure additive ETS</a></li>
<li class="chapter" data-level="8.6" data-path="ADAMETSPureAdditiveExamples.html"><a href="ADAMETSPureAdditiveExamples.html"><i class="fa fa-check"></i><b>8.6</b> Examples of application</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="ADAMETSPureAdditiveExamples.html"><a href="ADAMETSPureAdditiveExamples.html#non-seasonal-data"><i class="fa fa-check"></i><b>8.6.1</b> Non-seasonal data</a></li>
<li class="chapter" data-level="8.6.2" data-path="ADAMETSPureAdditiveExamples.html"><a href="ADAMETSPureAdditiveExamples.html#ADAMETSPureAdditiveExamplesETSAAA"><i class="fa fa-check"></i><b>8.6.2</b> Seasonal data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ADAMETSPureMultiplicative.html"><a href="ADAMETSPureMultiplicative.html"><i class="fa fa-check"></i><b>9</b> Pure multiplicative ADAM ETS</a>
<ul>
<li class="chapter" data-level="9.1" data-path="adamETSPuremultiplicativeRecursive.html"><a href="adamETSPuremultiplicativeRecursive.html"><i class="fa fa-check"></i><b>9.1</b> Recursive relation</a></li>
<li class="chapter" data-level="9.2" data-path="pureMultiplicativeExpectationAndVariance.html"><a href="pureMultiplicativeExpectationAndVariance.html"><i class="fa fa-check"></i><b>9.2</b> The problem with moments in pure multiplicative ETS</a></li>
<li class="chapter" data-level="9.3" data-path="stabilityConditionMultiplicativeError.html"><a href="stabilityConditionMultiplicativeError.html"><i class="fa fa-check"></i><b>9.3</b> Smoothing parameters bounds</a></li>
<li class="chapter" data-level="9.4" data-path="ADAMETSMultiplicativeDistributions.html"><a href="ADAMETSMultiplicativeDistributions.html"><i class="fa fa-check"></i><b>9.4</b> Distributional assumptions in pure multiplicative ETS</a></li>
<li class="chapter" data-level="9.5" data-path="ADAMETSMultiplicativeExamples.html"><a href="ADAMETSMultiplicativeExamples.html"><i class="fa fa-check"></i><b>9.5</b> Examples of application</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="ADAMETSMultiplicativeExamples.html"><a href="ADAMETSMultiplicativeExamples.html#non-seasonal-data-1"><i class="fa fa-check"></i><b>9.5.1</b> Non-seasonal data</a></li>
<li class="chapter" data-level="9.5.2" data-path="ADAMETSMultiplicativeExamples.html"><a href="ADAMETSMultiplicativeExamples.html#seasonal-data"><i class="fa fa-check"></i><b>9.5.2</b> Seasonal data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="ADAMETSMixedModels.html"><a href="ADAMETSMixedModels.html"><i class="fa fa-check"></i><b>10</b> Further ADAM ETS topics</a>
<ul>
<li class="chapter" data-level="10.1" data-path="ADAMETSMixedModelsGroup3.html"><a href="ADAMETSMixedModelsGroup3.html"><i class="fa fa-check"></i><b>10.1</b> Mixed models with non-multiplicative trend</a></li>
<li class="chapter" data-level="10.2" data-path="ADAMETSMixedModelsGroup4.html"><a href="ADAMETSMixedModelsGroup4.html"><i class="fa fa-check"></i><b>10.2</b> Mixed models with multiplicative trend</a></li>
<li class="chapter" data-level="10.3" data-path="ADAMETSSeasonalNormalisation.html"><a href="ADAMETSSeasonalNormalisation.html"><i class="fa fa-check"></i><b>10.3</b> Normalisation of seasonal indices in ETS models</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="ARIMA.html"><a href="ARIMA.html"><i class="fa fa-check"></i><b>11</b> Conventional ARIMA</a>
<ul>
<li class="chapter" data-level="11.1" data-path="ARIMAIntro.html"><a href="ARIMAIntro.html"><i class="fa fa-check"></i><b>11.1</b> Introduction to ARIMA</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="ARIMAIntro.html"><a href="ARIMAIntro.html#AR"><i class="fa fa-check"></i><b>11.1.1</b> AR(p)</a></li>
<li class="chapter" data-level="11.1.2" data-path="ARIMAIntro.html"><a href="ARIMAIntro.html#MA"><i class="fa fa-check"></i><b>11.1.2</b> MA(q)</a></li>
<li class="chapter" data-level="11.1.3" data-path="ARIMAIntro.html"><a href="ARIMAIntro.html#ARMA"><i class="fa fa-check"></i><b>11.1.3</b> ARMA(p,q)</a></li>
<li class="chapter" data-level="11.1.4" data-path="ARIMAIntro.html"><a href="ARIMAIntro.html#ARMAConstant"><i class="fa fa-check"></i><b>11.1.4</b> ARMA with constant</a></li>
<li class="chapter" data-level="11.1.5" data-path="ARIMAIntro.html"><a href="ARIMAIntro.html#Differences"><i class="fa fa-check"></i><b>11.1.5</b> I(d)</a></li>
<li class="chapter" data-level="11.1.6" data-path="ARIMAIntro.html"><a href="ARIMAIntro.html#arimapdq"><i class="fa fa-check"></i><b>11.1.6</b> ARIMA(p,d,q)</a></li>
<li class="chapter" data-level="11.1.7" data-path="ARIMAIntro.html"><a href="ARIMAIntro.html#ARIMABounds"><i class="fa fa-check"></i><b>11.1.7</b> Parameters bounds</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="seasonal-arima.html"><a href="seasonal-arima.html"><i class="fa fa-check"></i><b>11.2</b> Seasonal ARIMA</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="seasonal-arima.html"><a href="seasonal-arima.html#single-seasonal-arima"><i class="fa fa-check"></i><b>11.2.1</b> Single seasonal ARIMA</a></li>
<li class="chapter" data-level="11.2.2" data-path="seasonal-arima.html"><a href="seasonal-arima.html#sarima-with-constant"><i class="fa fa-check"></i><b>11.2.2</b> SARIMA with constant</a></li>
<li class="chapter" data-level="11.2.3" data-path="seasonal-arima.html"><a href="seasonal-arima.html#MSARIMA"><i class="fa fa-check"></i><b>11.2.3</b> Multiple seasonal ARIMA</a></li>
<li class="chapter" data-level="11.2.4" data-path="seasonal-arima.html"><a href="seasonal-arima.html#MSARIMABounds"><i class="fa fa-check"></i><b>11.2.4</b> Parameters bounds for MSARIMA</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="BJApproach.html"><a href="BJApproach.html"><i class="fa fa-check"></i><b>11.3</b> Box-Jenkins approach</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="BJApproach.html"><a href="BJApproach.html#identifying-stationarity"><i class="fa fa-check"></i><b>11.3.1</b> Identifying stationarity</a></li>
<li class="chapter" data-level="11.3.2" data-path="BJApproach.html"><a href="BJApproach.html#ACF"><i class="fa fa-check"></i><b>11.3.2</b> Autocorrelation function (ACF)</a></li>
<li class="chapter" data-level="11.3.3" data-path="BJApproach.html"><a href="BJApproach.html#PACF"><i class="fa fa-check"></i><b>11.3.3</b> Partial autocorrelation function (PACF)</a></li>
<li class="chapter" data-level="11.3.4" data-path="BJApproach.html"><a href="BJApproach.html#BJApproachSummary"><i class="fa fa-check"></i><b>11.3.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="ARIMAandETS.html"><a href="ARIMAandETS.html"><i class="fa fa-check"></i><b>11.4</b> ARIMA and ETS</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="ARIMAandETS.html"><a href="ARIMAandETS.html#ARIMAETS011"><i class="fa fa-check"></i><b>11.4.1</b> ARIMA(0,1,1) and ETS(A,N,N)</a></li>
<li class="chapter" data-level="11.4.2" data-path="ARIMAandETS.html"><a href="ARIMAandETS.html#ARIMAETS022"><i class="fa fa-check"></i><b>11.4.2</b> ARIMA(0,2,2) and ETS(A,A,N)</a></li>
<li class="chapter" data-level="11.4.3" data-path="ARIMAandETS.html"><a href="ARIMAandETS.html#ARIMAETS112"><i class="fa fa-check"></i><b>11.4.3</b> ARIMA(1,1,2) and ETS(A,Ad,N)</a></li>
<li class="chapter" data-level="11.4.4" data-path="ARIMAandETS.html"><a href="ARIMAandETS.html#arima-and-other-ets-models"><i class="fa fa-check"></i><b>11.4.4</b> ARIMA and other ETS models</a></li>
<li class="chapter" data-level="11.4.5" data-path="ARIMAandETS.html"><a href="ARIMAandETS.html#ets-arima"><i class="fa fa-check"></i><b>11.4.5</b> ETS + ARIMA</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="ARIMAExampleInR.html"><a href="ARIMAExampleInR.html"><i class="fa fa-check"></i><b>11.5</b> Examples of application</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="ARIMAExampleInR.html"><a href="ARIMAExampleInR.html#non-seasonal-data-2"><i class="fa fa-check"></i><b>11.5.1</b> Non-seasonal data</a></li>
<li class="chapter" data-level="11.5.2" data-path="ARIMAExampleInR.html"><a href="ARIMAExampleInR.html#ARIMAExampleInRSeasonal"><i class="fa fa-check"></i><b>11.5.2</b> Seasonal data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="ADAMARIMA.html"><a href="ADAMARIMA.html"><i class="fa fa-check"></i><b>12</b> ADAM ARIMA</a>
<ul>
<li class="chapter" data-level="12.1" data-path="StateSpaceARIMA.html"><a href="StateSpaceARIMA.html"><i class="fa fa-check"></i><b>12.1</b> State space ARIMA</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="StateSpaceARIMA.html"><a href="StateSpaceARIMA.html#StateSpaceARIMAAdditive"><i class="fa fa-check"></i><b>12.1.1</b> Additive ARIMA</a></li>
<li class="chapter" data-level="12.1.2" data-path="StateSpaceARIMA.html"><a href="StateSpaceARIMA.html#an-example"><i class="fa fa-check"></i><b>12.1.2</b> An example</a></li>
<li class="chapter" data-level="12.1.3" data-path="StateSpaceARIMA.html"><a href="StateSpaceARIMA.html#state-space-arima-with-constant"><i class="fa fa-check"></i><b>12.1.3</b> State space ARIMA with constant</a></li>
<li class="chapter" data-level="12.1.4" data-path="StateSpaceARIMA.html"><a href="StateSpaceARIMA.html#ADAMARIMAPureMultiplicative"><i class="fa fa-check"></i><b>12.1.4</b> Multiplicative ARIMA</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="ADAMARIMARecursive.html"><a href="ADAMARIMARecursive.html"><i class="fa fa-check"></i><b>12.2</b> Recursive relation</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="ADAMARIMARecursive.html"><a href="ADAMARIMARecursive.html#moments-of-adam-arima"><i class="fa fa-check"></i><b>12.2.1</b> Moments of ADAM ARIMA</a></li>
<li class="chapter" data-level="12.2.2" data-path="ADAMARIMARecursive.html"><a href="ADAMARIMARecursive.html#parameters-bounds"><i class="fa fa-check"></i><b>12.2.2</b> Parameters bounds</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="ADAMARIMADistributions.html"><a href="ADAMARIMADistributions.html"><i class="fa fa-check"></i><b>12.3</b> Distributional assumptions of ADAM ARIMA</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="ADAMARIMADistributions.html"><a href="ADAMARIMADistributions.html#conditional-distributions"><i class="fa fa-check"></i><b>12.3.1</b> Conditional distributions</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="ets-arima-1.html"><a href="ets-arima-1.html"><i class="fa fa-check"></i><b>12.4</b> ETS + ARIMA</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="ets-arima-1.html"><a href="ets-arima-1.html#pure-additive-models"><i class="fa fa-check"></i><b>12.4.1</b> Pure additive models</a></li>
<li class="chapter" data-level="12.4.2" data-path="ets-arima-1.html"><a href="ets-arima-1.html#pure-multiplicative-models"><i class="fa fa-check"></i><b>12.4.2</b> Pure multiplicative models</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="ADAMARIMAExamples.html"><a href="ADAMARIMAExamples.html"><i class="fa fa-check"></i><b>12.5</b> Examples of application</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="ADAMX.html"><a href="ADAMX.html"><i class="fa fa-check"></i><b>13</b> Explanatory variables in ADAM</a>
<ul>
<li class="chapter" data-level="13.1" data-path="adamx-model-formulation.html"><a href="adamx-model-formulation.html"><i class="fa fa-check"></i><b>13.1</b> ADAMX: Model formulation</a></li>
<li class="chapter" data-level="13.2" data-path="ADAMXConventionalConditionalMoments.html"><a href="ADAMXConventionalConditionalMoments.html"><i class="fa fa-check"></i><b>13.2</b> Conditional expectation and variance of ADAMX</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="ADAMXConventionalConditionalMoments.html"><a href="ADAMXConventionalConditionalMoments.html#the-adamx-with-known-explanatory-variables"><i class="fa fa-check"></i><b>13.2.1</b> The ADAMX with known explanatory variables</a></li>
<li class="chapter" data-level="13.2.2" data-path="ADAMXConventionalConditionalMoments.html"><a href="ADAMXConventionalConditionalMoments.html#adamx-with-random-explanatory-variables"><i class="fa fa-check"></i><b>13.2.2</b> ADAMX with random explanatory variables</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="ADAMXDynamic.html"><a href="ADAMXDynamic.html"><i class="fa fa-check"></i><b>13.3</b> Dynamic X in ADAMX</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="ADAMXDynamic.html"><a href="ADAMXDynamic.html#conditional-moments-of-dynamic-adamx"><i class="fa fa-check"></i><b>13.3.1</b> Conditional moments of dynamic ADAMX</a></li>
<li class="chapter" data-level="13.3.2" data-path="ADAMXDynamic.html"><a href="ADAMXDynamic.html#known-explanatory-variables"><i class="fa fa-check"></i><b>13.3.2</b> Known explanatory variables</a></li>
<li class="chapter" data-level="13.3.3" data-path="ADAMXDynamic.html"><a href="ADAMXDynamic.html#random-explanatory-variables"><i class="fa fa-check"></i><b>13.3.3</b> Random explanatory variables</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="stability-and-forecastability-conditions-of-adamx.html"><a href="stability-and-forecastability-conditions-of-adamx.html"><i class="fa fa-check"></i><b>13.4</b> Stability and forecastability conditions of ADAMX</a></li>
<li class="chapter" data-level="13.5" data-path="ETSXDynamicCategories.html"><a href="ETSXDynamicCategories.html"><i class="fa fa-check"></i><b>13.5</b> Dealing with categorical variables in ADAMX</a></li>
<li class="chapter" data-level="13.6" data-path="ETSXRExample.html"><a href="ETSXRExample.html"><i class="fa fa-check"></i><b>13.6</b> Examples of application</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="ADAMETSEstimation.html"><a href="ADAMETSEstimation.html"><i class="fa fa-check"></i><b>14</b> Estimation of ADAM models</a>
<ul>
<li class="chapter" data-level="14.1" data-path="ADAMETSEstimationLikelihood.html"><a href="ADAMETSEstimationLikelihood.html"><i class="fa fa-check"></i><b>14.1</b> Maximum Likelihood Estimation</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="ADAMETSEstimationLikelihood.html"><a href="ADAMETSEstimationLikelihood.html#an-example-in-r-1"><i class="fa fa-check"></i><b>14.1.1</b> An example in R</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="non-mle-based-loss-functions.html"><a href="non-mle-based-loss-functions.html"><i class="fa fa-check"></i><b>14.2</b> Non MLE-based loss functions</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="non-mle-based-loss-functions.html"><a href="non-mle-based-loss-functions.html#MSEandMAEEstimators"><i class="fa fa-check"></i><b>14.2.1</b> MSE and MAE</a></li>
<li class="chapter" data-level="14.2.2" data-path="non-mle-based-loss-functions.html"><a href="non-mle-based-loss-functions.html#ham"><i class="fa fa-check"></i><b>14.2.2</b> HAM</a></li>
<li class="chapter" data-level="14.2.3" data-path="non-mle-based-loss-functions.html"><a href="non-mle-based-loss-functions.html#lasso-and-ridge"><i class="fa fa-check"></i><b>14.2.3</b> LASSO and RIDGE</a></li>
<li class="chapter" data-level="14.2.4" data-path="non-mle-based-loss-functions.html"><a href="non-mle-based-loss-functions.html#custom-losses"><i class="fa fa-check"></i><b>14.2.4</b> Custom losses</a></li>
<li class="chapter" data-level="14.2.5" data-path="non-mle-based-loss-functions.html"><a href="non-mle-based-loss-functions.html#examples-in-r"><i class="fa fa-check"></i><b>14.2.5</b> Examples in R</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="multistepLosses.html"><a href="multistepLosses.html"><i class="fa fa-check"></i><b>14.3</b> Multistep losses</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="multistepLosses.html"><a href="multistepLosses.html#mathrmmse_h---mse-for-h-steps-ahead"><i class="fa fa-check"></i><b>14.3.1</b> <span class="math inline">\(\mathrm{MSE}_h\)</span> - MSE for h steps ahead</a></li>
<li class="chapter" data-level="14.3.2" data-path="multistepLosses.html"><a href="multistepLosses.html#multistepLossesTMSE"><i class="fa fa-check"></i><b>14.3.2</b> TMSE - Trace MSE</a></li>
<li class="chapter" data-level="14.3.3" data-path="multistepLosses.html"><a href="multistepLosses.html#multistepLossesGTMSE"><i class="fa fa-check"></i><b>14.3.3</b> GTMSE - Geometric Trace MSE</a></li>
<li class="chapter" data-level="14.3.4" data-path="multistepLosses.html"><a href="multistepLosses.html#msce---mean-squared-cumulative-error"><i class="fa fa-check"></i><b>14.3.4</b> MSCE - Mean Squared Cumulative Error</a></li>
<li class="chapter" data-level="14.3.5" data-path="multistepLosses.html"><a href="multistepLosses.html#gpl---general-predictive-likelihood"><i class="fa fa-check"></i><b>14.3.5</b> GPL - General Predictive Likelihood</a></li>
<li class="chapter" data-level="14.3.6" data-path="multistepLosses.html"><a href="multistepLosses.html#other-multistep-estimators"><i class="fa fa-check"></i><b>14.3.6</b> Other multistep estimators</a></li>
<li class="chapter" data-level="14.3.7" data-path="multistepLosses.html"><a href="multistepLosses.html#an-example-in-r-2"><i class="fa fa-check"></i><b>14.3.7</b> An example in R</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="ADAMInitialisation.html"><a href="ADAMInitialisation.html"><i class="fa fa-check"></i><b>14.4</b> Initialisation of ADAM</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="ADAMInitialisation.html"><a href="ADAMInitialisation.html#ADAMInitialisationOptAndBack"><i class="fa fa-check"></i><b>14.4.1</b> Optimisation vs backcasting</a></li>
<li class="chapter" data-level="14.4.2" data-path="ADAMInitialisation.html"><a href="ADAMInitialisation.html#pre-initialisation-of-adam-parameters"><i class="fa fa-check"></i><b>14.4.2</b> Pre-initialisation of ADAM parameters</a></li>
<li class="chapter" data-level="14.4.3" data-path="ADAMInitialisation.html"><a href="ADAMInitialisation.html#pre-initialisation-of-adam-states-ets"><i class="fa fa-check"></i><b>14.4.3</b> Pre-initialisation of ADAM states, ETS</a></li>
<li class="chapter" data-level="14.4.4" data-path="ADAMInitialisation.html"><a href="ADAMInitialisation.html#pre-initialisation-of-adam-states-arima"><i class="fa fa-check"></i><b>14.4.4</b> Pre-initialisation of ADAM states, ARIMA</a></li>
<li class="chapter" data-level="14.4.5" data-path="ADAMInitialisation.html"><a href="ADAMInitialisation.html#pre-initialisation-of-adam-states-regressors-and-constant"><i class="fa fa-check"></i><b>14.4.5</b> Pre-initialisation of ADAM states, Regressors and constant</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="multiple-frequencies-in-adam-ets.html"><a href="multiple-frequencies-in-adam-ets.html"><i class="fa fa-check"></i><b>15</b> Multiple frequencies in ADAM ETS</a>
<ul>
<li class="chapter" data-level="15.1" data-path="estimation-of-multiple-seasonal-model.html"><a href="estimation-of-multiple-seasonal-model.html"><i class="fa fa-check"></i><b>15.1</b> Estimation of multiple seasonal model</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="estimation-of-multiple-seasonal-model.html"><a href="estimation-of-multiple-seasonal-model.html#adam-ets-issues"><i class="fa fa-check"></i><b>15.1.1</b> ADAM ETS issues</a></li>
<li class="chapter" data-level="15.1.2" data-path="estimation-of-multiple-seasonal-model.html"><a href="estimation-of-multiple-seasonal-model.html#adam-arima-issues"><i class="fa fa-check"></i><b>15.1.2</b> ADAM ARIMA issues</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="ETSXMultipleSeasonality.html"><a href="ETSXMultipleSeasonality.html"><i class="fa fa-check"></i><b>15.2</b> Using explanatory variables for multiple seasonalities</a></li>
<li class="chapter" data-level="15.3" data-path="MultipleFrequenciesDSTandLeap.html"><a href="MultipleFrequenciesDSTandLeap.html"><i class="fa fa-check"></i><b>15.3</b> Dealing with daylight saving and leap years</a></li>
<li class="chapter" data-level="15.4" data-path="ADAMMultipleFrequenciesExamples.html"><a href="ADAMMultipleFrequenciesExamples.html"><i class="fa fa-check"></i><b>15.4</b> Examples of application</a>
<ul>
<li class="chapter" data-level="15.4.1" data-path="ADAMMultipleFrequenciesExamples.html"><a href="ADAMMultipleFrequenciesExamples.html#adam-ets"><i class="fa fa-check"></i><b>15.4.1</b> ADAM ETS</a></li>
<li class="chapter" data-level="15.4.2" data-path="ADAMMultipleFrequenciesExamples.html"><a href="ADAMMultipleFrequenciesExamples.html#adam-etsx"><i class="fa fa-check"></i><b>15.4.2</b> ADAM ETSX</a></li>
<li class="chapter" data-level="15.4.3" data-path="ADAMMultipleFrequenciesExamples.html"><a href="ADAMMultipleFrequenciesExamples.html#adam-arima"><i class="fa fa-check"></i><b>15.4.3</b> ADAM ARIMA</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="ADAMIntermittent.html"><a href="ADAMIntermittent.html"><i class="fa fa-check"></i><b>16</b> ADAM for Intermittent Demand</a>
<ul>
<li class="chapter" data-level="16.1" data-path="ADAMOccurrence.html"><a href="ADAMOccurrence.html"><i class="fa fa-check"></i><b>16.1</b> Occurrence part of the model</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="ADAMOccurrence.html"><a href="ADAMOccurrence.html#fixed-probability-model-oets_f"><i class="fa fa-check"></i><b>16.1.1</b> Fixed probability model, oETS<span class="math inline">\(_F\)</span></a></li>
<li class="chapter" data-level="16.1.2" data-path="ADAMOccurrence.html"><a href="ADAMOccurrence.html#oETSO"><i class="fa fa-check"></i><b>16.1.2</b> Odds ratio model, oETS<span class="math inline">\(_O\)</span></a></li>
<li class="chapter" data-level="16.1.3" data-path="ADAMOccurrence.html"><a href="ADAMOccurrence.html#inverse-odds-ratio-model-oets_i"><i class="fa fa-check"></i><b>16.1.3</b> Inverse odds ratio model, oETS<span class="math inline">\(_I\)</span></a></li>
<li class="chapter" data-level="16.1.4" data-path="ADAMOccurrence.html"><a href="ADAMOccurrence.html#oETSG"><i class="fa fa-check"></i><b>16.1.4</b> General oETS model, oETS<span class="math inline">\(_G\)</span></a></li>
<li class="chapter" data-level="16.1.5" data-path="ADAMOccurrence.html"><a href="ADAMOccurrence.html#direct-probability-model-oets_d"><i class="fa fa-check"></i><b>16.1.5</b> Direct probability model, oETS<span class="math inline">\(_D\)</span></a></li>
<li class="chapter" data-level="16.1.6" data-path="ADAMOccurrence.html"><a href="ADAMOccurrence.html#oETSModelSelection"><i class="fa fa-check"></i><b>16.1.6</b> Model selection in oETS</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="ADAMDemandSizes.html"><a href="ADAMDemandSizes.html"><i class="fa fa-check"></i><b>16.2</b> Demand sizes part of the model</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="ADAMDemandSizes.html"><a href="ADAMDemandSizes.html#additive-vs-multiplicative-ets-for-demand-sizes"><i class="fa fa-check"></i><b>16.2.1</b> Additive vs multiplicative ETS for demand sizes</a></li>
<li class="chapter" data-level="16.2.2" data-path="ADAMDemandSizes.html"><a href="ADAMDemandSizes.html#using-arima-for-demand-sizes"><i class="fa fa-check"></i><b>16.2.2</b> Using ARIMA for demand sizes</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="ADAMIntermittentFull.html"><a href="ADAMIntermittentFull.html"><i class="fa fa-check"></i><b>16.3</b> The full ADAM model</a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="ADAMIntermittentFull.html"><a href="ADAMIntermittentFull.html#iETSMLE"><i class="fa fa-check"></i><b>16.3.1</b> Maximum Likelihood Estimation</a></li>
<li class="chapter" data-level="16.3.2" data-path="ADAMIntermittentFull.html"><a href="ADAMIntermittentFull.html#conditional-expectation-and-variance"><i class="fa fa-check"></i><b>16.3.2</b> Conditional expectation and variance</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="examples-of-application-1.html"><a href="examples-of-application-1.html"><i class="fa fa-check"></i><b>16.4</b> Examples of application</a></li>
<li class="chapter" data-level="16.5" data-path="intermittent-demand-challenges.html"><a href="intermittent-demand-challenges.html"><i class="fa fa-check"></i><b>16.5</b> Intermittent demand challenges</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="diagnostics.html"><a href="diagnostics.html"><i class="fa fa-check"></i><b>17</b> Model diagnostics</a>
<ul>
<li class="chapter" data-level="17.1" data-path="diagnosticsOmitted.html"><a href="diagnosticsOmitted.html"><i class="fa fa-check"></i><b>17.1</b> Model specification: Omitted variables</a></li>
<li class="chapter" data-level="17.2" data-path="model-specification-redundant-variables.html"><a href="model-specification-redundant-variables.html"><i class="fa fa-check"></i><b>17.2</b> Model specification: Redundant variables</a></li>
<li class="chapter" data-level="17.3" data-path="diagnosticsTransformations.html"><a href="diagnosticsTransformations.html"><i class="fa fa-check"></i><b>17.3</b> Model specification: Transformations</a></li>
<li class="chapter" data-level="17.4" data-path="diagnosticsOutliers.html"><a href="diagnosticsOutliers.html"><i class="fa fa-check"></i><b>17.4</b> Model specification: Outliers</a>
<ul>
<li class="chapter" data-level="17.4.1" data-path="diagnosticsOutliers.html"><a href="diagnosticsOutliers.html#outliers-detection"><i class="fa fa-check"></i><b>17.4.1</b> Outliers detection</a></li>
<li class="chapter" data-level="17.4.2" data-path="diagnosticsOutliers.html"><a href="diagnosticsOutliers.html#dealing-with-outliers"><i class="fa fa-check"></i><b>17.4.2</b> Dealing with outliers</a></li>
<li class="chapter" data-level="17.4.3" data-path="diagnosticsOutliers.html"><a href="diagnosticsOutliers.html#an-automatic-mechanism"><i class="fa fa-check"></i><b>17.4.3</b> An automatic mechanism</a></li>
<li class="chapter" data-level="17.4.4" data-path="diagnosticsOutliers.html"><a href="diagnosticsOutliers.html#final-remarks"><i class="fa fa-check"></i><b>17.4.4</b> Final remarks</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="diagnosticsResidualsIIDAuto.html"><a href="diagnosticsResidualsIIDAuto.html"><i class="fa fa-check"></i><b>17.5</b> Residuals are i.i.d.: autocorrelation</a></li>
<li class="chapter" data-level="17.6" data-path="diagnosticsResidualsIIDHetero.html"><a href="diagnosticsResidualsIIDHetero.html"><i class="fa fa-check"></i><b>17.6</b> Residuals are i.i.d.: heteroscedasticity</a>
<ul>
<li class="chapter" data-level="17.6.1" data-path="diagnosticsResidualsIIDHetero.html"><a href="diagnosticsResidualsIIDHetero.html#detecting-heteroscedasticity"><i class="fa fa-check"></i><b>17.6.1</b> Detecting heteroscedasticity</a></li>
</ul></li>
<li class="chapter" data-level="17.7" data-path="residuals-are-i-i-d-zero-expectation.html"><a href="residuals-are-i-i-d-zero-expectation.html"><i class="fa fa-check"></i><b>17.7</b> Residuals are i.i.d.: zero expectation</a></li>
<li class="chapter" data-level="17.8" data-path="residuals-are-i-i-d-distributional-assumptions.html"><a href="residuals-are-i-i-d-distributional-assumptions.html"><i class="fa fa-check"></i><b>17.8</b> Residuals are i.i.d.: distributional assumptions</a></li>
<li class="chapter" data-level="17.9" data-path="multicollinearity-1.html"><a href="multicollinearity-1.html"><i class="fa fa-check"></i><b>17.9</b> Multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="ADAMSelection.html"><a href="ADAMSelection.html"><i class="fa fa-check"></i><b>18</b> Model selection and combinations in ADAM</a>
<ul>
<li class="chapter" data-level="18.1" data-path="ETSSelection.html"><a href="ETSSelection.html"><i class="fa fa-check"></i><b>18.1</b> ADAM ETS components selection</a></li>
<li class="chapter" data-level="18.2" data-path="ARIMASelection.html"><a href="ARIMASelection.html"><i class="fa fa-check"></i><b>18.2</b> ADAM ARIMA order selection</a></li>
<li class="chapter" data-level="18.3" data-path="ETSXSelection.html"><a href="ETSXSelection.html"><i class="fa fa-check"></i><b>18.3</b> Explanatory variables selection</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Forecasting and Analytics with ADAM</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div class = rmdreview>
This book is in <b><a href="open.html#open">Open Review</a></b>. I want your feedback to make the book better for you and other readers. To add your annotation, <span style="background-color: #3297FD; color: white">select some text</span> and then click the <i class="h-icon-annotate"></i> on the pop-up menu. To see the annotations of others, click the button in the upper right hand corner of the page <i class="fa fa-arrow-circle-right  fa-rotate-315" aria-hidden="true"></i>
</div>
<div id="assumptions" class="section level2" number="3.6">
<h2><span class="header-section-number">3.6</span> Statistical models assumptions</h2>
<p>In order for a statistical model to work adequately and not to fail, when applied to a data, several assumptions about it should hold. If they do not, then the model might lead to <a href="estimatesProperties.html#estimatesProperties">biased or inefficient estimates of parameters</a> and inaccurate forecasts. In this section we discuss the main assumptions, united in three big groups:</p>
<ol style="list-style-type: decimal">
<li><a href="assumptions.html#assumptionsCorrectModel">Model is correctly specified</a>;</li>
<li><a href="assumptions.html#assumptionsResidualsAreIID">Residuals are independent and identically distributed (i.i.d.)</a>;</li>
<li><a href="assumptions.html#assumptionsXreg">The explanatory variables are not correlated with anything but the response variable</a>.</li>
</ol>
<p>We do not aim to explain why the violation of assumptions would lead to the discussed problem, and refer a curious reader to econometrics textbooks <span class="citation">(for example <a href="#ref-Hanck2020" role="doc-biblioref">Hanck et al., 2020</a>)</span>. In many cases, in our discussions in this textbook, we assume that all of these assumptions hold. In some of the cases, we will say explicitly, which are violated and what needs to be done in those situations. In Section <a href="diagnostics.html#diagnostics">17</a> we will discuss how these assumptions can be checked for dynamic models, and how the issues caused by their violation can be fixed.</p>
<div id="assumptionsCorrectModel" class="section level3" number="3.6.1">
<h3><span class="header-section-number">3.6.1</span> Model is correctly specified</h3>
<p>This is one of the fundamental group of assumptions, which can be summarised as âwe have included everything necessary in the model in the correct form.â It implies that:</p>
<ol style="list-style-type: decimal">
<li>We have not omitted important variables in the model (underfitting the data);</li>
<li>We do not have redundant variables in the model (overfitting the data);</li>
<li>The necessary transformations of the variables are applied;</li>
<li>We do not have outliers in the model.</li>
</ol>
<div id="omitted-variables" class="section level4" number="3.6.1.1">
<h4><span class="header-section-number">3.6.1.1</span> Omitted variables</h4>
<p>If there are some important variables that we did not include in the model, then the estimates of the parameters might be <em>biased</em> and in some cases quite seriously (e.g.Â positive sign instead of the negative one). A classical example of model with omitted important variables is <a href="simpleLinearRegression.html#simpleLinearRegression">simple linear regression</a>, which by definition includes only one explanatory variable. Making decisions based on such model might not be wise, as it might mislead about the significance and sign of effects. Yes, we use simple linear regression for educational purposes, to understand how the model works and what it implies, but it is not sufficient on its own. Finally, when it comes to forecasting, omitting important variables is equivalent to underfitting the data, ignoring significant aspects of the model. This means that the point forecasts from the model might be <em>biased</em> (systematic under or over forecasting), the variance of the error term will be higher than needed, which will result in wider than necessary <a href="confidenceIntervals.html#confidenceIntervalsPrediction">prediction interval</a>.</p>
<p>In some cases, it is possible to diagnose the violation of this assumption. In order to do that an analyst needs to analyse a variety of plots of residuals vs fitted, vs time (if we deal with time series), and vs omitted variables. Consider an example with <code>mtcars</code> data and a simple linear regression:</p>
<div class="sourceCode" id="cb153"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb153-1"><a href="assumptions.html#cb153-1" aria-hidden="true" tabindex="-1"></a>mtcarsSLR <span class="ot">&lt;-</span> <span class="fu">alm</span>(mpg<span class="sc">~</span>wt, mtcars, <span class="at">loss=</span><span class="st">&quot;MSE&quot;</span>)</span></code></pre></div>
<p>Based on the preliminary analysis that we have conducted in Sections <a href="dataAnalysis.html#dataAnalysis">2.1</a> and <a href="correlations.html#correlations">2.6</a>, this model omits important variables. And there are several basic plots that might allow us diagnosing the violation of this assumption.</p>
<div class="sourceCode" id="cb154"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb154-1"><a href="assumptions.html#cb154-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfcol=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb154-2"><a href="assumptions.html#cb154-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mtcarsSLR,<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span></code></pre></div>
<div class="figure"><span id="fig:diagnostics01"></span>
<img src="adam_files/figure-html/diagnostics01-1.png" alt="Diagnostics of omitted variables." width="672" />
<p class="caption">
Figure 3.29: Diagnostics of omitted variables.
</p>
</div>
<p>Figure <a href="assumptions.html#fig:diagnostics01">3.29</a> demonstrates actuals vs fitted and fitted vs standardised residuals. The standardised residuals are the residuals from the model that are divided by their standard deviation, thus removing the scale. What we want to see on the first plot in Figure <a href="assumptions.html#fig:diagnostics01">3.29</a>, is for all the point lie around the grey line and for the LOWESS line to coincide with the grey line. That would mean that the relations are captured correctly and all the observations are explained by the model. As for the second plot, we want to see the same, but it just presents that information in a different format, which is sometimes easier to analyse. In both plot of Figure <a href="assumptions.html#fig:diagnostics01">3.29</a>, we can see that there are still some patterns left: the LOWESS line has a u-shaped form, which in general means that something is wrong with model specification. In order to investigate if there are any omitted variables, we construct a spread plot of residuals vs all the variables not included in the model (Figure <a href="assumptions.html#fig:diagnostics02">3.30</a>).</p>
<div class="sourceCode" id="cb155"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb155-1"><a href="assumptions.html#cb155-1" aria-hidden="true" tabindex="-1"></a><span class="fu">spread</span>(<span class="fu">data.frame</span>(<span class="at">residuals=</span><span class="fu">resid</span>(mtcarsSLR), mtcars[,<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">6</span>)]))</span></code></pre></div>
<div class="figure"><span id="fig:diagnostics02"></span>
<img src="adam_files/figure-html/diagnostics02-1.png" alt="Diagnostics of omitted variables." width="672" />
<p class="caption">
Figure 3.30: Diagnostics of omitted variables.
</p>
</div>
<p>What we want to see in Figure <a href="assumptions.html#fig:diagnostics02">3.30</a> is the absence of any patterns in plots of residuals vs variables. However, we can see that there are still many relations. For example, with the increase of the number of cylinders, the mean of residuals decreases. This might indicate that the variable is needed in the model. And indeed, we can imagine a situation, where mileage of a car (the response variable in our model) would depend on the number of cylinders because the bigger engines will have more cylinders and consume more fuel, so it makes sense to include this variable in the model as well.</p>
<p><strong>Note that we do not suggest to start modelling from simple linear relation!</strong> You should construct a model that you think is suitable for the problem, and the example above is provided only for illustrative purposes.</p>
</div>
<div id="redundant-variables" class="section level4" number="3.6.1.2">
<h4><span class="header-section-number">3.6.1.2</span> Redundant variables</h4>
<p>If there are redundant variables that are not needed in the model, then the estimates of parameters and point forecasts might be <em>unbiased</em>, but <em>inefficient</em>. This implies that the variance of parameters can be lower than needed and thus the prediction intervals will be narrower than needed. There are no good instruments for diagnosing this issue, so judgment is needed, when deciding what to include in the model.</p>
</div>
<div id="transformations" class="section level4" number="3.6.1.3">
<h4><span class="header-section-number">3.6.1.3</span> Transformations</h4>
<p>This assumption implies that we have taken all possible non-linearities into account. If, for example, instead of using a multiplicative model, we apply an additive one, the estimates of parameters and the point forecasts might be <em>biased</em>. This is because the model will produce linear trajectory of the forecast, when a non-linear one is needed. This was discussed in detail in Section <a href="variablesTransformations.html#variablesTransformations">3.5</a>. The diagnostics of this assumption is similar to the diagnostics shown above for the omitted variables: construct actuals vs fitted and residuals vs fitted in order to see if there are any patterns in the plots. Take the multiple regression model for mtcars, which includes several variables, but is additive in its form:</p>
<div class="sourceCode" id="cb156"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb156-1"><a href="assumptions.html#cb156-1" aria-hidden="true" tabindex="-1"></a>mtcarsALM01 <span class="ot">&lt;-</span> <span class="fu">alm</span>(mpg<span class="sc">~</span>wt<span class="sc">+</span>qsec<span class="sc">+</span>am, mtcars, <span class="at">loss=</span><span class="st">&quot;MSE&quot;</span>)</span></code></pre></div>
<p>Arguably, the model includes important variables (although there might be some others that could improve it), but the residuals will show some patterns, because the model should be multiplicative (see Figure <a href="assumptions.html#fig:diagnostics03">3.31</a>), because mileage should not reduce linearly with increase of those variables. In order to understand that, ask yourself, whether the mileage can be negative and whether weight and other variables can be non-positive (a car with <span class="math inline">\(wt=0\)</span> just does not exist).</p>
<div class="sourceCode" id="cb157"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb157-1"><a href="assumptions.html#cb157-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfcol=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb157-2"><a href="assumptions.html#cb157-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mtcarsALM01,<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span></code></pre></div>
<div class="figure"><span id="fig:diagnostics03"></span>
<img src="adam_files/figure-html/diagnostics03-1.png" alt="Diagnostics of necessary transformations in linear model." width="672" />
<p class="caption">
Figure 3.31: Diagnostics of necessary transformations in linear model.
</p>
</div>
<p>Figure <a href="assumptions.html#fig:diagnostics03">3.31</a> demonstrates the u-shaped pattern in the residuals, which is one of the indicators of a wrong model specification, calling for a non-linear transformation. We can try a model in logarithms:</p>
<div class="sourceCode" id="cb158"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb158-1"><a href="assumptions.html#cb158-1" aria-hidden="true" tabindex="-1"></a>mtcarsALM02 <span class="ot">&lt;-</span> <span class="fu">alm</span>(<span class="fu">log</span>(mpg)<span class="sc">~</span><span class="fu">log</span>(wt)<span class="sc">+</span><span class="fu">log</span>(qsec)<span class="sc">+</span>am, mtcars, <span class="at">loss=</span><span class="st">&quot;MSE&quot;</span>)</span></code></pre></div>
<p>And see what would happen with the diagnostics of the model in logarithms:</p>
<div class="sourceCode" id="cb159"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb159-1"><a href="assumptions.html#cb159-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfcol=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb159-2"><a href="assumptions.html#cb159-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mtcarsALM02,<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span></code></pre></div>
<div class="figure"><span id="fig:diagnostics04"></span>
<img src="adam_files/figure-html/diagnostics04-1.png" alt="Diagnostics of necessary transformations in log-log model." width="672" />
<p class="caption">
Figure 3.32: Diagnostics of necessary transformations in log-log model.
</p>
</div>
<p>Figure <a href="assumptions.html#fig:diagnostics04">3.32</a> demonstrates that while the LOWESS lines do not coincide with the grey lines, the residuals do not have obvious patterns. The fact that the LOWESS line starts from below, when fitted values are low in our case only shows that we do not have enough observations with low actual values. As a result, LOWESS is impacted by 2 observations that lie below the grey line. This demonstrates that LOWESS lines should be taken with a pinch of salt and we should abstain from finding patterns in randomness, when possible. Overall, the log-log model is more appropriate to this data than the linear one.</p>
</div>
<div id="outliers" class="section level4" number="3.6.1.4">
<h4><span class="header-section-number">3.6.1.4</span> Outliers</h4>
<p>In a way, this assumption is similar to the first one with omitted variables. The presence of outliers might mean that we have missed some important information, implying that the estimates of parameters and forecasts would be <em>biased</em>. There can be other reasons for outliers as well. For example, we might be using a wrong distributional assumption. If so, this would imply that the prediction interval from the model is narrower than necessary. The diagnostics of outliers comes to producing standardised residuals vs fitted, to studentised vs fitted and to Cookâs distance plot. While we are already familiar with the first one, the other two need to be explained in more detail.</p>
<p>Studentised residuals are the residuals that are calculated in the same way as the standardised ones, but removing the value of each residual. For example, the studentised residual on observation 25 would be calculated as the raw residual divided by standard deviation of residuals, calculated without this 25th observation. This way we diminish the impact of potential serious outliers on the standard deviation, making it easier to spot the outliers.</p>
<p>As for the Cookâs distance, its idea is to calculate measures for each observation showing how influential they are in terms of impact on the estimates of parameters of the model. If there is an influential outlier, then it would distort the values of parameters, causing bias.</p>
<div class="sourceCode" id="cb160"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb160-1"><a href="assumptions.html#cb160-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfcol=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb160-2"><a href="assumptions.html#cb160-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mtcarsALM02,<span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>))</span></code></pre></div>
<div class="figure"><span id="fig:diagnostics05"></span>
<img src="adam_files/figure-html/diagnostics05-1.png" alt="Diagnostics of outliers." width="672" />
<p class="caption">
Figure 3.33: Diagnostics of outliers.
</p>
</div>
<p>Figure <a href="assumptions.html#fig:diagnostics05">3.33</a> demonstrates standardised and studentised residuals vs fitted values for the log-log model on mtcars data. We can see that the plots are very similar, which already indicates that there are no strong outliers in the residuals. The bounds produced on the plots correspond to the 95% prediction interval, so by definition it should contain <span class="math inline">\(0.95\times 32 \approx 30\)</span> observations. Indeed, there are only two observations: 15 and 25 - that lie outside the bounds. Technically, we would suspect that they are outliers, but they do not lie far away from the bounds and their number meets our expectations, so we can conclude that there are no outliers in the data.</p>
<div class="sourceCode" id="cb161"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb161-1"><a href="assumptions.html#cb161-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mtcarsALM02,<span class="dv">12</span>)</span></code></pre></div>
<div class="figure"><span id="fig:diagnostics06"></span>
<img src="adam_files/figure-html/diagnostics06-1.png" alt="Cook's distance plot." width="672" />
<p class="caption">
Figure 3.34: Cookâs distance plot.
</p>
</div>
<p>Finally, we produce Cookâs distance over observations in Figure <a href="assumptions.html#fig:diagnostics06">3.34</a>. The x-axis says âTime,â because <code>alm()</code> function is tailored for time series data, but this can be renamed into âobservations.â The plot shows how influential the outliers are. If there were some significantly influential outliers in the data, then the plot would draw red lines, corresponding to 0.5, 0.75 and 0.95 quantiles of Fisherâs distribution, and the line of those outliers would be above the red lines. Consider the following example for demonstration purposes:</p>
<div class="sourceCode" id="cb162"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb162-1"><a href="assumptions.html#cb162-1" aria-hidden="true" tabindex="-1"></a>mtcarsData[<span class="dv">28</span>,<span class="dv">6</span>] <span class="ot">&lt;-</span> <span class="dv">4</span></span>
<span id="cb162-2"><a href="assumptions.html#cb162-2" aria-hidden="true" tabindex="-1"></a>mtcarsALM03 <span class="ot">&lt;-</span> <span class="fu">alm</span>(<span class="fu">log</span>(mpg)<span class="sc">~</span><span class="fu">log</span>(wt)<span class="sc">+</span><span class="fu">log</span>(qsec)<span class="sc">+</span>am, mtcarsData, <span class="at">loss=</span><span class="st">&quot;MSE&quot;</span>)</span></code></pre></div>
<p>This way, we intentionally create an influential outlier (the car should have the minimum weight in the dataset, and now it has a very high one).</p>
<div class="sourceCode" id="cb163"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb163-1"><a href="assumptions.html#cb163-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mtcarsALM03, <span class="dv">12</span>, <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="fl">1.5</span>), <span class="at">xlab=</span><span class="st">&quot;Observations&quot;</span>, <span class="at">main=</span><span class="st">&quot;&quot;</span>)</span></code></pre></div>
<div class="figure"><span id="fig:diagnostics07"></span>
<img src="adam_files/figure-html/diagnostics07-1.png" alt="Cook's distance plot for the data with influential outlier." width="672" />
<p class="caption">
Figure 3.35: Cookâs distance plot for the data with influential outlier.
</p>
</div>
<p>Figure <a href="assumptions.html#fig:diagnostics07">3.35</a> shows how Cookâs distance will look in this case - it detects that there is an influential outlier, which is above the norm. We can compare the parameters of the new and the old models to see how the introduction of one outlier leads to bias in the estimates of parameters:</p>
<div class="sourceCode" id="cb164"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb164-1"><a href="assumptions.html#cb164-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rbind</span>(<span class="fu">coef</span>(mtcarsALM02),</span>
<span id="cb164-2"><a href="assumptions.html#cb164-2" aria-hidden="true" tabindex="-1"></a>      <span class="fu">coef</span>(mtcarsALM03))</span></code></pre></div>
<pre><code>##      (Intercept)    log(wt) log(qsec)         am
## [1,]   1.2095788 -0.7325269 0.8857779 0.05205307
## [2,]   0.1382442 -0.4852647 1.1439862 0.21406331</code></pre>
</div>
</div>
<div id="assumptionsResidualsAreIID" class="section level3" number="3.6.2">
<h3><span class="header-section-number">3.6.2</span> Residuals are i.i.d.</h3>
<p>There are five assumptions in this group:</p>
<ol style="list-style-type: decimal">
<li>There is no autocorrelation in the residuals;</li>
<li>The residuals are homoscedastic;</li>
<li>The expectation of residuals is zero, no matter what;</li>
<li>The variable follows the assumed distribution;</li>
<li>More generally speaking, distribution of residuals does not change over time.</li>
</ol>
<div id="no-autocorrelations" class="section level4" number="3.6.2.1">
<h4><span class="header-section-number">3.6.2.1</span> No autocorrelations</h4>
<p>This assumption only applied to time series data, and in a way comes to capturing correctly the dynamic relations between variables. The term âautocorrelationâ refers to the situation, when variable is correlated with itself from the past. If the residuals are autocorrelated, then something is neglected by the applied model. Typically, this leads to <em>inefficient</em> estimates of parameters, which in some cases might also become <em>biased</em>. The model with autocorrelated residuals might produce inaccurate point forecasts and prediction intervals of a wrong width (wider or narrower than needed).</p>
<p>There are several ways of diagnosing the problem, including visual analysis and statistical tests. In order to show some of them, we consider the <code>Seatbelts</code> data from <code>datasets</code> package for R. We fit a basic model, predicting monthly totals of car drivers in the Great Britain killed or seriously injured in car accidents:</p>
<div class="sourceCode" id="cb166"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb166-1"><a href="assumptions.html#cb166-1" aria-hidden="true" tabindex="-1"></a>SeatbeltsALM01 <span class="ot">&lt;-</span> <span class="fu">alm</span>(drivers<span class="sc">~</span>PetrolPrice<span class="sc">+</span>kms<span class="sc">+</span>front<span class="sc">+</span>rear<span class="sc">+</span>law, Seatbelts)</span></code></pre></div>
<p>In order to do graphical diagnose, we can produce plots of standardised / studentised residuals over time:</p>
<div class="sourceCode" id="cb167"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb167-1"><a href="assumptions.html#cb167-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(SeatbeltsALM01,<span class="dv">8</span>,<span class="at">main=</span><span class="st">&quot;&quot;</span>)</span></code></pre></div>
<div class="figure"><span id="fig:diagnostics08"></span>
<img src="adam_files/figure-html/diagnostics08-1.png" alt="Standardised residuals over time." width="672" />
<p class="caption">
Figure 3.36: Standardised residuals over time.
</p>
</div>
<p>If the assumption is not violated, then the plot in Figure <a href="assumptions.html#fig:diagnostics08">3.36</a> would not contain any patterns. However, we can see that, first, there is a seasonality in the residuals and second, the expectation (captured by the red LOWESS line) changes over time. This indicates that there might be some autocorrelation in residuals caused by omitted components. We do not aim to resolve the issue now, it is discussed in more detail in Section <a href="diagnosticsResidualsIIDAuto.html#diagnosticsResidualsIIDAuto">17.5</a>.</p>
<p>The other instrument for diagnostics is ACF / PACF plots, which are produced in <code>alm()</code> via the following command:</p>
<div class="sourceCode" id="cb168"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb168-1"><a href="assumptions.html#cb168-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfcol=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb168-2"><a href="assumptions.html#cb168-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(SeatbeltsALM01,<span class="fu">c</span>(<span class="dv">10</span>,<span class="dv">11</span>),<span class="at">main=</span><span class="st">&quot;&quot;</span>)</span></code></pre></div>
<div class="figure"><span id="fig:diagnostics09"></span>
<img src="adam_files/figure-html/diagnostics09-1.png" alt="ACF and PACF of the residuals of a model." width="672" />
<p class="caption">
Figure 3.37: ACF and PACF of the residuals of a model.
</p>
</div>
<p>These are discussed in more detail in Sections <a href="BJApproach.html#ACF">11.3.2</a> and <a href="BJApproach.html#PACF">11.3.3</a>.</p>
</div>
<div id="homoscedastic-residuals" class="section level4" number="3.6.2.2">
<h4><span class="header-section-number">3.6.2.2</span> Homoscedastic residuals</h4>
<p>In general, we assume that the variance of residuals is constant. If this is violated, then we say that there is a <strong>heteroscedasticity</strong> in the model. This means that with a change of a variable, the variance of the residuals will change as well. If the model neglects this, then typically the estimates of parameters become <em>inefficient</em> and prediction intervals are wrong: they are wider than needed in some cases (e.g.m when the volume of data is low) and narrower than needed in the other ones (e.g.Â on high volume data).</p>
<p>Typically, this assumption will be violated if the model is not specified correctly. The classical example is the income versus expenditure on meals for different families. If the income is low, then there is not many options what to buy and the variability of expenditures would be low. However, with the increase of the income, the mean expenditures and their variability would increase as well, because there are more options of what to buy, including both cheap and expensive products. If we constructed a basic linear model on such data, then it would violate the assumption of homoscedasticity and as a result will have the issues discussed above. But arguably this would typically appear because of the misspecification of the model. For example, taking logarithms might resolve the issue in many cases, implying that the effect of one variable on the other should be multiplicative rather than the additive. Alternatively, dividing variables by some other variable (e.g.Â working with expenses per family member, not per family) might resolve the problem as well. Unfortunately, the transformations are not the panacea, so in some cases analyst would need to construct a model, taking the changing variance into account (e.g.Â GARCH or GAMLSS models). This is discussed in Section <a href="#almScaleModel"><strong>??</strong></a>.</p>
<p>While in forecasting we are more interested in the holdout performance of models, in econometrics, the parameters of models are typically of the main interest. And, as we discussed earlier, in case of correctly specified model with heteroscedastic residuals, the estimates of parameters will be unbiased, but inefficient. So, econometricians would use different approaches to diminish the heteroscedasticity effect on parameters: either a different estimator for a model (such as Weighted Least Squares), or a different method for calculation of standard errors of parameters (e.g.Â Heteroskedasticity-Consistent Standard Errors). This does not resolve the problem, but rather corrects the parameters of the model (i.e.Â does not heal the illness, but treats the symptoms). Although these approaches typically suffice for the analytical purposes, they do not fix the issues in forecasting.</p>
<p>The diagnostics of heteroscedasticity can be done via plotting absolute and / or squared residuals against the fitted values.</p>
<div class="sourceCode" id="cb169"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb169-1"><a href="assumptions.html#cb169-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfcol=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb169-2"><a href="assumptions.html#cb169-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mtcarsALM01,<span class="dv">4</span><span class="sc">:</span><span class="dv">5</span>)</span></code></pre></div>
<div class="figure"><span id="fig:diagnostics10"></span>
<img src="adam_files/figure-html/diagnostics10-1.png" alt="Detecting heteroscedasticity. Model 1." width="672" />
<p class="caption">
Figure 3.38: Detecting heteroscedasticity. Model 1.
</p>
</div>
<p>If your model assumes that residuals follow a distribution related to the Normal one, then you should focus on the plot of squared residuals vs fitted, as this would be closer related to the variance of the distribution. In the example of mtcars model in Figure <a href="assumptions.html#fig:diagnostics10">3.38</a> we see that the variance of residuals increases with the increase of Fitted values (the LOWESS line increases and the overall variability around 1200 is lower than the one around 2000). This indicates that the residuals are heteroscedastic. One of the possible solutions of the problem is taking the logarithms, as we have done in the model <code>mtcarsALM02</code>:</p>
<div class="sourceCode" id="cb170"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb170-1"><a href="assumptions.html#cb170-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfcol=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb170-2"><a href="assumptions.html#cb170-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mtcarsALM02,<span class="dv">4</span><span class="sc">:</span><span class="dv">5</span>)</span></code></pre></div>
<div class="figure"><span id="fig:diagnostics11"></span>
<img src="adam_files/figure-html/diagnostics11-1.png" alt="Detecting heteroscedasticity. Model 2." width="672" />
<p class="caption">
Figure 3.39: Detecting heteroscedasticity. Model 2.
</p>
</div>
<p>While the LOWESS lines on plots in Figure <a href="assumptions.html#fig:diagnostics11">3.39</a> demonstrate some dynamics, the variability of residuals does not change significantly with the increase of fitted value, so non-linear transformation seems to fix the issue in our example. If it would not, then we would need to consider either some other transformations or finding out, which of the variables causes heteroscedasticity and then modelling it explicitly via the scale model (Section <a href="#almScaleModel"><strong>??</strong></a>).</p>
</div>
<div id="mean-of-residuals" class="section level4" number="3.6.2.3">
<h4><span class="header-section-number">3.6.2.3</span> Mean of residuals</h4>
<p>While in sample, this holds automatically in many cases (e.g.Â when using Least Squares method for regression model estimation), this assumption might be violated in the holdout sample. In this case the point forecasts would be <em>biased</em>, because they typically do not take the non-zero mean of forecast error into account, and the prediction interval might be off as well, because of the wrong estimation of the scale of distribution (e.g.Â variance is higher than needed). This assumption also implies that the expectation of residuals is zero even conditional on the explanatory variables in the model. If it is not, then this might mean that there is still some important information omitted in the applied model.</p>
<p>Note that some models assume that the expectation of residuals is equal to one instead of zero (e.g.Â multiplicative error models). The idea of the assumption stays the same, it is only the value that changes.</p>
<p>The diagnostics of the problem would be similar to the case of non-linear transformations or autocorrelations: plotting residuals vs fitted or residuals vs time and trying to find patterns. If the mean of residuals changes either with the change of fitted values of with time, then the conditional expectation of residuals is not zero, and something is missing in the model.</p>
</div>
<div id="assumptionsDistribution" class="section level4" number="3.6.2.4">
<h4><span class="header-section-number">3.6.2.4</span> Distributional assumptions</h4>
<p>In some cases we are interested in using methods that imply specific distributional assumptions about the model and its residuals. For example, it is assumed in the classical linear model that the error term follows Normal distribution. Estimating this model using MLE with the probability density function of Normal distribution or via minimisation of <a href="errorMeasures.html#errorMeasures">Mean Squared Error</a> (MSE) would give <em>efficient</em> and <em>consistent</em> estimates of parameters. If the assumption of normality does not hold, then the estimates might be <em>inefficient</em> and in some cases <em>inconsistent</em>. When it comes to forecasting, the main issue in the wrong distributional assumption appears, when prediction intervals are needed: they might rely on a wrong distribution and be narrower or wider than needed. Finally, if we deal with the wrong distribution, then the model selection mechanism might be flawed and would lead to the selection of an inappropriate model.</p>
<p>The most efficient way of diagnosing this, is constructing QQ-plot of residuals (discussed in Section <a href="dataAnalysis.html#dataAnalysisGraphical">2.1.2</a>).</p>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb171-1"><a href="assumptions.html#cb171-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mtcarsALM02,<span class="dv">6</span>)</span></code></pre></div>
<div class="figure"><span id="fig:diagnostics12"></span>
<img src="adam_files/figure-html/diagnostics12-1.png" alt="QQ-plot of residuals of model 2 for mtcars dataset." width="672" />
<p class="caption">
Figure 3.40: QQ-plot of residuals of model 2 for mtcars dataset.
</p>
</div>
<p>Figure <a href="assumptions.html#fig:diagnostics12">3.40</a> shows that all the points lie close to the line (with minor fluctuations around it), so we can conclude that the residuals follow the normal distribution. In comparison, Figure <a href="assumptions.html#fig:diagnostics12">3.40</a> demonstrates how residuals would look in case of a wrong distribution. Although the values lie not too far from ths straight line, there are several observations in the tails that are further away than needed. Comparing the two plots, we would select the on in Figure <a href="assumptions.html#fig:diagnostics12">3.40</a>, as the residuals are better behaved.</p>
<div class="sourceCode" id="cb172"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb172-1"><a href="assumptions.html#cb172-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(mtcarsALM01,<span class="dv">6</span>)</span></code></pre></div>
<div class="figure"><span id="fig:diagnostics13"></span>
<img src="adam_files/figure-html/diagnostics13-1.png" alt="QQ-plot of residuals of model 1 for mtcars dataset." width="672" />
<p class="caption">
Figure 3.41: QQ-plot of residuals of model 1 for mtcars dataset.
</p>
</div>
</div>
<div id="distribution-does-not-change" class="section level4" number="3.6.2.5">
<h4><span class="header-section-number">3.6.2.5</span> Distribution does not change</h4>
<p>This assumption aligns with the Subsection <a href="assumptions.html#assumptionsDistribution">3.6.2.4</a>, but in this specific context implies that all the parameters of distribution stay the same and the shape of distribution does not change. If the former is violated then we might have one of the issues discussed above. If the latter is violated then we might produce <em>biased</em> forecasts and underestimate / overestimate the uncertainty about the future. The diagnosis of this comes to analysing QQ-plots, similar to Subsection <a href="assumptions.html#assumptionsDistribution">3.6.2.4</a>.</p>
</div>
</div>
<div id="assumptionsXreg" class="section level3" number="3.6.3">
<h3><span class="header-section-number">3.6.3</span> The explanatory variables are not correlated with anything but the response variable</h3>
<p>There are two assumptions in this group:</p>
<ol style="list-style-type: decimal">
<li>No multicollinearity;</li>
<li>No endogeneity;</li>
</ol>
<div id="multicollinearity" class="section level4" number="3.6.3.1">
<h4><span class="header-section-number">3.6.3.1</span> Multicollinearity</h4>
<p>One of the classical issues in econometrics and in statistics in regression context is the issue of multicollinearity, the effect when several explanatory variables are correlated. In a way, this has nothing to do with classical assumptions of linear regression, because it is unreasonable to assume that the explanatory variables have some specific relation between them - they are what they are, and multicollinearity mainly causes issues with estimation of the parameters of model, not with its structure. But it is an issue nonetheless, so it is worth exploring.</p>
<p>Multicollinearity appears, when either some of explanatory variables are correlated with each other (see Section <a href="correlations.html#correlationCoefficient">2.6.3</a>), or their linear combination explains another explanatory variable included in the model. Depending on the strength of this relation and the estimation method used for model construction, the multicollinearity might cause issues of varying severity. For example, in the case, when two variables are perfectly correlated (correlation coefficient is equal to 1 or -1), the model will have perfect multicollinearity and it would not be possible to estimate its parameters. Another example is a case, when an explanatory variable can be perfectly explained by a set of other explanatory variables (resulting in <span class="math inline">\(R^2\)</span> being close to one), which will cause exactly the same issue. The classical example of this situation is the dummy variables trap (see Section <a href="dummyVariables.html#dummyVariables">3.4</a>), when all values of categorical variable are included in regression together with the constant resulting in the linear relation <span class="math inline">\(\sum_{j=1}^k d_j = 1\)</span>. Given that the square root of <span class="math inline">\(R^2\)</span> of linear regression is equal to multiple correlation coefficient, these two situations are equivalent and just come to âabsolute value of correlation coefficient is equal to 1.â Finally, if correlation coefficient is high, but not equal to one, the effect of multicollinearity will lead to <a href="estimatesProperties.html#estimatesPropertiesEfficiency">less efficient estimates</a> of parameters. The loss of efficiency is in this case proportional to the absolute value of correlation coefficient. In case of forecasting, the effect is not as straight forward, and in some cases might not damage the point forecasts, but can lead to prediction intervals of an incorrect width. The main issue of multicollinearity comes to the difficulties in the model estimation in a sample. If we had all the data in the world, then the issue would not exist. All of this tells us how this problem can be diagnosed and that this diagnosis should be carried out before constructing regression model.</p>
<p>First, we can calculate correlation matrix for the available variables. If they are all numeric, then <code>cor()</code> function from <code>stats</code> should do the trick (we remove the response variable from consideration):</p>
<div class="sourceCode" id="cb173"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb173-1"><a href="assumptions.html#cb173-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(mtcars[,<span class="sc">-</span><span class="dv">1</span>])</span></code></pre></div>
<pre><code>##             cyl       disp         hp        drat         wt        qsec
## cyl   1.0000000  0.9020329  0.8324475 -0.69993811  0.7824958 -0.59124207
## disp  0.9020329  1.0000000  0.7909486 -0.71021393  0.8879799 -0.43369788
## hp    0.8324475  0.7909486  1.0000000 -0.44875912  0.6587479 -0.70822339
## drat -0.6999381 -0.7102139 -0.4487591  1.00000000 -0.7124406  0.09120476
## wt    0.7824958  0.8879799  0.6587479 -0.71244065  1.0000000 -0.17471588
## qsec -0.5912421 -0.4336979 -0.7082234  0.09120476 -0.1747159  1.00000000
## vs   -0.8108118 -0.7104159 -0.7230967  0.44027846 -0.5549157  0.74453544
## am   -0.5226070 -0.5912270 -0.2432043  0.71271113 -0.6924953 -0.22986086
## gear -0.4926866 -0.5555692 -0.1257043  0.69961013 -0.5832870 -0.21268223
## carb  0.5269883  0.3949769  0.7498125 -0.09078980  0.4276059 -0.65624923
##              vs          am       gear        carb
## cyl  -0.8108118 -0.52260705 -0.4926866  0.52698829
## disp -0.7104159 -0.59122704 -0.5555692  0.39497686
## hp   -0.7230967 -0.24320426 -0.1257043  0.74981247
## drat  0.4402785  0.71271113  0.6996101 -0.09078980
## wt   -0.5549157 -0.69249526 -0.5832870  0.42760594
## qsec  0.7445354 -0.22986086 -0.2126822 -0.65624923
## vs    1.0000000  0.16834512  0.2060233 -0.56960714
## am    0.1683451  1.00000000  0.7940588  0.05753435
## gear  0.2060233  0.79405876  1.0000000  0.27407284
## carb -0.5696071  0.05753435  0.2740728  1.00000000</code></pre>
<p>This matrix tells us that there are some variables that are highly correlated and might reduce efficiency of estimates of parameters of regression model if included in the model together. This mainly applies to <code>cyl</code> and <code>disp</code>, which both characterise the size of engine. If we have a mix of numerical and categorical variables, then <code>assoc()</code> (aka <code>association()</code>) function from <code>greybox</code> will be more appropriate (see Section <a href="correlations.html#correlations">2.6</a>).</p>
<div class="sourceCode" id="cb175"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb175-1"><a href="assumptions.html#cb175-1" aria-hidden="true" tabindex="-1"></a><span class="fu">assoc</span>(mtcars)</span></code></pre></div>
<p>In order to cover the second situation with linear combination of variables, we can use the <code>determ()</code> (aka <code>determination()</code>) function from <code>greybox</code>:</p>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb176-1"><a href="assumptions.html#cb176-1" aria-hidden="true" tabindex="-1"></a><span class="fu">determ</span>(mtcars[,<span class="sc">-</span><span class="dv">1</span>])</span></code></pre></div>
<pre><code>##       cyl      disp        hp      drat        wt      qsec        vs        am 
## 0.9349544 0.9537470 0.8982917 0.7036703 0.9340582 0.8671619 0.7986256 0.7848763 
##      gear      carb 
## 0.8133441 0.8735577</code></pre>
<p>This function will construct linear regression models for each variable from all the other variables and report the <span class="math inline">\(R^2\)</span> from these models. If there are coefficients of determination close to one, then this might indicate that the variables would cause multicollinearity in the model. In our case, we see that <code>disp</code> is linearly related to other variables, and we can expect it to cause the reduction of efficiency of estimate of parameters. If we remove it from the consideration (we do not want to include it in our model anyway), then the picture will change:</p>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb178-1"><a href="assumptions.html#cb178-1" aria-hidden="true" tabindex="-1"></a><span class="fu">determ</span>(mtcars[,<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>)])</span></code></pre></div>
<pre><code>##       cyl        hp      drat        wt      qsec        vs        am      gear 
## 0.9299952 0.8596168 0.6996363 0.8384243 0.8553748 0.7965848 0.7847198 0.8121855 
##      carb 
## 0.7680136</code></pre>
<p>Now <code>cyl</code> has linear relation with some other variables, so it would not be wise to include it in the model with the other variables. We would need to decide, what to include based on our understanding of the problem.</p>
<p>Instead of calculating the coefficients of determination, econometricians prefer to calculate Variance Inflation Factor (VIF), which shows by how many times the estimates of parameters will loose efficiency. Its formula is based on the <span class="math inline">\(R^2\)</span> calculated above:
<span class="math display">\[\begin{equation*}
  \mathrm{VIF}_j = \frac{1}{1-R_j^2}
\end{equation*}\]</span>
for each model <span class="math inline">\(j\)</span>. Which in our case can be calculated as:</p>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="assumptions.html#cb180-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span><span class="sc">/</span>(<span class="dv">1</span><span class="sc">-</span><span class="fu">determ</span>(mtcars[,<span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>)]))</span></code></pre></div>
<pre><code>##       cyl        hp      drat        wt      qsec        vs        am      gear 
## 14.284737  7.123361  3.329298  6.189050  6.914423  4.916053  4.645108  5.324402 
##      carb 
##  4.310597</code></pre>
<p>This is useful when you want to see the specific impact on the variance of parameters, but is difficult to work with, when it comes to model diagnostics, because the value of VIF lies between zero and infinity. So, I prefer using the determination coefficients instead, which is always bounded by <span class="math inline">\((0, 1)\)</span> region and thus easier to interpret.</p>
<p>Finally, in some cases nothing can be done with multicollinearity, it just exists, and we need to include those correlated variables. This might not be a big problem, as long as we acknowledge the issues it will cause to the estimates of parameters.</p>
</div>
<div id="engogeneity" class="section level4" number="3.6.3.2">
<h4><span class="header-section-number">3.6.3.2</span> Engogeneity</h4>
<p><strong>Endogeneity</strong> applies to the situation, when the dependent variable <span class="math inline">\(y_t\)</span> influences the explanatory variable <span class="math inline">\(x_t\)</span> in the model on the same observation. The relation in this case becomes bi-directional, meaning that the basic model is not appropriate in this situation any more. The parameters and forecasts will typically be <em>biased</em>, and a different estimation method would be needed or maybe a different model would need to be constructed in order to fix this.</p>
<p>Endogeneity cannot be properly diagnosed and comes to the judgment: do we expect the relation between variable to be one directional or bi-directional? Note that if we work with time series, then endogeneity would only appear, when the bi-directional relation happens at the same time <span class="math inline">\(t\)</span>, not over time.</p>
</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Hanck2020" class="csl-entry">
â¢ Hanck, C., Arnold, M., Gerber, A., Schmelzer, M., 2020. <span class="nocase">Introduction to Econometrics with R</span>. <a href="https://www.econometrics-with-r.org/index.html">https://www.econometrics-with-r.org/index.html</a> (version: 2020-08-12)
</div>
</div>

            </section>

          </div>
        </div>
      </div>
<a href="variablesTransformations.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="likelihoodApproach.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/config-i1/adam/tree/master/Chapters//03-regression.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["adam.pdf", "adam.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
