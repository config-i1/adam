# General ADAM ETS model {#ADAMETSOther}
Now that we have discussed two special cases of ADAM ETS models (namely [pure additive](#ADAMETSPureAdditive) and [pure multiplicative](#ADAMETSPureMultiplicative) ADAM ETS), we can move to the discussion of the general model and other special cases of it, such as mixed models. We will consider two important groups of mixed ADAM ETS models: with non-multiplicative and with multiplicative trends. They have very different properties that are worth mentioning. Finally, we will discuss the question of normalisation of seasonal indices. This topic has been discussed in the literature back in 80s, when we still did not have a proper ETS model and then was summarised in Chapter 8 of @Hyndman2008b. In Section \@ref(ADAMETSSeasonalNormalisation), we take a more critical view towards the topic.


## Model formulation {#ADAMETSGeneral}
Based on the discussion in previous Chapters, we can summarise the general ADAM ETS model. It is built upon the conventional model discussed in Section \@ref(ETSConventionalModel) but has several important differences, the most important of which is that it is formulated using lags of components rather than the transition of them over time (this was discussed in Section \@ref(ADAMETSPureAdditive)), so the original model \@ref(eq:ETSConventionalStateSpace) is rewritten in the following way:
\begin{equation}
  \begin{aligned}
    {y}_{t} = &w(\mathbf{v}_{t-\boldsymbol{l}}) + r(\mathbf{v}_{t-\boldsymbol{l}}) \epsilon_t \\
    \mathbf{v}_{t} = &f(\mathbf{v}_{t-\boldsymbol{l}}) + g(\mathbf{v}_{t-\boldsymbol{l}}) \epsilon_t
  \end{aligned},
  (\#eq:ETSADAMStateSpace)
\end{equation}
where $\mathbf{v}_{t-\boldsymbol{l}}$ is the vector of lagged components and $\boldsymbol{l}$ is the vector of lags, while all the other functions corresponds to the ones used in \@ref(eq:ETSConventionalStateSpace). This model form is mainly useful for the formulation, rather than for the derivations, as discussed in Section \@ref(ETSConventionalModel). Not only it encompasses any pure models, it also allows formulating any of the mixed ones. For example, the ETS(M,A,M) will have the following values:
\begin{equation}
  \begin{aligned}
    w(\mathbf{v}_{t-\boldsymbol{l}}) = (l_{t-1}+b_{t-1}) s_{t-m}, &
    r(\mathbf{v}_{t-\boldsymbol{l}}) = w(\mathbf{v}_{t-\boldsymbol{l}}) & 
    f(\mathbf{v}_{t-\boldsymbol{l}}) = \begin{pmatrix} l_{t-1} + b_{t-1} \\ b_{t-1} \\ s_{t-m} \end{pmatrix}, & \\
    g(\mathbf{v}_{t-\boldsymbol{l}}) = \begin{pmatrix} \alpha (l_{t-1} + b_{t-1}) \\ \beta (l_{t-1} + b_{t-1}) \\ \gamma s_{t-m} \end{pmatrix}, &
    \mathbf{v}_{t} = \begin{pmatrix} l_t \\ b_t \\ s_t \end{pmatrix}, &
    \boldsymbol{l} = \begin{pmatrix} 1 \\ 1 \\ m \end{pmatrix} &
    \mathbf{v}_{t-\boldsymbol{l}} = \begin{pmatrix} l_{t-1} \\ b_{t-1} \\ s_{t-m} \end{pmatrix}
  \end{aligned}.
  (\#eq:ETSADAMMAMMatrices)
\end{equation}
By inserting \@ref(eq:ETSADAMMAMMatrices) in \@ref(eq:ETSADAMStateSpace) we will get the classical ETS(M,A,M) model, mentioned in Section \@ref(ETSTaxonomyMaths):
\begin{equation}
  \begin{aligned}
    y_{t} = & (l_{t-1} + b_{t-1}) s_{t-m}(1 + \epsilon_t) \\
    l_t = & (l_{t-1} + b_{t-1})(1 + \alpha \epsilon_t) \\
    b_t = & b_{t-1} + (l_{t-1} + b_{t-1}) \beta \epsilon_t \\
    s_t = & s_{t-m} (1 + \gamma \epsilon_t) 
  \end{aligned}.
  (\#eq:ETSADAMMAM)
\end{equation}
The model \@ref(eq:ETSADAMStateSpace) with different values for the functions is the basis of `adam()` function from `smooth` package.


## Mixed ADAM ETS models {#ADAMETSMixedModels}
@Hyndman2008b proposed five classes of ETS models, based on the types of their components:

1. ANN; AAN; AAdN; ANA; AAA; AAdA;
2. MNN; MAN; MAdN; MNA; MAA; MAdA;
3. MNM; MAM; MAdM;
4. MMN; MMdN; MMM; MMdM;
5. ANM; AAM; AAdM; MMA; MMdA; AMN; AMdN; AMA; AMdA; AMM; AMdM

The `ets()` model from `forecast` package supports only the Classes 1 - 4. The Class 5 models are not included in the function mainly because they have infinite variances, specifically on long horizons and when the data has low values. Indeed, when the level in one of these models becomes close to zero, there is an increased chance of breaking the model due to the appearance of negative values (think of ETS(A,A,M) model, which might have a negative trend, leading to negative values, which are then multiplied by the positive seasonal indices). That is why in practice these models should only be used, when the level of the series is high. Furthermore, some of the models from the Class 5 are very difficult to estimate and are very sensitive to the smoothing parameters values. All of this gives a rationale for restricting the pool of models to the 19 from classes 1 - 4.

@Hyndman2008b demonstrate that models from the class 2 have closed forms of conditional expectation and variance, with the former corresponding to the point forecasts. However, the conditional distribution from these models is not Gaussian, so there are no formulae for the prediction intervals from these models. Yes, in some cases Normal distribution might be a fine approximation for the real one, but in general simulations should be preferred.

Class 3 models suffer from similar issues, but the situation worsens: there are no analytical solutions for the conditional mean and variance, and there are only approximations to these statistics.

Class 4 models have been discussed in [the previous section](#ADAMETSPureMultiplicative).

To be fair, any mixed model can potentially break, when the level of series is close to zero. For example, ETS(M,A,N) can have the negative trend, which might lead to the negative level and as a result to the multiplication of pure positive error term by the negative components. Estimating such a model on real data becomes a non-trivial task. In addition, as discussed above, simulations are typically needed in order to get adequate estimates of prediction interval for models of classes 2 - 5 and conditional mean and variance for models fo classes 4 - 5. All of this in my opinion means that the more useful classification of ETS models is the following:

1. [Pure additive models](#ADAMETSPureAdditive): ANN; AAN; AAdN; ANA; AAA; AAdA;
2. [Pure multiplicative models](#ADAMETSPureMultiplicative): MNN; MMN; MMdN; MNM; MMM; MMdM;
3. [Mixed models with non-multiplicative trend](#ADAMETSMixedModelsGroup3): MAN; MAdN; MNA; MAA; MAdA; MAM; MAdM; ANM; AAM; AAdM;
4. [Mixed models with multiplicative trend](#ADAMETSMixedModelsGroup4): MMA; MMdA; AMN; AMdN; AMA; AMdA; AMM; AMdM;

The main idea behind the split to (3) and (4) is because the presence of multiplicative trend makes it almost impossible to derive the formulae for the conditional moments of distribution. So this class of models can be considered as the most challenging.

`adam()` function supports all 30 ETS models, but you should keep in mind the limitations of some of them discussed in this section.


## Mixed models with non-multiplicative trend {#ADAMETSMixedModelsGroup3}
In this class of models, there are two subclasses: one with non-multiplicative seasonal component (MAN, MAdN, MNA, MAA, MAdA) and another one with the multiplicative one (MAM; MAdM; ANM; AAM; AAdM). The conditional mean for the former models coincides with the point forecasts, while the conditional variance can be calculated using the following recursive formula [@Hyndman2008b]:
\begin{equation}
	\begin{aligned}
	& \text{V}(y_{t+h}|t) = (1+\sigma^2) \xi_h - \mu_{t+h|t}^2 \\
	& \text{where } \xi_{1} = \mu_{t+1|t}^2 \text{ and } \xi_h = \mu_{t+h|t}^2 + \sigma^2 \sum_{j=1}^{h-1} c_{j}^2 \xi_{h-j}
	\end{aligned} ,
	(\#eq:ETSADAMMixedModels31Variance)
\end{equation}
where $\sigma^2$ is the variance of the error term. As for the second subgroup, the conditional mean corresponds to the point forecasts, when the forecast horizon is less than or equal to the seasonal frequency of the component (i.e. $h\leq m$), and there is a cumbersome formula for calculating the conditional mean to some of models in this subgroup for the $h>m$. When it comes to the conditional variance, there exists the formula for some of models in the second subgroup, but they are cumbersome as well. The interested reader is directed to @Hyndman2008b, page 85.

When it comes to the parameters bounds for the models in this group, the first subgroup of models should have [similar bounds to the ones for the respective additive error](#stabilityConditionAdditiveError) models (because both underly the same exponential smoothing methods), but with additional restrictions, comming from [the multiplicative error](#stabilityConditionMultiplicativeError).

1. The *traditional bounds* (aka "usual") should work fine for these models for the same reasons they work for the pure additive models, although they might be too restrictive in some cases;
2. The *admissible bounds* for smoothing parameters for the models in this group might be too wide and violate the condition of $(1+ \alpha \epsilon_t)>0, (1+ \beta \epsilon_t)>0, (1+ \gamma \epsilon_t)>0$, which is important in order not to break the models.

The second subgroup is more challenging in terms of parameters bounds because of the multiplication of states by the seasonal components. 

## Mixed models with multiplicative trend {#ADAMETSMixedModelsGroup4}
This is the most difficult class of models (MMA; MMdA; AMN; AMdN; AMA; AMdA; AMM; AMdM). These do not have analytical formulae for conditional moments, they are very sensitive to the values of smoothing parameters and may lead to explosive forecasting trajectories. So, in order to obtain conditional expectation, variance and prediction interval from the models of this classs, simulations should be used.

One of the issues that can be encountered, when using these models is the explosive trajectories because of the multiplicative trend. As a result, when these models are estimated, it makes sense to set the initial value of trend to 1 or a lower value, so that the optimiser does not encounter difficulties in the calculations.

Furthermore, the combination of components for the models in this class makes even less sense than the combination for [the previous class](#ADAMETSMixedModelsGroup3) of models. For example, the multiplicative trend assumes either the explosive growth or decay as shown on the following two figures:

```{r echo=FALSE}
par(mfcol=c(1,2))
plot(exp(0.05*c(1:100)),type="l",ylab="Demand",xlab="Time")
plot(exp(-0.05*c(1:100)),type="l",ylab="Demand",xlab="Time")
```

Assuming that either seasonal component, or the error term, or both will have exactly the same impact on the final value irrespective of the point of time is unrealistic for these situation. The more reasonable would be for the amplitude of seasonality to decrease together with the exponential decay of the trend and for the variance of the error term to do the same. But this means that we are talking about the [pure multiplicative models](#ADAMETSPureMultiplicative), not the mixed ones. There is only one situation, where such mixed models could make sense: when the speed of change of the exponential trajectory is close to zero, meaning that the level of the series does not change rapidly and when the volume of the data is high. In this case the mixed models might perform well and even produce more accurate forecasts than the models from the other classes.

When it comes to the parameters bounds, this is a mistery for the mixed models. This is because the recursive relations are complicated and calculating the discount matrix or anything like that becomes a challenging task. Using the usual bounds should still be okay, but keep in mind that these mixed models are typically not very stable, so from my experience the smoothing parameters should be as low as possible, assuming that the initial values guarantee a working model (not breaking at some of observations).


## Normalisation of seasonal indices in ETS models {#ADAMETSSeasonalNormalisation}
One of the ideas arrising from [time series decomposition](#ClassicalDecomposition), inheritted by the conventional ETS, is the idea of renormalisation of seasonal indices. It comes to one of the two principles, depending on the type of seasonality:

1. If the model has additive seasonality, then the seasonal indices should add up to zero in a specific period of time, e.g. monthly indices should add up to 0 over a yearly period;
2. If the model has multiplicative seasonality, then the geometric mean of seasonal indices over a specific period should be equal to one.

(2) in the conventional ETS is substituted by "the arithmetic mean of multiplicative indices should be equal to one", which does not have good grounds behind it - if we deal with multiplicative effect, then the geometric mean should be used, not the arithmetic one, otherwise by multiplying components by indices we introduce bias in the model. While the normalisation is a natural element of the time series decomposition and works fine for the initial seasonal indices, renormalising the seasonal indices over time might not be a natural idea for the ETS.

@Hyndman2008b discuss different mechanisms for the renormalisation of seasonal indices, which as the authors claim are needed in order to make the principles (1) and (2) hold from period to period in the data. However, I argue that this is an unnatural idea for the ETS models, that the indices should only be normalised during the initialisation of the model (at the moment $t=0$) and that they should vary independently for the rest of the sample. The rationale for this comes from the model itself. To illustrate it, I will use ETS(A,N,A), but the idea can be easily used for any other ETS model with any types of components and any number of seasonal frequencies. Just a reminder, the model can be formulated as:
\begin{equation}
  \begin{aligned}
  y_t = &l_{t-1} + s_{t-m} + \epsilon_t \\
  {l}_{t} = &l_{t-1} + \alpha\epsilon_t \\
  s_t = &s_{t-m} + \gamma\epsilon_t
  \end{aligned}.
  (\#eq:ETSANAExampleNormalisation)
\end{equation}
Let's assume that this is the true model for whatever data we have for whatever reasons. In this case the set of equations \@ref(eq:ETSANAExampleNormalisation) tells us that the seasonal indices change over time, depending on the values of the smoothing parameter $\gamma$ and each specific values of $\epsilon_t$, which is assumed to be i.i.d. All seasonal indeces $s_{t+i}$ in a specific period (e.g. monthly indices in a year) can be written down explicitly based on \@ref(eq:ETSANAExampleNormalisation):
\begin{equation}
  \begin{aligned}
  s_{t+1} = &s_{t+1-m} + \gamma\epsilon_{t+1} \\
  s_{t+2} = &s_{t+2-m} + \gamma\epsilon_{t+2} \\
  \vdots \\
  s_{t+m} = &s_{t} + \gamma\epsilon_{t+m}
  \end{aligned}.
  (\#eq:ETSANAExampleNormalisationIndices01)
\end{equation}
If this is how the data is "generated" and the seasonality evolves over time, then there is only one possibility, for the indices $s_{t+1}, s_{t+2}, \dots, s_{t+m}$ to add up to zero:
\begin{equation}
  \begin{aligned}
  &s_{t+1}+ s_{t+2}+ \dots+ s_{t+m} = 0 \\
  &s_{t+1-m}+ s_{t+2-m}+ \dots+ s_{t} + \gamma \left(\epsilon_{t+1}+ \epsilon_{t+2}+ \dots+ \epsilon_{t+m}\right) = 0
  \end{aligned}.
  (\#eq:ETSANAExampleNormalisationIndices02)
\end{equation}
meaning that:

a. the previous indices $s_{t+1-m}, s_{t+2-m}, \dots, s_{t}$ add up to zero **and**
b. either $\gamma=0$,
c. or the sum of error terms $\epsilon_{t+1}, \epsilon_{t+2}, \dots, \epsilon_{t+m}$ is zero.

Note that we do not consider the situation $s_{t+1-m}+ \dots+ s_{t} = - \gamma \left(\epsilon_{t+1}+ \dots+ \epsilon_{t+m}\right)$ as it does not make sense. The condition (a) can be considered reasonable if the previous indices are normalised. (b) means that the seasonal indices do not evolve over time. However, (c) implies that the error term is not independent, because $\epsilon_{t+m} = -\epsilon_{t+1}- \epsilon_{t+2}- \dots- \epsilon_{t+m-1}$, which violates one of the [basic assumptions](#assumptions) of the model, meaning that \@ref(eq:ETSANAExampleNormalisationIndices02) cannot be considered as the "true" model anymore, as it omits some important elements.

The other case, when each seasonal index is updated on each observation $t$ (to make sure that the indices are normalised), does not make sense either. In this situation we have:
\begin{equation}
  \begin{aligned}
  &s_t = s_{t-m} + \gamma\epsilon_t \\
  &s_{t-m+1}+ s_{t-m+2}+ \dots+ s_{t-1} + s_{t} = 0
  \end{aligned},
  (\#eq:ETSANAExampleNormalisationIndices03)
\end{equation}
which can be rewritten as $s_{t-m} + \gamma\epsilon_t = -s_{t+1-m}- s_{t+2-m}- \dots- s_{t-1}$, meaning that:
\begin{equation}
  \begin{aligned}
  s_{t-m}+ s_{t+1-m}+ s_{t+2-m}+ \dots+ s_{t-1} = -\gamma\epsilon_t
  \end{aligned},
  (\#eq:ETSANAExampleNormalisationIndices03)
\end{equation}
but due to the normalisation, the sum on the left hand side should be equal to zero, implying that either $\gamma=0$ or $\epsilon_t=0$. While former might hold in some cases (deterministic seasonality), the latter cannot hold for all $t=1,\dots,T$ and violates the assumptions of the model.

The discussion in this section demonstrate that the renormalisation of seasonal indices is unnatural for the ETS model and should not be used. Having said that, this does not imply that the initial seasonal indices (those that correspond to the observation $t=0$) cannot be normalised. In fact, the normalisation of the initial indices allows reducing the number of estimated parameters in the model.
