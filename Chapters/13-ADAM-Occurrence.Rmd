# Intermittent State Space Model {#ADAMIntermittent}
So far, we have discussed data that has regular occurrence (i.e. happening every observation). For example, daily sales of bread in a supermarket would have this regularity. However, there are time series where non-zero values do not happen on every observation. In the context of demand forecasting, this is called "**intermittent demand**". The conventional example of such demand is monthly sales of jet engines: they will contain a lot of zeroes, when nobody buys the product and then all of a sudden several units when an aeroplane company decides to buy it, again followed by zeroes. However, this problem does not only apply to such expensive exotic products -- the retailers face this all the time for various products, mainly when sales are recorded daily or on an even higher frequency.

One of the most straightforward definitions of intermittent demand is that *it is the demand that happens at irregular frequency*. This means that we cannot tell with 100% certainty, when specifically customers will buy our product. In fact, if we zoom in on the sales of any product and observe it at a higher frequency, we will most probably see intermittent demand. For example, if we work with hourly sales of products in a supermarket, we will most probably observe intermittent demand because there will be some hours of day, when supermarket will have few customers and thus will not sell some products at all. However, if we aggregate this data to a weekly level, the intermittence will typically disappear, making the demand look regular. So, intermittent demand is related to the regular one, and in many cases arises on the lower aggregation levels.

You might also meet the term "count data" (or "integer-valued data") in a similar context, but there is a fundamental difference between the count and intermittent data. The former implies that demand can take integer values only and can be typically modelled via Poisson, Binomial, or Negative Binomial distributions. It does not necessarily contain zeroes and does not explicitly allow demand to happen at random. In this case, if there are zeroes, then it is assumed that they are just one of the possible values of a distribution. On the other hand, in the case of intermittent demand, we explicitly acknowledge that demand might not happen, but if it happens, then the value will be greater than zero. Furthermore, intermittent demand does not necessarily need to be integer-valued. For example, daily energy consumption for charging electric vehicles would typically be intermittent (because the vehicle owners do not charge them every day), but the non-zero consumption will not be an integer. Still, count distributions can be used in some cases of intermittent demand, but they do not necessarily always provide a good approximation of complex reality.

Before we move towards the proper discussion of the topic in the context of ADAM, we should acknowledge that at the heart of what follows, there lies the following model [@Croston1972]:
\begin{equation}
	y_t = o_t z_t ,
	(\#eq:IntermittentDemandModel)
\end{equation}
where $o_t$ is the demand occurrence variable, which can be either zero or one and has some probability of occurrence $p_t$, $z_t$ is the demand sizes captured by a model (for example, ETS), and $y_t$ is the final observed demand. In the context of intermittent demand, this model was originally proposed by @Croston1972, but similar models (e.g. Hurdle and Zero Inflated Poisson) exist in other, non-forecasting related literature.

In this chapter, we will discuss the intermittent state space model \@ref(eq:IntermittentDemandModel), both parts of which can be modelled via ADAM, and we will see how they can be used, what they imply and how they connect to the conventional regular demand. If an ETS model is used for $z_t$ then \@ref(eq:IntermittentDemandModel) will be called iETS. So, the iETS(M,N,N) model refers to the intermittent state space model, where demand sizes are modelled via ETS(M,N,N). ETS can also be used for the occurrence part of the model, so if the discussion is focused on the demand occurrence part of the model, $o_t$ (as in Section \@ref(ADAMOccurrence)), we will use "oETS" instead. Similarly, we can use the terms iARIMA and oARIMA, referring either to the whole model or just to its occurrence part. Note, however, that while ARIMA can be used in theory, it is not yet implemented for the occurrence part of the model. So we will focus the discussion in this chapter on the ADAM ETS. Furthermore, depending on how the occurrence part is modelled, the notations above can be expanded to include references to specific parts of the occurrence part of the model. This is discussed in detail in Section \@ref(ADAMOccurrence).

This chapter is based on @Svetunkov2019a. If you want to know more about intermittent demand forecasting, @BoylanSyntetos2021 is an excellent textbook on the topic, covering all the main aspects in appropriate detail.


## Occurrence part of the model {#ADAMOccurrence}
The general model \@ref(eq:IntermittentDemandModel) assumes that demand occurs randomly and that the variable $o_t$ can be either zero (no demand) or one (there is some demand). While this process can be modelled using different distributions, @Svetunkov2019a proposed using Bernoulli with a time varying probability:
\begin{equation}
	o_t \sim \text{Bernoulli} \left(p_t \right) ,
	(\#eq:OccurrenceModelBernoulli)
\end{equation}
where $p_t$ is the probability of occurrence. The higher it is, the more frequently the demand will happen. If $p_t=1$, then the demand becomes regular, while if $p_t=0$, nobody buys the product at all. This section will discuss different types of models for the probability of occurrence. For each of them, there are different mechanisms of the model construction, estimation, error calculation, update of the states, and the generation of forecasts. To estimate any of these models, I recommend using likelihood, which can be calculated based on the Probability Mass Function (PMF) of Bernoulli distribution:
\begin{equation}
	f_o(o_t, p_t) = p_t^{o_t}(1-p_t)^{1-o_t}.
	(\#eq:BernoulliPMF)
\end{equation}
The parameters of the occurrence part of the model can be then estimated via the maximisation of the log-likelihood function, which comes directly from \@ref(eq:BernoulliPMF), and in the most general case is:
\begin{equation}
	\ell \left(\boldsymbol{\theta}_o | \mathbf{o} \right) = \sum_{o_t=1} \log(\hat{p}_t) + \sum_{o_t=0} \log(1-\hat{p}_t) ,
	(\#eq:oETSLikelihood)
\end{equation}
where $\hat{p}_t$ is the in-sample conditional one step ahead expectation of the probability on observation $t$, given the information on observation $t-1$, which depends on the vector of estimated parameters for the occurrence part of the model $\boldsymbol{\theta}_o$.

In order to demonstrate the difference between specific types of oETS models, we will use the following artificial data:
```{r artificialData, eval=FALSE}
y <- ts(c(rpois(20,0.25), rpois(20,0.5), rpois(20,1),
          rpois(20,2), rpois(20,3), rpois(20,5)))
```

```{r echo=FALSE}
load("data/oETSData.Rdata")
```

Figure \@ref(fig:intermittentExamplePlot) shows how the data looks:

```{r intermittentExamplePlot, fig.cap="Example of intermittent demand data."}
plot(y, ylab="Sales")
```

The probability of occurrence in this example increases together with the demand sizes. This example corresponds to the situation of intermittent demand for a product evolving to the regular one.


### Fixed probability model, oETS$_F$
We start with the simplest case of fixed probability of occurrence, the oETS$_F$ model:
\begin{equation}
	o_t \sim \text{Bernoulli}(p) ,
	(\#eq:oETSFixed)
\end{equation}
This model assumes that demand happens with the same probability no matter what. This might sound exotic because, in practice, there might be many factors influencing customers' desire to purchase, and the impact of these factors might change over time. But this is a basic model, which can be used as a benchmark on intermittent demand data. Furthermore, it might be suitable for modelling demand on expensive high-tech products, such as jet engines, which is "very slow" in its nature and typically does not evolve much over time.

When estimated via maximisation of the likelihood function \@ref(eq:oETSLikelihood), the probability of occurrence in this model is equal to:
\begin{equation}
	\hat{p} = \frac{T_1}{T},
	(\#eq:oETSFixedProbabilityMLE)
\end{equation}
where $T_1$ is the number of non-zero observations and $T$ is the number of all the available observations in-sample.

The occurrence part of the model, oETS$_F$ can be constructed using the `oes()` function from the `smooth` package:

```{r oETSFExample1}
oETSFModel <- oes(y, h=10, holdout=TRUE,
                  occurrence="fixed")
oETSFModel
```

The oETS$_F$ model produces the straight line for the probability of `r round(oETSFModel$initial,2)`, ignoring that in our example, the probability of occurrence has increased over time.

```{r oETSFModel, fig.cap="Demand occurrence and probability of occurrence in the oETS$_F$ model."}
plot(oETSFModel)
```

The plot in Figure \@ref(fig:oETSFModel) demonstrates the dynamics of the occurrence variable $o_t$ and the fitted and predicted probabilities. The solid line shows when zeroes and ones happen, depicting the variable $o_t$. The dashed line corresponds to the fixed probability of occurrence $\hat{p}$ in the sample.


### Odds ratio model, oETS$_O$ {#oETSO}
In this model, it is assumed that the update of the probability is driven by the previously observed occurrence of a variable. It is more complicated than the previous model, as the probability now changes over time and can be modelled, for example, with an ETS(M,N,N) model:
\begin{equation}
	\begin{aligned}
		& o_t \sim \text{Bernoulli} \left(p_t \right) \\
		& p_t = \frac{\mu_{a,t}}{\mu_{a,t}+1} \\
		& a_t = l_{a,t-1} \left(1 + \epsilon_{a,t} \right) \\
		& l_{a,t} = l_{a,t-1}( 1  + \alpha_{a} \epsilon_{a,t}) \\
		& \mu_{a,t} = l_{a,t-1}
	\end{aligned},
	(\#eq:oETSOddsMNN)
\end{equation}
where $l_{a,t}$ is the unobserved level component, $\alpha_{a}$ is the smoothing parameter, $1+\epsilon_{a,t}$ is the error term , which is positive, has the mean of one, and follows an unknown distribution, and $\mu_{a,t}$is the conditional expectation for the unobservable shape variable $a_t$. The measurement and transition equations in \@ref(eq:oETSOddsMNN) can be substituted by any other ETS, ARIMA, or regression model if it is reasonable to assume that the probability dynamic has some additional components, such as trend, seasonality, or exogenous variables. This model is called the "odds ratio" because the probability of occurrence in \@ref(eq:oETSOddsMNN) is calculated using the classical logistic transform. This also means that $\mu_{a,t}$ equals to:
\begin{equation} \label{eq:oETS_O_oddsRatio}
\mu_{a,t} = \frac{p_t}{1 -p_t} .
\end{equation}
When $\mu_{a,t}$ increases in the oETS\textsubscript{O} model, the odds ratio increases as well, meaning that the probability of occurrence goes up. @Svetunkov2019a explain that this model is, in theory, appropriate for the demand for products becoming obsolescent, because the multiplicative error ETS models asymptotically almost surely converge to zero. Still, given the updating mechanism, it should also work fine on other types of intermittent data.

When it comes to the application of the model to the data, its construction is done via the following set of equations (example with oETS$_O$(M,N,N)):
\begin{equation}
	\begin{aligned}
		& \hat{p}_t = \frac{\hat{\mu}_{a,t}}{\hat{\mu}_{a,t}+1} \\
		& \hat{\mu}_{a,t} = \hat{l}_{a,t-1} \\
		& \hat{l}_{a,t} = \hat{l}_{a,t-1}( 1  + \hat{\alpha}_{a} e_{a,t}) \\
		& 1+e_{a,t} = \frac{u_t}{1-u_t} \\
		& u_{t} = \frac{1 + o_t -\hat{p}_t}{2}
	\end{aligned},
	(\#eq:oETSOddsMNNEstimated)
\end{equation}
where $e_{a,t}$ is the proxy for the unobservable error term $\epsilon_{a,t}$ and $\hat{\mu}_t$ is the estimate of $\mu_{a,t}$. If a multiple steps ahead forecast for the probability is needed from this model, then the formulae discussed in Section \@ref(ETSTaxonomyMaths) can be used to get $\hat{\mu}_{a,t+h}$, which then can be inserted in the first equation of \@ref(eq:oETSOddsMNNEstimated) to get the final conditional multiple steps ahead probability of occurrence.

Finally, to estimate the parameters of the model \@ref(eq:oETSOddsMNNEstimated), the likelihood \@ref(eq:oETSLikelihood) can be used.

The occurrence model oETS$_O$ is constructed using the very same `oes()` function, but also allows specifying the ETS model to use. For example, here is the oETS$_O$(M,M,N) model:
```{r oETSOExample1}
oETSOModel <- oes(y, model="MMN", h=10, holdout=TRUE,
                  occurrence="odds-ratio")
oETSOModel
```

In this example, we introduce the multiplicative trend in the model, which is supposed to reflect the idea of demand building up over time.

```{r oETSOModel, fig.cap="Demand occurrence and probability of occurrence in the oETS(M,M,N)$_O$ model.", echo=FALSE}
plot(oETSOModel)
```

Figure \@ref(fig:oETSOModel) shows that the model captures the changing probability of occurrence well, reflecting that it increases over time. Also notice how the model reacts more to the zeroes, in the beginning of the zeroes rather than to ones at the end. This is the main distinguishing characteristic of the model.


### Inverse odds ratio model, oETS$_I$ {#oETSI}
Using a similar approach to the oETS$_O$, we can formulate the "inverse odds ration" model oETS$_I$(M,N,N):
\begin{equation}
	\begin{aligned}
		& o_t \sim \text{Bernoulli} \left(p_t \right) \\
		& p_t = \frac{1}{1+\mu_{b,t}} \\
		& b_t = l_{b,t-1} \left(1 + \epsilon_{b,t} \right) \\
		& l_{b,t} = l_{b,t-1}( 1  + \alpha_{b} \epsilon_{b,t}) \\
		& \mu_{b,t} = l_{b,t-1}
	\end{aligned},
	(\#eq:oETSInverseOddsMNN)
\end{equation}
where similarly to \@ref(eq:oETSOddsMNNEstimated), $l_{b,t}$ is the unobserved level component, $\alpha_{b}$ is the smoothing parameter, $1+\epsilon_{b,t}$ is the positive error term with a mean of one, and $\mu_{b,t}$ is the one step ahead conditional expectation for the unobservable shape parameters $b_t$. The main difference between this model and the previous one is in the mechanism of probability calculation, which relies on the probability of "inoccurrence", i.e. on zeroes of data rather than on ones. This type of model should be more appropriate for cases of demand building up [@Svetunkov2019a]. The probability calculation mechanism in \@ref(eq:oETSInverseOddsMNN) implies that $\mu_{b,t}$ can be expressed as:
\begin{equation}
\mu_{b,t} = \frac{1-p_t}{p_t} .
\end{equation}

The construction of the model \@ref(eq:oETSInverseOddsMNN) is similar to \@ref(eq:oETSOddsMNNEstimated):
\begin{equation}
	\begin{aligned}
		& \hat{p}_t = \frac{1}{1+\hat{\mu}_{b,t}} \\
		& \hat{\mu}_{b,t} = \hat{l}_{b,t-1} \\
		& \hat{l}_{b,t} = l_{b,t-1}( 1  + \hat{\alpha}_{b} e_{b,t}) \\
		& 1+e_{b,t} = \frac{1-u_t}{u_t} \\
		& u_{t} = \frac{1 + o_t -\hat{p}_t}{2}
	\end{aligned},
	(\#eq:oETSInverseOddsMNNEstimated)
\end{equation}
where $e_{b,t}$ is the proxy for the unobservable error term $\epsilon_{b,t}$ and $\hat{\mu}_{b,t}$ is the estimate of $\mu_{b,t}$. Once again, we refer an interested reader to Subsection \@ref(ETSTaxonomyMaths) for the discussion of the multiple steps ahead conditional expectations from the ETS(M,N,N) model.

@Svetunkov2019a show that the oETS$_I$(M,N,N) model, in addition to \@ref(eq:oETSInverseOddsMNNEstimated), can be estimated using Croston's method, as long as we can assume that the probability does not change over time substantially. In this case the demand intervals (the number of zeroes between demand sizes) can be used instead of $\hat{\mu}_{b,t}$ in \@ref(eq:oETSInverseOddsMNNEstimated). So the iETS(M,N,N)$_I$(M,N,N) can be considered as a model underlying Croston's method.

The function `oes()` implements the oETS$_I$ model as well. For example, here is the oETS$_I$(M,M,N) model:
```{r oETSIExample1}
oETSIModel <- oes(y, model="MMN", h=10, holdout=TRUE,
                  occurrence="inverse-odds-ratio")
oETSIModel
```

```{r oETSIModel, fig.cap="Demand occurrence and probability of occurrence in the oETS(M,M,N)$_I$ model.", echo=FALSE}
plot(oETSIModel)
```

Figure \@ref(fig:oETSIModel) shows that similarly to the oETS$_O$, the model captures the trend in the probability of occurrence but has a higher smoothing parameter $\alpha_b$. Also notice how the update of states happens more often towards the second part of the data, when demand is building up and more ones appear in the data. The model is much more inert when it has many zeroes. This behaviour can be contrasted to the behaviour of oETS$_O$, which updated the states more frequently in the beginning of the series in our example.


### General oETS model, oETS$_G$ {#oETSG}
Uniting the oETS$_O$ with oETS$_I$, we can obtain the "general" model, which in the most general case can be summarised in the following set of state space equations:
\begin{equation}
	\begin{aligned}
		& p_t = f_p(\mu_{a,t}, \mu_{b,t}) \\
		& a_t = w_a(\mathbf{v}_{a,t-\boldsymbol{l}}) + r_a(\mathbf{v}_{a,t-\boldsymbol{l}}) \epsilon_{a,t} \\
		& \mathbf{v}_{a,t} = f_a(\mathbf{v}_{a,t-\boldsymbol{l}}) + g_a(\mathbf{v}_{a,t-\boldsymbol{l}}) \epsilon_{a,t} \\
		& b_t = w_b(\mathbf{v}_{b,t-\boldsymbol{l}}) + r_b(\mathbf{v}_{b,t-\boldsymbol{l}}) \epsilon_{b,t} \\
		& \mathbf{v}_{b,t} = f_b(\mathbf{v}_{b,t-\boldsymbol{l}}) + g_b(\mathbf{v}_{b,t-\boldsymbol{l}}) \epsilon_{b,t}
	\end{aligned} ,
	(\#eq:oETSG)
\end{equation}
where $\epsilon_{a,t}$, $\epsilon_{b,t}$, $\mu_{a,t}$, and $\mu_{b,t}$ have been defined in previous subsections, and the other elements correspond to the ADAM discussed in Chapter \@ref(ADAMETSIntroduction). Note that in this case two state space models similar to the one discussed in Section \@ref(ADAMETSGeneral) are used for the modelling of $a_t$ and $b_t$. These can be either ETS, or ARIMA, or regression, or any combination of those.

The general formula for the probability in the case of the multiplicative error model is:
\begin{equation}
	p_t = \frac{\mu_{a,t}}{\mu_{a,t}+\mu_{b,t}} ,
	(\#eq:oETSMZZ)
\end{equation}
while for the additive one, it is:
\begin{equation}
	p_t = \frac{\exp(\mu_{a,t})}{\exp(\mu_{a,t})+\exp(\mu_{b,t})} .
	(\#eq:oETSAZZ)
\end{equation}
This is because both $\mu_{a,t}$ and $\mu_{b,t}$ need to be strictly positive, while the additive error models support negative and positive values and zero. The canonical oETS model assumes that the pure multiplicative model is used for $a_t$ and $b_t$. This model type is positively defined for any values of error, trend, and seasonality, which is essential for the values of $a_t$ and $b_t$ and their expectations. If a combination of additive and multiplicative error models is used, then the additive part should be exponentiated before using the formulae to calculate the probability. So, the $f_p(\cdot)$ function from \@ref(eq:oETSG) maps the expectations from models A and B to the probability of occurrence, depending on the error type of the respective models:
\begin{equation}
\resizebox{0.85\textwidth}{!}{$
	p_t = f_p(\mu_{a,t}, \mu_{b,t}) = \left \lbrace
	\begin{aligned}
		& \frac{\mu_{a,t}}{\mu_{a,t} + \mu_{b,t}} \text{ when both have multiplicative errors} \\
		& \frac{\mu_{a,t}}{\mu_{a,t} + \exp(\mu_{b,t})} \text{ when model B has additive error} \\
		& \frac{\exp(\mu_{a,t})}{\exp(\mu_{a,t}) + \mu_{b,t}} \text{ when model A has additive error} \\
		& \frac{\exp(\mu_{a,t})}{\exp(\mu_{a,t}) + \exp(\mu_{b,t})} \text{ when both have additive errors.}
	\end{aligned}
	\right. $}
	(\#eq:probabilityFunction)
\end{equation}

An example of the oETS model is the one based on two local level models (see discussion in Subsection \@ref(SESandETS)), oETS$_G$(M,N,N)(M,N,N):
\begin{equation}
	\begin{aligned}
		& o_t \sim \text{Bernoulli} \left(p_t \right) \\
		& p_t = \frac{\mu_{a,t}}{\mu_{a,t}+\mu_{b,t}} \\
		\\
		& a_t = l_{a,t-1} \left(1 + \epsilon_{a,t} \right) \\
		& l_{a,t} = l_{a,t-1}( 1  + \alpha_{a} \epsilon_{a,t}) \\
		& \mu_{a,t} = l_{a,t-1} \\
		\\
		& b_t = l_{b,t-1} \left(1 + \epsilon_{b,t} \right) \\
		& l_{b,t} = l_{b,t-1}( 1  + \alpha_{b} \epsilon_{b,t}) \\
		& \mu_{b,t} = l_{b,t-1} \\
	\end{aligned},
	(\#eq:oETSGExample)
\end{equation}
where all the parameters have already been defined in Subsections \@ref(oETSO) and \@ref(oETSI). More advanced models can be constructed for $a_t$ and $b_t$ by specifying the ETS models for each part and/or adding explanatory variables.

The construction of the model \@ref(eq:oETSGExample) is done via the following set of recursive equations:
\begin{equation}
	\begin{aligned}
		& e_{a,t} = \frac{u_t}{1-u_t} -1 \\
		& \hat{a}_t = \hat{l}_{a,t-1} \\
		& \hat{l}_{a,t} = \hat{l}_{a,t-1}( 1  + \alpha_{a} e_{a,t}) \\
		& e_{b,t} = \frac{1-u_t}{u_t} -1 \\
		& \hat{b}_t = \hat{l}_{b,t-1} \\
		& \hat{l}_{b,t} = \hat{l}_{b,t-1}( 1  + \alpha_{b} e_{b,t})
	\end{aligned} .
	(\#eq:oETSGExampleEstimated)
\end{equation}
<!-- The initialisation of the parameters of the oETS$_G$ model is done separately for the variables $a_t$ and $b_t$, based on the principles, described above for the oETS$_O$ and oETS$_I$. -->

In R, there is a separate function for the oETS$_G$ model, called `oesg()`. It has twice as many parameters as `oes()`, because it allows fine tuning of the models for the both parts $a_t$ and $b_t$. This gives an additional flexibility. For example, here is how we can use ETS(M,N,N) for the $a_t$ and ETS(A,A,N) for the $b_t$, resulting in oETS$_G$(M,N,N)(A,A,N):
```{r oETSGExample1}
oETSGModel <- oesg(y, modelA="MNN", modelB="AAN",
                   h=10, holdout=TRUE)
oETSGModel
```

```{r oETSGModel, fig.cap="Demand occurrence and probability of occurrence in the oETS(M,N,N)(A,A,N)$_G$ model.", echo=FALSE}
plot(oETSGModel)
```

We can also analyse models separately for $a_t$ and $b_t$ from the saved variable. Here is, for example, Model A:
```{r}
oETSGModel$modelA
```

The experiments that I have done so far show that oETS$_G$ very seldom brings improvements in comparison with oETS$_O$ or oETS$_I$ in terms of forecasting accuracy. Besides, selecting models for each of the parts is a challenging task. So, this model is theoretically attractive, being more general than the other oETS models, but is not very practical. Still it is useful because we can introduce different oETS models by restricting $a_t$ and $b_t$. For example, we can get:

1. oETS$_F$, when $\mu_{a,t} = \text{const}$, $\mu_{b,t} = \text{const}$ for all $t$;
2. oETS$_O$, when $\mu_{b,t} = 1$ for all $t$;
3. oETS$_I$, when $\mu_{a,t} = 1$ for all $t$;
4. oETS$_D$, when $\mu_{a,t} + \mu_{b,t} = 1$, $\mu_{a,t} \in [0,1]$ for all $t$ (discussed in Subsection \@ref(oETSD));
5. oETS$_G$, when there are no restrictions.


### Direct probability model, oETS$_D$ {#oETSD}
The last model in the family of oETS is the "Direct probability". It appears, when the following restriction is imposed on the oETS$_G$:
\begin{equation}
	\mu_{a,t} + \mu_{b,t} = 1, \mu_{a,t} \in [0, 1] .
	(\#eq:oETSGRestriction)
\end{equation}
This restriction is inspired by the mechanism for the probability update proposed by @Teunter2011 (TSB method). Their paper uses SES (discussed in Section \@ref(SES)) to model the time-varying probability of occurrence. Based on this idea and the restriction \@ref(eq:oETSGRestriction), we can formulate an oETS$_D$(M,N,N) model, which will underly the occurrence part of the TSB method:
\begin{equation}
	\begin{aligned}
		& o_t \sim \text{Bernoulli} \left(\mu_{a,t} \right) \\
		& a_t = l_{a,t-1} \left(1 + \epsilon_{a,t} \right) \\
		& l_{a,t} = l_{a,t-1}( 1  + \alpha_{a} \epsilon_{a,t}) \\
		& \mu_{a,t} = \min(l_{a,t-1}, 1)
	\end{aligned}.
	(\#eq:oETSD)
\end{equation}
There is also an option with the additive error for the occurrence part (also underlying TSB), which has a different, more complicated form:
\begin{equation}
	\begin{aligned}
		& o_t \sim \text{Bernoulli} \left(\mu_{a,t} \right) \\
		& a_t = l_{a,t-1} + \epsilon_{a,t} \\
		& l_{a,t} = l_{a,t-1}  + \alpha_{a} \epsilon_{a,t} \\
		& \mu_{a,t} = \max \left( \min(l_{a,t-1}, 1), 0 \right)
	\end{aligned}.
	(\#eq:oETSDAdditive)
\end{equation}

The estimation of the oETS$_D$(M,N,M) model can be done using the following set of equations:
\begin{equation}
	\begin{aligned}
		& \hat{\mu}_{a,t} = \hat{l}_{a,t-1} \\
		& \hat{l}_{a,t} = \hat{l}_{a,t-1}( 1  + \hat{\alpha}_{a} e_{a,t})
	\end{aligned},
	(\#eq:ISSETSMNNProbabilityEstimate)
\end{equation}
where
\begin{equation}
	e_{a,t} = \frac{o_t (1 -2 \kappa) + \kappa -\hat{\mu}_{a,t}}{\hat{\mu}_{a,t}},
	(\#eq:oETSDMultiplicativeError)
\end{equation}
and $\kappa$ is a very small number (for example, $\kappa = 10^{-10}$), needed only in order to make the model estimable. The estimate of the error term in case of the additive model is much simpler and does not need any specific tricks to work:
\begin{equation}
	e_{a,t} = o_t -\hat{\mu}_{a,t} ,
	(\#eq:oETSDAdditiveError)
\end{equation}
which is directly related to the TSB method. Note that equation \@ref(eq:ISSETSMNNProbabilityEstimate) does not contain the minimum function, because the estimated error \@ref(eq:oETSDMultiplicativeError) will always guarantee that the level will lie between 0 and 1 as long as the smoothing parameter lies in the [0, 1] region (which is the conventional assumption for both th ETS(A,N,N) and ETS(M,N,N) models). This also applies for the oETS$_D$(A,N,N) model, where the maximum and minimum functions can be dropped as long as the smoothing parameter lies in [0,1].

An important feature of this model is that it allows probability to become either 0 or 1, thus implying either that there is no demand on the product or that the demand for the product has become regular. No other oETS model permits that -- they assume that probability might become very close to bounds but can never reach them.

Here's an example of the application of the oETS$_D$(M,M,N) to the same artificial data:
```{r oETSDExample1}
oETSDModel <- oes(y, model="MMN", h=10, holdout=TRUE,
                  occurrence="direct")
oETSDModel
```

```{r oETSDModel, fig.cap="Demand occurrence and probability of occurrence in the oETS(M,M,N)$_D$ model.", echo=FALSE}
plot(oETSDModel)
```

From Figure \@ref(fig:oETSDModel), we can see that the probability of occurrence increases rapidly and reaches the bound of one around the 90th observation.

Practically speaking, using oETS$_D$ makes sense, when you expect the demand on your product either to disappear completely or to become regular. In other cases, oETS$_I$ and oETS$_O$ could be used efficiently. On M5 data, I found that the latter two models to performed very well in the majority of cases [@Svetunkov2019a].


### Model selection in oETS {#oETSModelSelection}
There are two dimensions for the model selection in the oETS model:

1. Selection of the type of occurrence;
2. Selection of the model type for the occurrence part.

The solution in this situation is simple. Given the formula \@ref(eq:oETSLikelihood), we can try each of the models, calculate log-likelihoods, the number of all estimated parameters, and then select the one that has the lowest information criterion. The demand occurrence models discussed in this section will have:

1. oETS$_F$: 1 parameter for the probability of occurrence;
2. oETS$_O$, oETS$_I$, and oETS$_D$: initial values, smoothing and dampening parameters;
3. oETS$_G$: initial values, smoothing, and dampening parameters for models A and B.

For example, if the oETS(M,N,N) model is constructed, the overall number of estimated parameters for the models will be:

1. oETS(M,N,N)$_F$ -- 1 parameter: the probability of occurrence $\hat{p}$;
2. oETS(M,N,N)$_O$, oETS(M,N,N)$_I$ and oETS(M,N,N)$_D$ -- 2 each: the initial value of level and the smoothing parameter;
3. oETS(M,N,N)$_G$ -- 4: the initial values of $\hat{l}_{a,0}$ and $\hat{l}_{b,0}$ and the smoothing parameters $\hat{\alpha}_a$ and $\hat{\alpha}_b$.

This implies that the selection between models in (2) will come to the best fit to the demand occurrence data, while oETS(M,N,N)$_G$ will only be selected if it provides a much better fit to the data. Given that intermittent demand typically does not have many observations, the selection of oETS(M,N,N)$_G$ becomes highly improbable.

When it comes to selecting the most appropriate demand occurrence model (e.g. selecting ETS components or ARIMA orders), the approach would be similar: estimate the pool of models via likelihood, calculate numbers of parameters, select the model with the lowest information criterion. Given that we assume that the demand occurrence is independent of the demand sizes, the selection of models in the occurrence part can be done based on the likelihood \@ref(eq:oETSLikelihood) independently of the demand sizes part of the model, which significantly simplifies the estimation and model selection process for the whole iETS model.


## Demand sizes part of the model {#ADAMDemandSizes}
So far, we have discussed the occurrence part of the model $o_t$ and how to capture the probability of demand occurrence $p_t$. But this is only half of the intermittent state space model. The second one is the model for the demand sizes $z_t$, which focuses on how many units of product will be sold if our customers decide to buy in a specific period of time. This can be modelled with any ADAM (ETS/ARIMA/regression), but it would need to be amended slightly to take intermittent demand features into account.

We start the discussion with analysis of an iETS(M,N,N)$_F$ model, which can be formulated as:
\begin{equation}
	\begin{aligned}
		& y_t = o_t z_t  \\
		& z_t = l_{z,t-1}(1 + \epsilon_{z,t}) \\
		& l_{z,t} = l_{z,t-1}(1  + \alpha_{z} \epsilon_{z,t}) \\
		& o_t \sim \text{Bernoulli}(p) \\
	\end{aligned},
	(\#eq:iETSMNNFixed)
\end{equation}
where the subscript $z$ refers to the components and parameters of demand sizes. This model assumes that there is always a potential demand on the product which evolves over time (even when $o_t=0$), but we do not always observe it. This model's main properties have already been discussed in Section \@ref(ADAMETSPureMultiplicative). The main challenge appears when this model needs to be constructed and estimated because $z_t$ is not observable when $o_t=0$. In these instances, the error term cannot be estimated, but according to the model, it still exists, thus impacting the level of demand $l_{z,t}$. To construct the model in the cases of no demand, we propose taking the conditional expectation for these periods, given the last available non-zero observation. This means that iETS(M,N,N)$_F$ can be constructed using the following set of equations:
\begin{equation}
	\begin{aligned}
		& e_{z,t} = \frac{z_t -\hat{\mu}_{z,t}}{\hat{\mu}_{z,t}}, \text{ when } o_t=1 \\
		& \hat{\mu}_{z,t} = \hat{l}_{z,t-1} \\
		& \hat{l}_{z,t} = 
		\left \lbrace \begin{aligned}
		& \hat{l}_{z,t-1} (1 + \hat{\alpha}_z e_t ), & \text{ when } o_t=1 \\
		& \hat{l}_{z,t-1} , & \text{ when } o_t=0
		\end{aligned} \right.
	\end{aligned}.
	(\#eq:iETSMNNFixedConstruction)
\end{equation}
This is only possible if $\mathrm{E}(1+\epsilon_{z,t})=1$, which is an important assumption for multiplicative error models, discussed in Section \@ref(ADAMETSMultiplicativeDistributions). If this is violated, then the formula for the calculation of the level in \@ref(eq:iETSMNNFixedConstruction) will become more complicated, involving the expectation of products of random variables.

In a similar way, we can construct more complicated models for the demand sizes. In a more general case (Section \@ref(ADAMETSIntroduction)) this can be written as:
\begin{equation}
	\begin{aligned}
		& e_{z,t} = \frac{z_t -\hat{\mu}_{z,t}}{\hat{\mu}_{z,t}}, \text{ when } o_t=1 \\
		& \hat{\mathbf{v}}_{t} = 
		\left \lbrace \begin{aligned}
		& f(\hat{\mathbf{v}}_{t-\boldsymbol{l}}) + g(\hat{\mathbf{v}}_{t-\boldsymbol{l}}) e_t, & \text{ when } o_t=1 \\
		& f(\hat{\mathbf{v}}_{t-\boldsymbol{l}}) , & \text{ when } o_t=0
		\end{aligned} \right.
	\end{aligned},
	(\#eq:iETSADAMStateSpaceConstruction)
\end{equation}
where all the functions and vectors have been defined for the original ADAM \@ref(eq:ETSADAMStateSpace) in Section \@ref(ADAMETSGeneral).

### Additive vs multiplicative ETS for demand sizes
The approach above supports any type of ADAM, including pure additive ETS (Section \@ref(ADAMETSPureAdditive)), pure multiplicative ETS (Section \@ref(ADAMETSPureMultiplicative)) or mixed ETS (Section \@ref(ADAMETSMixedModels)). While selection of the appropriate model can be automated, I argue that the better approach is to do it based on the understanding of the problem. In demand forecasting, typically we expect the values to be non-negative: people want to buy our product, and usually, the business does not want to buy products back from customers (unless we are dealing with a circular supply chain, but this is a different topic). This means that the pure multiplicative models should be preferred to the additive ones, as they will always produce meaningful results, as long as the assumption of positivity of $(1+\epsilon_{z,t})$ holds. This assumption is important because the intermittent demand would typically have low volume, and the model might generate unreasonable (negative) point and interval forecasts if a non-positive distribution is used for the error term (e.g. Normal). Thus, it is important to use Inverse Gaussian, or Gamma, or Log-Normal distribution (see discussion in Section \@ref(ADAMETSMultiplicativeDistributions)) for the error term of the demand sizes part of the model when the volume of data is low, and you expect the non-zero values to be strictly positive.

The main difficulty with pure multiplicative models arises from the construction point of view. As discussed in Section \@ref(pureMultiplicativeExpectationAndVariance), the point forecasts of such models, in general, do not correspond to the conditional $h$ steps ahead expectations (the only exclusion is the ETS(M,N,N) model). At the same time, the construction of the model for demand sizes assumes that the conditional expectations are equal to point forecasts when demand is not observed. If this is violated, then \@ref(eq:iETSADAMStateSpaceConstruction) is no longer the correct way to construct the model. This problem becomes especially important for the models with the multiplicative trend, where the conditional expectation might differ from point forecasts substantially [@Svetunkov2020ETS]. Still, point forecasts can be considered proxies for the conditional expectations, especially when smoothing parameters are close to zero. For example, the conditional expectation coincides with the point forecast in the boundary case with $\alpha=0$ and $\beta=0$ in ETS(M,M,N). The higher the smoothing parameters are, the more significant the discrepancy will be, implying that the model for the demand sizes is constructed incorrectly.

The pure additive models do not have the issue with the conditional expectation and thus can be constructed easily in the case of intermittent demand. But as discussed earlier, they might violate the non-negativity assumption of the model. So, in practice, they should be used with care.

### Using ARIMA for demand sizes
ADAM ARIMA can also be used for demand sizes, resulting in the iARIMA model. All the discussions in the previous subsection would apply to ARIMA as well, keeping in mind that ADAM ARIMA can be either pure additive (Section \@ref(StateSpaceARIMAAdditive)) or pure multiplicative (Section \@ref(ADAMARIMAPureMultiplicative)). Given that the multiplicative ARIMA is formulated via logarithms and still has the error term with the expectation of one, any ARIMA model can be used for the variable $z_t$ and can be constructed via \@ref(eq:iETSADAMStateSpaceConstruction). This can also be used for the cases when a pure multiplicative model with the trend is needed, and there are difficulties with the construction of ETS(M,M,N) (i.e. smoothing parameters are not close to zero). The relation between ARIMA and ETS (discussed in Section \@ref(ARIMAandETS)) might be useful in this case: instead of constructing ETS(M,M,N) we can construct logARIMA(0,2,2) (see Section \@ref(ADAMARIMAPureMultiplicative)), sidestepping the aforementioned problem.

### Rounding up forecasts
Finally, when it comes to using an intermittent state space model on count data, there is a temptation to round up the resulting forecasts. If this is done for the point forecasts (conditional expectations), then this should be avoided, because the values show what happens on average and thus are allowed to take any values, not only the integers. However, when it comes to predictive quantiles, @Svetunkov2019a show that rounding them up is equivalent to generating quantiles from a model with discretised distribution [see discussion on discretised distributions in @Chakraborty2015] and improves both the forecasting and inventory performance of the model. So, the simple approach of generating a prediction interval (see Section \@ref(ADAMForecastingPI)) and then rounding it up has a theoretical rationale behind it and works well in practice.


## The complete ADAM {#ADAMIntermittentFull}
Uniting demand occurrence (from Section \@ref(ADAMOccurrence)) with the demand sizes (Section \@ref(ADAMDemandSizes)) parts of the model, we can now discuss the complete ADAM model, which in the most general form can be represented as:
\begin{equation}
    \begin{aligned}
        & y_t = o_t z_t , \\
        & {z}_{t} = w_z(\mathbf{v}_{z,t-\boldsymbol{l}}) + r_z(\mathbf{v}_{z,t-\boldsymbol{l}}) \epsilon_{z,t} \\
        & \mathbf{v}_{z,t} = f_z(\mathbf{v}_{z,t-\boldsymbol{l}}) + g_z(\mathbf{v}_{z,t-\boldsymbol{l}}) \epsilon_{z,t} \\
        & \\
        & o_t \sim \text{Bernoulli} \left(p_t \right) , \\
        & p_t = f_p(\mu_{a,t}, \mu_{b,t}) \\
        & a_t = w_a(\mathbf{v}_{a,t-\boldsymbol{l}}) + r_a(\mathbf{v}_{a,t-\boldsymbol{l}}) \epsilon_{a,t} \\
        & \mathbf{v}_{a,t} = f_a(\mathbf{v}_{a,t-\boldsymbol{l}}) + g_a(\mathbf{v}_{a,t-\boldsymbol{l}}) \epsilon_{a,t} \\
        & b_t = w_b(\mathbf{v}_{b,t-\boldsymbol{l}}) + r_b(\mathbf{v}_{b,t-\boldsymbol{l}}) \epsilon_{b,t} \\
        & \mathbf{v}_{b,t} = f_b(\mathbf{v}_{b,t-\boldsymbol{l}}) + g_b(\mathbf{v}_{b,t-\boldsymbol{l}}) \epsilon_{b,t}
    \end{aligned} ,
    (\#eq:iETSG)
\end{equation}
where the elements of the demand size and demand occurrence parts have been discussed in Sections \@ref(ADAMDemandSizes) and \@ref(ADAMOccurrence), respectively. The model \@ref(eq:iETSG) can also be considered a more general one than the conventional ADAM ETS and ARIMA models: if the probability of occurrence $p_t$ is equal to one for all observations, then the model reverts to them.

Summarising the discussions in previous sections of this chapter, the complete ADAM has the following assumptions:

1. The demand sizes variable $z_t$ is continuous. This is a reasonable assumption for many contexts, including, for example, energy forecasting. But even when we deal with integer values, @Svetunkov2019a showed that such a model does not perform worse than count data models. And if the integer values are needed, @Svetunkov2019a demonstrated that rounding up quantiles from such a model is a reasonable and efficient approach that performs well in terms of forecasting accuracy and inventory performance;
2. Potential demand size may change over time even when $o_t=0$. This means that the states evolve even when demand is not observed;
3. Demand sizes and demand occurrence are independent. This simplifies many derivations and makes the model estimable. If the assumption is violated, a different model with different properties would need to be constructed. My understanding of the problem tells me that the model \@ref(eq:iETSG) will work well even if this is violated, but I have not done any experiments in this direction.

Depending on the specific model for each part and restrictions on $\mu_{a,t}$ and $\mu_{b,t}$, we might have different types of iETS models. To distinguish one model from another, we introduce the notation of iETS models of the form "iETS(demand sizes model)$_\text{type of occurrence}$(model A type)(model B type)". For example, in the iETS(M,N,N)$_G$(A,N,N)(M,M,N), the first brackets say that ETS(M,N,N) was applied to the demand sizes, and the underscored letter points out that this is the "general probability" model (Subsection \@ref(oETSG)), which has ETS(A,N,N) for the model A and ETS(M,M,N) for the model B. If only one demand occurrence part is used (either $a_t$ or $b_t$), then the redundant brackets are dropped, and the notation is simplified. For example, iETS(M,N,N)$_O$(M,M,N) has only one part for demand occurrence, which is captured using the ETS(M,M,N) model. If the same type of model is used for both demand sizes and demand occurrence, then the second brackets can be dropped as well, simplifying this further to iETS(M,N,N)$_O$ (odds ratio model with ETS(M,N,N) for both parts, Section \@ref(oETSO)). All these models are implemented in the `adam()` function for the `smooth` package in R.

Similar notations and principles can be used for models based on ARIMA. Note that oARIMA is not yet implemented in `smooth`, but in theory, a model like iARIMA(0,1,1)$_O$(1,1,2) could be constructed in the ADAM framework.

Furthermore, in some cases, we might have explanatory variables, such as promotions, prices, weather, etc. They would impact both demand occurrence and demand sizes. In ADAM, they are implemented in respective `oes()` and `adam()` functions. Remember that when you include explanatory variables in the occurrence part, you are modelling the probability of occurrence, not the occurrence itself. So, for example, a promotional effect in this situation would mean a higher chance of having sales. In some other situations, we might not need dynamic models, such as ETS and ARIMA, and can focus on static regression. While `adam()` supports this, the `alm()` function from the `greybox` might be more suitable in this situation. It supports similar parameters, but its `occurrence` parameter accepts either the type of transform (`plogis` for the logit model and `pnorm` for the probit one) or a previously estimated occurrence model (either from `alm()` or from `oes()`).

In addition, there might be some cases, when the demand itself happens at random, but the demand sizes are at the same time not random. This means that when someone buys a product, they buy a fixed amount of $z$. Typically, in these situations $z=1$, but there might be some cases with other values. An example of such a demand process is shown in Figure \@ref(fig:fixedDemandSizes).

```{r fixedDemandSizes, fig.cap="Example of intermittent time series with fixed demand sizes.", echo=FALSE}
plot(rbinom(100, 1, 0.3), type="h",
     xlab="Time", ylab="Sales")
```

In this case, the model \@ref(eq:iETSG) simplifies to:
\begin{equation}
    \begin{aligned}
        & y_t = o_t z , \\
        & o_t \sim \text{Bernoulli} \left(p_t \right)
    \end{aligned} ,
    (\#eq:iETSFixedDemand)
\end{equation}
where $p_t$ can be captured via one of the demand occurrence models discussed in previous sections. Given that $z$ is not random anymore, it does not require estimation, and the likelihood simplifies to the one for the demand occurrence (from Section \@ref(ADAMOccurrence)). The forecast from this model can be generated by producing conditional expectation for the probability and then multiplying it by the value of $z$.

Finally, in some situations the occurrence might be not random, i.e. we deal with not an intermittent demand, but with a demand, where sales sometimes do not happen (i.e. $o_t=0$), but we can predict perfectly when they happen. If we know when the demand occurs, we can use the respective values of zeroes and ones in the variable $o_t$, simplifying the model \@ref(eq:iETSG) to:
\begin{equation}
    \begin{aligned}
        & y_t = o_t z_t , \\
        & {z}_{t} = w_z(\mathbf{v}_{z,t-\boldsymbol{l}}) + r_z(\mathbf{v}_{z,t-\boldsymbol{l}}) \epsilon_{z,t} \\
        & \mathbf{v}_{z,t} = f_z(\mathbf{v}_{z,t-\boldsymbol{l}}) + g_z(\mathbf{v}_{z,t-\boldsymbol{l}}) \epsilon_{z,t}
    \end{aligned} ,
    (\#eq:iETSFixedOccurrence)
\end{equation}
where the values of $o_t$ are known in advance. An example of such a situation is the demand on watermelons, which reaches zero in specific periods of time in winter (at least in the UK). This special type of model is implemented in both the `adam()` and `alm()` functions, where the user needs to provide the vector of zeroes and ones in the `occurrence` parameter.


### Maximum Likelihood Estimation {#iETSMLE}
While there are different ways of estimating the parameters of the ADAM \@ref(eq:iETSG), it is worth focusing on likelihood estimation (Section \@ref(ADAMETSEstimationLikelihood)) for consistency with other ADAMs. The likelihood of the model will consist of several parts:

1. The probability density function (PDF) of demand sizes when demand occurs;
2. The probability of occurrence;
3. The probability of inoccurrence.

When demand occurs the likelihood is:
\begin{equation}
    \mathcal{L}(\boldsymbol{\theta} | y_t, o_t=1) = p_t f_z(z_t | \mathbf{v}_{z,t-\boldsymbol{l}}) ,
    (\#eq:LogLikelihoodOccurs)
\end{equation}
while in the opposite case it is:
\begin{equation}
    \mathcal{L}(\boldsymbol{\theta} | y_t, o_t=0) = (1-p_t) f_z(z_t | \mathbf{v}_{z,t-\boldsymbol{l}}),
    (\#eq:LogLikelihoodOccursNot)
\end{equation}
where $\boldsymbol{\theta}$ includes all the estimated parameters of the model (for demand sizes and demand occurrence, including parameters of distribution, such as scale). Note that because the model assumes that the demand evolves over time even when it is not observed ($o_t=0$), we have a probability density function of demand sizes, $f_z(z_t | \mathbf{v}_{z,t-\boldsymbol{l}})$ in \@ref(eq:LogLikelihoodOccursNot). Based on equations \@ref(eq:LogLikelihoodOccurs) and \@ref(eq:LogLikelihoodOccursNot), we can summarise the likelihood for the whole sample of $T$ observations:
\begin{equation}
    \mathcal{L}(\boldsymbol{\theta} | \textbf{y}) = \prod_{o_t=1} p_t \prod_{o_t=0} (1-p_t) \prod_{t=1}^T f_z(z_t | \mathbf{v}_{z,t-\boldsymbol{l}}) ,
    (\#eq:LikelihoodForDGP)
\end{equation}
or in logarithms:
\begin{equation}
    \ell(\boldsymbol{\theta} | \textbf{y}) = \sum_{o_t=1} \log(p_t) + \sum_{o_t=0} \log(1-p_t) + \sum_{t=1}^T f_z(z_t | \mathbf{v}_{z,t-\boldsymbol{l}}),
    (\#eq:LogLikelihoodForDGP)
\end{equation}
where $\textbf{y}$ is the vector of all actual values and $f_z(z_t | \mathbf{v}_{z,t-\boldsymbol{l}})$ can be substituted by a PDF of the assumed distribution from the list of candidates in Section \@ref(ADAMETSEstimationLikelihood). The main issue in calculating the likelihood \@ref(eq:LogLikelihoodForDGP) is that the demand sizes are not observable when $o_t=0$. This means that we cannot calculate the likelihood using the conventional approach. We need to use something else. @Svetunkov2019a proposed using the Expectation Maximisation (EM) algorithm for this purpose, which is typically done in the following stages:

1. Take *Expectation* of the likelihood;
2. *Maximise* it with the obtained parameters;
3. Go to (1) with the new set of parameters if the likelihood has not converged to the maximum.

A classic example with EM is when several samples have different parameters, and we need to split them (e.g. do clustering). In that case, we do not know what cluster specific observations belong to and what the probability that each observation belongs to one of the groups is. In our context, the problem is slightly different: we know probabilities, but we do not observe some of the values. As a result the application of EM gives a different result. If we take the expectation of \@ref(eq:LogLikelihoodForDGP) with respect to the unobserved demand sizes, we will get:
\begin{equation}
    \begin{aligned}
        \mathrm{E}\left(\ell(\boldsymbol{\theta} | \textbf{y})\right) & = \sum_{o_t=1} \log f_z \left(z_{t} | \mathbf{v}_{z,t-\boldsymbol{l}} \right) + \sum_{o_t=0} \text{E} \left( \log f_z \left(z_{t} | \mathbf{v}_{z,t-\boldsymbol{l}} \right) \right) \\
        & + \sum_{o_t=1} \log(p_t) + \sum_{o_t=0} \log(1- p_t)
    \end{aligned}.
    (\#eq:LogLikelihoodForDGPExpectation)
\end{equation}
The first term in \@ref(eq:LogLikelihoodForDGPExpectation) is known because the $z_t$ are observed when $o_t=1$. The expectation in the second term of \@ref(eq:LogLikelihoodForDGPExpectation) is known in statistics as "Differential Entropy" (in the formula above, we have the negative differential entropy). It will differ from one distribution to another. Table \@ref(tab:differentialEntropy) summarises differential entropies for the distributions used in ADAM.

```{r echo=FALSE}
# Assumption | Differential Entropy
# Normal distribution
entropiesTable <- c("$\\epsilon_t \\sim \\mathcal{N}(0, \\sigma^2)$",
                    "$\\frac{1}{2}\\left(\\log(2\\pi\\sigma^2)+1\\right)$",
                    # Laplace distribution
                    "$\\epsilon_t \\sim \\mathcal{L}(0, s)$",
                    "$1+\\log(2s)$",
                    # S distribution
                    "$\\epsilon_t \\sim \\mathcal{S}(0, s)$",
                    "$2+2\\log(2s)$",
                    # GN distribution
                    "$\\epsilon_t \\sim \\mathcal{GN}(0, s, \\beta)$",
                    "$\\beta^{-1}-\\log\\left(\\frac{\\beta}{2s\\Gamma\\left(\\beta^{-1}\\right)}\\right)$",
                    # Asymmetric Laplace distribution
                    # "$\\epsilon_t \\sim \\mathcal{ALaplace}(0, s, \\alpha)$",
                    # "$1+\\log(2s)$",
                    # IG distribution
                    "$1+\\epsilon_t \\sim \\mathcal{IG}(1, \\sigma^2)$",
                    "$\\frac{1}{2}\\left(\\log \\pi e \\sigma^2 -\\log(2) \\right)$",
                    # Gamma distribution
                    "$1+\\epsilon_t \\sim \\mathcal{\\Gamma}(\\sigma^{-2}, \\sigma^2)$",
                    "$\\sigma^{-2} + \\log \\Gamma\\left(\\sigma^{-2} \\right) + \\left(1-\\sigma^{-2}\\right)\\psi\\left(\\sigma^{-2}\\right)$",
                    # logN distribution
                    "$1+\\epsilon_t \\sim \\mathrm{log}\\mathcal{N}\\left(-\\frac{\\sigma^2}{2}, \\sigma^2\\right)$",
                    "$\\frac{1}{2}\\left(\\log(2\\pi\\sigma^2)+1\\right)-\\frac{\\sigma^2}{2}$"
)
entropiesTable <- matrix(entropiesTable, 7, 2, byrow=TRUE,
                         dimnames=list(c("\\textbf{Normal}","\\textbf{Laplace}","\\textbf{S}",
                                         "\\textbf{Generalised Normal}",
                                         # "\\textbf{Asymmetric Laplace}",
                                         "\\textbf{Inverse Gaussian}","\\textbf{Gamma}","\\textbf{Log-Normal}"),
                                       c("\\textbf{Assumption}","\\textbf{Differential Entropy}")))
kableTable <- kableExtra::kable(entropiesTable, escape=FALSE, caption="Differential entropies for different distributions. $\\Gamma(\\cdot)$ is the Gamma function, while $\\psi(\\cdot)$ is the digamma function.",
                                col.names=c("Assumption","Differential Entropy"), label="differentialEntropy")
kableExtra::kable_styling(kableTable, font_size=12, protect_latex=TRUE, latex_options="scale_down")
```

The majority of formulae for differential entropy in Table \@ref(tab:differentialEntropy) are taken from @Lazo1978a with the exclusion of the one for $\mathcal{IG}$, which was derived by @Mudholkar2002. These values can be inserted instead of the $\text{E} \left( \log f_z \left(z_{t} | \mathbf{v}_{z,t-\boldsymbol{l}} \right) \right)$ in the formula \@ref(eq:LogLikelihoodForDGPExpectation), leading to the expected likelihood for respective distributions, which can then be maximised. For example, for Inverse Gaussian distribution (using the PDF from the Table \@ref(tab:multiplicativeErrorLikelihoods) and the entropy from Table \@ref(tab:differentialEntropy)), we get:
\begin{equation}
    \begin{aligned}
        \mathrm{E}\left(\ell(\boldsymbol{\theta} | \textbf{y})\right) & =
        -\frac{T_1}{2} \log \left(2 \pi \sigma^2 \right) -\frac{1}{2}\sum_{o_t=1} \left(1+\epsilon_{t}\right)^3 \\
        & -\frac{3}{2} \sum_{o_t=1} \log y_t -\frac{1}{2 \sigma^2} \sum_{o_t=1} \frac{\epsilon_t^2}{1+\epsilon_t} \\
        & -\frac{T_0}{2}\left(\log \pi e \sigma^2 -\log(2) \right) \\
        & + \sum_{o_t=1} \log(p_t) + \sum_{o_t=0} \log(1- p_t)
    \end{aligned} ,
(\#eq:LogLikelihoodForDGPExpectationIG)
\end{equation}
where $T_0$ is the number of zeroes in the data and $T_1$ is the number of non-zero values. Luckily, the EM process in our specific situation does not need to be iterative -- the obtained likelihood can then be maximised directly by changing the values of parameters $\boldsymbol{\theta}$. It is also possible to derive analytical formulae for parameters of some of distributions based on \@ref(eq:LogLikelihoodForDGPExpectation) and the values from Table \@ref(tab:differentialEntropy). For example, in the case of the Inverse Gaussian distribution the estimate of scale parameter is:
\begin{equation}
\hat{\sigma}^2 = \frac{1}{T} \sum_{o_t=1}\frac{e_t^2}{1+e_t}.
(\#eq:IGLogLikelihoodScale)
\end{equation}
This is obtained by taking the derivative of \@ref(eq:LogLikelihoodForDGPExpectationIG) with respect to $\sigma^2$ and equating it to zero. It can be shown that the likelihood estimates of scales for different distributions correspond to the conventional formulae from Section \@ref(ADAMETSEstimationLikelihood), but with the summation over $o_t=1$ instead of all the observations. Note, however, that the division in \@ref(eq:IGLogLikelihoodScale) is done by the whole sample $T$. This implies that the scale estimate will be biased, similarly to the classical bias of the sample variance. @Svetunkov2019a show that in the full ADAM, the estimate of scale is biased not only in-sample but also asymptotically, implying that with the increase of the sample size, it will be consistently lower than needed. This is because the summation is done over the non-zero values, while the division is done over the whole sample. This proportion of non-zeroes impacts the scale in \@ref(eq:IGLogLikelihoodScale), deflating its value. The only situation when the bias will be reduced is when the probability of occurrence reaches 1 (demand becomes regular). Still, the value \@ref(eq:IGLogLikelihoodScale) will maximise the expected likelihood \@ref(eq:LogLikelihoodForDGPExpectation) and is useful for inference. However, if one needs to construct prediction intervals, this bias needs to be addressed, which can be done using the conventional correction:
\begin{equation}
\hat{\sigma}^2{^{\prime}} = \frac{T}{T_1-k} \hat{\sigma}^2,
(\#eq:scaleFixed)
\end{equation}
where $k$ is the number of all estimated parameters.

Finally, for the two exotic cases with known demand occurrence and known demand sizes, the likelihood \@ref(eq:LogLikelihoodForDGPExpectation) simplifies to the first two and the last two terms in the formula, respectively.


### Conditional expectation and variance
Now that we have discussed how the model is formulated and how it can be estimated, we can move to the discussion of conditional expectation and variance from it. The former is needed to produce point forecasts, while the latter might be required for different inventory decisions.

The conditional $h$ steps ahead expectation of the model can be obtained easily based on the assumption of independence of demand occurrence and demand sizes discussed earlier in Section \@ref(ADAMIntermittentFull):
\begin{equation}
    \mathrm{E}(y_{t+h}|t) = \mu_{y,t+h|t} = \mathrm{E}(o_{t+h}|t) \mathrm{E}(z_{t+h}|t) = \mu_{o,t+h|t} \mu_{z,t+h|t},
    (\#eq:iETSConditionalExpectation)
\end{equation}
where $\mu_{o,t+h|t}$ is the conditional expectation of the occurrence variable (the conditional $h$ steps ahead probability of occurrence) and $\mu_{z,t+h|t}$ is the conditional expectation of the demand sizes variable $z_t$. So, the forecast from the complete ADAM relies on the probability of occurrence of the variable and will reflect an average demand per period of time. As a result, it might be less than one in some cases, implying that the product is not sold every day. Consequentially, @Kourentzes2014a argued that the term "demand rate" should be used in this context instead of the conditional expectation. However, any forecasting model produces "demand per period" forecasts. They just typically assume that the probability of occurrence is equal to one ($p_t=1$) for all observations. So, there is no conceptual difference between the point forecasts produced by regular and intermittent demand models, and I do not see the point in using the "demand rate" term.

As for the conditional variance, it is slightly trickier than the conditional expectation, because the variance of a product involves not only variances, but expectations as well (assuming that two variables are independent):
\begin{equation}
	\resizebox{0.85\textwidth}{!}{$
    \mathrm{V}(y_{t+h}|t) = \mathrm{V}(o_{t+h}|t) \mathrm{V}(z_{t+h|t}) + \mathrm{E}(o_{t+h}|t)^2 \mathrm{V}(z_{t+h}|t) + \mathrm{V}(o_{t+h}|t) \mathrm{E}(z_{t+h}|t)^2 . $}
    (\#eq:VarianceOfProduct)
\end{equation}
Given that we use Bernoulli distribution for the variable $o_t$, its variance is equal to $\mu_{o,t+h|t} (1-\mu_{o,t+h|t})$. In our context this implies that the conditional $h$ steps ahead variance for the complete ADAM is:
\begin{equation}
	\resizebox{0.85\textwidth}{!}{$
    \sigma^2_h = \mu_{o,t+h|t} (1-\mu_{o,t+h|t}) \sigma^2_{z,h} + \mu_{o,t+h|t}^2 \sigma^2_{z,h} + \mu_{o,t+h|t} (1-\mu_{o,t+h|t}) \mu_{z,t+h|t}^2 , $}
    (\#eq:iETSConditionalVariance01)
\end{equation}
or after some manipulations:
\begin{equation}
    \sigma^2_h = \mu_{o,t+h|t} \left(\sigma^2_{z,h} + (1 -\mu_{o,t+h|t}) \mu_{z,t+h|t}^2 \right).
    (\#eq:iETSConditionalVariance)
\end{equation}
All the elements of the formula \@ref(eq:iETSConditionalVariance) are available and have been discussed in Sections \@ref(pureAdditiveExpectationAndVariance), \@ref(pureMultiplicativeExpectationAndVariance), and \@ref(ADAMOccurrence).

When it comes to the two exotic cases, discussed in the beginning of this section, we have the following conditional expectation and variance:

1. When demand sizes are fixed and known, i.e. $z_t=z$:
\begin{equation}
    \begin{aligned}
        & \mu_{y,t+h|t} = \mu_{o,t+h|t} z, \\
        & \sigma^2_h = \mu_{o,t+h|t} (1 -\mu_{o,t+h|t}) z^2 ;
    \end{aligned}
    (\#eq:iETSConditionalMomentsFixedSizes)
\end{equation}

2. When demand occurrence is known:
\begin{equation}
    \begin{aligned}
        & \mu_{y,t+h|t} = o_{t+h} \mu_{z,t+h|t}, \\
        & \sigma^2_h = o_{t+h} \left(\sigma^2_{z,h} + (1 -o_{t+h}) \mu_{z,t+h|t}^2 \right).
    \end{aligned}
    (\#eq:iETSConditionalMomentsFixedOccurrence)
\end{equation}

These two cases might not arise often, but it is important to understand how they change the moments of the model.


## Examples of application {#IntermittentExample}
We consider the same example from Section \@ref(ADAMOccurrence). Just as a reminder, in that example, both demand occurrence and demand sizes increase over time (Figure \@ref(fig:intermittentExamplePlot)), meaning that we can try the model with the trend for both parts. This can be done using the `adam()` function from the `smooth` package, defining the type of occurrence to use. We will try several options and select the one that has the lowest AICc:
```{r}
adamiETSy <- vector("list",4)
adamiETSy[[1]] <- adam(y, "MMdN", h=10, holdout=TRUE,
                       occurrence="odds-ratio")
adamiETSy[[2]] <- adam(y, "MMdN", h=10, holdout=TRUE,
                       occurrence="inverse-odds-ratio")
adamiETSy[[3]] <- adam(y, "MMdN", h=10, holdout=TRUE,
                       occurrence="direct")
adamiETSy[[4]] <- adam(y, "MMdN", h=10, holdout=TRUE,
                       occurrence="general")
adamiETSyAICcs <-
    setNames(sapply(adamiETSy,AICc),
             c("odds-ratio", "inverse-odds-ratio",
               "direct", "general"))
adamiETSyAICcs
```

Based on this, we can see that the model with `r names(adamiETSyAICcs)[which.min(adamiETSyAICcs)]` probability has the lowest AICc. We can show how the model approximates the data and produces forecasts for the holdout:

```{r adamModelsiETSBest, fig.cap="The fit of the best model to the intermittent data: final demand and the demand occurrence parts."}
i <- which.min(adamiETSyAICcs)
par(mfcol=c(2,1), mar=c(2,1,2,1))
plot(adamiETSy[[i]],7)
plot(adamiETSy[[i]]$occurrence,7)
```

Figure \@ref(fig:adamModelsiETSBest) shows that the model captured the trend well for both the demand occurrence and demand sizes parts. It forecasts that the mean demand will increase for the holdout period. We can also explore the demand occurrence part of this model by typing:

```{r}
adamiETSy[[i]]$occurrence
```
In our example, the smoothing parameters are equal to zero for the demand occurrence part, which makes sense because the selected model is the damped multiplicative trend one, which should capture the increasing probability of occurrence well.

Depending on the generated data, there might be issues in the ETS(M,Md,N) model for demand sizes, if the smoothing parameters are too big, especially for the trend component. So, we can also try out the logARIMA(1,1,2) to see how it compares with this model. Given that ARIMA is not yet implemented for the occurrence part of the model, we need to construct the oETS separately and then use in `adam()`:

```{r}
oETSModel <- oes(y, "MMdN", h=10, holdout=TRUE,
                 occurrence=names(adamiETSyAICcs)[i])
adamiARIMA <- adam(y, "NNN", h=10, holdout=TRUE,
                   occurrence=oETSModel,
                   orders=c(1,1,2),
                   distribution="dlnorm")
adamiARIMA
```

Comparing the iARIMA model with the previous iETS based on AIC would not be fair because as soon as the occurrence model is provided to the `adam()`, it does not count the parameters estimated in that part towards the overall number of estimated parameters. To make the comparison fair, we need to make ADAM iETS comparable by estimating it in a similar way:

```{r}
adamiETSy[[i]] <- adam(y, "MMdN", h=10, holdout=TRUE,
                       occurrence=oETSModel)
adamiETSy[[i]]
```

Comparing information criteria, the iETS model is more appropriate for this data. But this might be due to different distributional assumptions and difficulties estimating the ARIMA model. If you want to experiment more with iARIMA, you might try fine tuning its parameters (see Section \@ref(ADAMInitialisationOptAndBack)) for the data either by increasing the `maxeval` or changing the initialisation, for example:

```{r eval=FALSE}
adamiARIMA <- adam(y, "NNN", h=10, holdout=TRUE,
                   occurrence=oETSModel, orders=c(1,1,2),
                   distribution="dgamma", initial="back")
```

Finally, we can produce point and interval forecasts from either of the models via the `forecast()` method. Here is an example:

```{r adamiETSyForecasts, fig.cap="Point forecasts and prediction interval from the iETS(M,Md,N)$_D$ model."}
forecast(adamiETSy[[i]], h=10,
         interval="prediction", nsim=10000) |>
    plot()
```

In Figure \@ref(fig:adamiETSyForecasts), the interval is expanding, reflecting the captured tendency of growth in the data. The prediction interval produced from multiplicative ETS models will typically be simulated if `interval="prediction"`, so to make them smoother, you might need to increase the `nsim` parameter, for example, to `nsim=100000`.


## Intermittent demand challenges
Intermittent demand is complicated and is difficult to work with. As a result, several challenges are related to the ADAM specifically and to the intermittent demand at large are worth discussing.

First, given the presence of zeroes, the decomposition (Section \@ref(ClassicalDecomposition)) of intermittent time series does not make sense. The classical time series model assumes that the demand happens on every observation, while the intermittent demand happens irregularly. This makes all the conventional models inapplicable to the problem, although some of them might still work well in some cases (for example, SES from Section \@ref(SES) in case of mildly intermittent data).

The second follows directly from the first point. While, in theory, it is possible to use any ETS/ARIMA model for both demand occurrence and demand sizes of the ADAM, some of the specific model types are either impossible or very difficult to estimate. For example, seasonality on intermittent data is not very well pronounced, so estimating the initial values of components of seasonal models (such as ETS(M,N,M)) is not a trivial task. In some cases, if we have several products in a group that exhibit similar seasonal patterns, we can aggregate them to the group level to get a better estimate of seasonal indices, and then use them on the lower level. The `adam()` function allows doing that via `initial=list(seasonal=seasonalIndices)`. But in all the other cases, the estimation of seasonal models might fail.

Third, in some cases, you might know when specifically demand will happen (for example, kiwis stop growing in New Zealand from May till September, so the crop will go down around that time). In this case, you do not need a proper intermittent demand model, you just need to deal with the demand sizes via ADAM ETS/ARIMA and provide zeroes and ones in the demand occurrence part for the variable $o_t$. We have discussed this type of model in Section \@ref(ADAMIntermittentFull). Practically speaking, this can be done in `adam()` via `occurrence=ot`, where `ot` would contain zeroes and ones for the sample. This can also be done for the holdout sample in the `forecast()` function in a similar manner:

```{r eval=FALSE}
forecast(ourModel, occurrence=otFuture, h=h)
```
where `otFuture` should contain the values of the occurrence variable in the future.

Fourth, more specialised models, such as iETS, will produce positively biased estimates of the smoothing parameters, whatever the estimator is used [see explanation in @Svetunkov2019a]. This is caused by the assumption that the potential demand might change between the observed sales. In this situation, the components would evolve slowly, while we would only see their values before the set of zeroes and afterwards, which will make the applied model catch up to the data, thus inflating the estimates of smoothing parameters. This also implies that such forecasting methods as Croston [@Croston1972] and TSB [@Teunter2011] would also result in positively biased estimates of parameters if we assume that demand might change between the non-zero observations. Practically speaking, this means that the smoothing parameters will be higher than needed, implying more rapid changes in components and thus higher uncertainty in final forecasts. There is currently no solution to this problem.

Finally, summarising this chapter, intermittent demand forecasting is a complex problem. Differences between various forecasting models and methods on such data might be insignificant, and it would be challenging to select the appropriate one. Furthermore, point forecasts on intermittent demand are difficult to grasp and make actionable (unless you are interested in lead time forecasts, to get an idea about the expected demand over a period of time). All of this means that intermittent demand should be avoided if possible. Yes, you can have fancy models for it, but do you need to? For example, do you need to look at daily demand on products if decisions are made on a weekly basis (e.g. how many units of pasta should a supermarket order for the next week)? In many cases thinking about the problem carefully would allow avoiding intermittent demand, making the life of the analyst easier. But if it is not possible, then ADAM iETS and iARIMA models can be considered potential solutions in some situations.
