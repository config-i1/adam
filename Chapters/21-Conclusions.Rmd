# What's next? {#conclusions}
Having discussed the main aspects of ADAM and how to use it in different circumstances, I want to pause to look back at what we have covered and what is left behind.

The reason why I did not call this monograph "Forecasting with ETS" or "Forecasting with State space models" is because the framework proposed here is not the same as for ETS, and it does not rely on the standard state space model. The combination of ETS, ARIMA and Regression in one unified model has not been discussed in the literature before. This is then extended by introducing a variety of distributions: typically, dynamic models rely on Normality, which is not realistic in real life, but ADAM supports several real-valued and several positive distributions. Furthermore, the model that can be applied to both regular and intermittent demand has been developed only by @Svetunkov2019a but has not been published yet (and god knows when it will be). This is included in ADAM. In addition, the model then can be extended with multiple seasonal components, making it applicable to high-frequency data. Moreover, ADAM supports not only the location, but the scale model as well, allowing to model and predict the scale of distribution explicitly (giving it a connection with GARCH models). All of the aspects mentioned above are united in one approach, giving immense flexibility to the analyst.

But what's next? While we have discussed the important aspects of ADAM, there are still several things left that I did not have time to make work yet.

The first one is the ADAM with asymmetric Laplace and similar distributions with the non-zero mean (the related to this is the estimation of ADAM with non-standard loss functions, such as pinball). While it is possible to use such distributions, in theory, they do not work as intended in the ADAM framework. They work perfectly in the case of the regression model (e.g. see how the `alm()` from the `greybox` works with the Asymmetric Laplace) but fail when a model has MA-related terms. This is because the model becomes more adaptive to the changes, pulls to the centre and cannot maintain the desired quantile. An introduction of such distributions would imply changing the architecture of the state space model.

Second, model combination and selection literature has seen several bright additions to the field, such as a stellar paper by @Kourentzes2019c on pooling. This is neither implemented in the `adam()` function nor discussed in the monograph. Yes, one can use ADAM to do pooling, but it would make sense to introduce it as a part of the ADAM approach.

Third, we have not discussed multiple frequency models in detail that they deserve. For example, we have not mentioned how to diagnose such models when the sample includes thousands of observations. The classical statistical approaches discussed in Section \@ref(diagnostics) typically fail in this situation, and other tools can be used in this context.

Fourth, `adam()` has a built-in missing values approach that relies on interpolation and intermittent state space model (from Section \@ref(ADAMIntermittent)). While this already works in practice, there are some aspects of this that are worth discussing that have been left outside this monograph.

Finally, while I tried to introduce examples of application of ADAM, case studies for several contexts would be helpful. This would show how ADAM can be used for decisions in inventory management (we have touched the topic in Subsection \@ref(forecastingADAMOtherExample)), scheduling, staff allocation etc.

All of this will hopefully come in the next editions of this monograph.
