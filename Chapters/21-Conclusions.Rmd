# What's next? {#conclusions}
Having discussed the main aspects of ADAM and how to use it in different circumstances, I want to pause to look back at what we have covered and what is left behind.

The reason why I did not call this textbook "Forecasting with ETS" or "Forecasting with State space models" is because the framework proposed here is not the same as ETS and it does not rely on the standard state space model. The combination of ETS, ARIMA and Regression in one unified model has not been discussed in the literature before. This is then extended by introduction of a variety of distributions: typically, dynamic models rely on Normality, which is not realistic in real life, but ADAM supports several real-valued and several positive distributions. Furthermore, the model that can be applied to both regular and intermittent demand, has been developed only by @Svetunkov2019a, but has not been published yet (and god knows, when it will be). This is included in ADAM. In addition, the model then can be extended with multiple seasonal components, making it applicable to high frequency data. All of the aspects mentioned above are united in one approach, giving immense flexibility to analyst.

But what's next? While we have discussed the important aspects of ADAM, there are still several things left, that I did not have time to make work yet.

The first one is the scale model for ADAM. This is already implemented for `alm()` function in `greybox` package and will be discussed in @SvetunkovSBA in one of the next online editions. For ADAM, this would mean that the scale parameter (e.g. variance in Normal distribution) can be modelled explicitly using the combination of ETS, ARIMA and regression models. This would have some similarities with GARCH and / or [GAMLSS](https://www.gamlss.com/), but (again) would be united in one framework. 

The second one is the ADAM with asymmetric Laplace distribution. While we mentioned it several times in the course of this textbook, it does not work as intended in ADAM framework. The idea behind this distribution is to introduce the quantile-based estimation of a model. It works perfectly in case of regression model (e.g. see how `alm()` from `greybox` works with it), but it fails, when a model has MA-related terms, because the model itself becomes more adaptive to the changes, pulls to centre and cannot maintain the desired quantile.

Third, model combination and selection literature has seen several bright additions to the field, with for example stellar paper by @Kourentzes2019c on pooling. This is neither yet implemented in `adam()`, nor discussed in the textbook. Yes, one can use ADAM to do pooling, but it would make sense to introduce it as a part of the ADAM approach.

Fourth, we have not discussed multiple frequency models in detail that they deserve. For example, we have not mentioned how to do diagnostics of such models, when the sample includes thousands of observations. The classical statistical approaches discussed in Section \@ref(diagnostics) typically fail in this situation, and there are other tools that can be used in this context.

Fifth, `adam()` has a built-in missing values approach that relies on interpolation and intermittent state space model (from Section \@ref(ADAMIntermittent)). While this already works in practice, there are some aspects of this that are worth discussing that have been left outside this textbook.

Finally, while I tried to introduce examples of application of ADAM, case studies for several contexts would be helpful. This would show how ADAM can be used for decisions in inventory management (we have touched the topic in Subsection \@ref(forecastingADAMOtherExample)), scheduling, staff allocation etc.

All of this will hopefully come in the next editions of this textbook.
